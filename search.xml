<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>yolov3实现——head与loss</title>
      <link href="/2020/07/10/yolov3-head-loss/"/>
      <url>/2020/07/10/yolov3-head-loss/</url>
      
        <content type="html"><![CDATA[<h1 id="head"><a class="markdownIt-Anchor" href="#head"></a> head</h1><p>head主要作用是对输出进行后处理，yolov3有三个输出，相应的就有三个head，假定各项参数为：</p><ul><li>输入图片尺寸：416×416×3</li><li>anchors: [[10, 13], [16, 30], [33, 23], [30, 61], [62, 45], [59, 119], [116, 90], [156, 198], [373, 326]]</li><li>masks: [[6, 7, 8], [3, 4, 5], [0, 1, 2]]</li><li>类别数：80</li></ul><p>则yolov3网络的三个输出output_1，output_2，output_3对应的参数为：</p><table><thead><tr><th style="text-align:center"></th><th style="text-align:center">shape</th><th style="text-align:center">anchors</th></tr></thead><tbody><tr><td style="text-align:center">output_1</td><td style="text-align:center">(13, 13, 255)</td><td style="text-align:center">[116, 90], [156, 198], [373, 326]</td></tr><tr><td style="text-align:center">output_2</td><td style="text-align:center">(26, 26, 255)</td><td style="text-align:center">[30, 61], [62, 45], [59, 119]</td></tr><tr><td style="text-align:center">output_3</td><td style="text-align:center">(52, 52, 255)</td><td style="text-align:center">[10, 13], [16, 30], [33, 23]</td></tr></tbody></table><p><strong>注：anchors为当前输出所负责的锚框。</strong></p><p>对单个输出进行后处理，将输出转换成预测框，步骤为：</p><ol><li><p>对输出进行reshape：(grid_size, grid_size, num_anchors * (5 + num_classes)) <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mo>⟶</mo></mrow><annotation encoding="application/x-tex">\longrightarrow</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.522em;vertical-align:-0.011em;"></span><span class="mrel">⟶</span></span></span></span> (grid_size, grid_size, num_anchors, 5 + num_classes)；</p></li><li><p>将reshape的结果按照最后一个维度拆分为：d<sub>x</sub>, d<sub>y</sub>, d<sub>w</sub>, d<sub>h</sub>, confidence, class_probs；</p></li><li><p>添加激活函数，其中</p><ul><li>d<sub>w</sub>, d<sub>h</sub>不需要激活函数；</li><li>d<sub>x</sub>, d<sub>y</sub>使用sigmoid激活函数；</li><li>confidence使用sigmoid激活函数；</li><li>class_probs使用sigmoid激活函数；</li></ul></li><li><p>使用(d<sub>x</sub>, d<sub>y</sub>, d<sub>w</sub>, d<sub>h</sub>)计算框的具体位置，计算公式如下：</p></li></ol><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>x</mi><mo>=</mo><mi>x</mi><mo>+</mo><msub><mi>d</mi><mi>x</mi></msub><mspace linebreak="newline"></mspace><mi>y</mi><mo>=</mo><mi>y</mi><mo>+</mo><msub><mi>d</mi><mi>y</mi></msub><mspace linebreak="newline"></mspace><mi>w</mi><mo>=</mo><mi>w</mi><mo>×</mo><mi>e</mi><mi>x</mi><mi>p</mi><mo stretchy="false">(</mo><msub><mi>d</mi><mi>w</mi></msub><mo stretchy="false">)</mo><mspace linebreak="newline"></mspace><mi>h</mi><mo>=</mo><mi>w</mi><mo>×</mo><mi>e</mi><mi>x</mi><mi>p</mi><mo stretchy="false">(</mo><msub><mi>d</mi><mi>h</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">x = x + d_{x}\\y = y + d_{y}\\w = w × exp(d_{w})\\h = w × exp(d_{h})</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault">x</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.66666em;vertical-align:-0.08333em;"></span><span class="mord mathdefault">x</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">x</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span><span class="mspace newline"></span><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.7777700000000001em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.980548em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathdefault">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.15139200000000003em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.03588em;">y</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span><span class="mspace newline"></span><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.02691em;">w</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.66666em;vertical-align:-0.08333em;"></span><span class="mord mathdefault" style="margin-right:0.02691em;">w</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault">e</span><span class="mord mathdefault">x</span><span class="mord mathdefault">p</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.02691em;">w</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span><span class="mspace newline"></span><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathdefault">h</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.66666em;vertical-align:-0.08333em;"></span><span class="mord mathdefault" style="margin-right:0.02691em;">w</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault">e</span><span class="mord mathdefault">x</span><span class="mord mathdefault">p</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">h</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span></p><ol start="5"><li>将(x, y, w, h)，confidence，(d<sub>x</sub>, d<sub>y</sub>, d<sub>w</sub>, d<sub>h</sub>)，class_probs返回，其中：</li></ol><ul><li>(x, y, w, h)用于计算当前框和ground truth的IoU，从而找到每一个预测框的target；</li><li>confidence用于计算置信度损失；</li><li>(d<sub>x</sub>, d<sub>y</sub>, d<sub>w</sub>, d<sub>h</sub>)用于计算中心坐标和宽高损失；</li><li>class_probs用于计算多分类损失。</li></ul><p>代码为：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">yolo_head</span><span class="params">(preds, anchors, num_classes)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    对单个输出进行后处理</span></span><br><span class="line"><span class="string">    output: (batch_size, grid_size, grid_size, (5 + num_classes))，其中5: (dx, dy, dw, dh, conf)</span></span><br><span class="line"><span class="string">    anchors: 该输出所负责的锚框，小数形式的宽高</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    grid_size = output.shape[<span class="number">1</span>]</span><br><span class="line">    dtype = tf.float32</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 1 reshape</span></span><br><span class="line">    preds = tf.reshape(output, (<span class="number">-1</span>, len(anchors), <span class="number">5</span> + num_classes))</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 2 拆分</span></span><br><span class="line">    perd_dxdy, pred_dwdh, pred_conf, pred_probs = tf.split(preds, [<span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>, num_classes], axis=<span class="number">-1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 3 激活函数</span></span><br><span class="line">    pred_conf = tf.sigmoid(conf)</span><br><span class="line">    perd_dxdy = tf.sigmoid(dxdy)</span><br><span class="line">    pred_probs = tf.sigmoid(probs)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 4 利用dx，dy，dw，dh计算框的具体位置</span></span><br><span class="line">    grid_x, grid_y = tf.meshgrid(tf.range(grid_size), tf.range(grid_size))</span><br><span class="line">    grid_xy = tf.stack([grid_x, grid_y], axis=<span class="number">-1</span>)</span><br><span class="line">    grid_xy = (tf.cast(grid_xy, dtype) + <span class="number">0.5</span>) / tf.cast(grid_size, dtype)  <span class="comment"># (grid_size, grid_size, 2)</span></span><br><span class="line">    </span><br><span class="line">    pred_xy = grid_xy + dxdy</span><br><span class="line">    pred_wh = tf.exp(dwdh) * anchors</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> pred_xy, pred_wh, prd_dxdy, pred_dwdh, pred_conf, pred_probs, grid_xy</span><br></pre></td></tr></table></figure><h1 id="loss"><a class="markdownIt-Anchor" href="#loss"></a> loss</h1><p>这里的loss仅指单个输出的损失。loss函数接收两个值：</p><ul><li>targets：预测的目标值，shape为(batch_size, grid_size, grid_size, num_anchors, 5 + num_classes)，targets的初始格式并非如此，格式转换工作在数据预处理时完成；</li><li>preds：yolo网络的单个输出，shape为(batch_size, grid_size, grid_size, num_anchors * (5 + num_classes))。</li></ul><p>计算loss的步骤为：</p><ol><li><p>调用上面的yolo_head，得到:</p><ul><li>pred_xy：预测框的中心坐标；</li><li>pred_wh：预测框的宽、高；</li><li>prd_dxdy：预测的中心坐标偏移量；</li><li>pred_dwdh：预测的宽、高偏移量；</li><li>pred_conf：预测的置信度；</li><li>pred_probs：预测的各类的概率分布；</li><li>grid_xy：初始锚框的中心坐标；</li></ul><p>将targets也分割target_xy, target_wh, target_conf, target_probs，以便后续计算。</p></li><li><p>由于预测的值实际上是x, y, w, h的偏移量而非其本身，计算loss值时也是对于预测的偏移量和真实的偏移量进行计算，所以我们需要将真实值转换成偏移量，偏移量变换的公式为：</p></li></ol><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>t</mi><mi>a</mi><mi>r</mi><mi>g</mi><mi>e</mi><mi>t</mi><mi mathvariant="normal">_</mi><mi>d</mi><mi>x</mi><mo>=</mo><mi>t</mi><mi>a</mi><mi>r</mi><mi>g</mi><mi>e</mi><mi>t</mi><mi mathvariant="normal">_</mi><mi>x</mi><mo>−</mo><mi>g</mi><mi>r</mi><mi>i</mi><mi>d</mi><mi mathvariant="normal">_</mi><mi>x</mi><mi>t</mi><mi>a</mi><mi>r</mi><mi>g</mi><mi>e</mi><mi>t</mi><mi mathvariant="normal">_</mi><mi>d</mi><mi>y</mi><mo>=</mo><mi>t</mi><mi>a</mi><mi>r</mi><mi>g</mi><mi>e</mi><mi>t</mi><mi mathvariant="normal">_</mi><mi>y</mi><mo>−</mo><mi>g</mi><mi>r</mi><mi>i</mi><mi>d</mi><mi mathvariant="normal">_</mi><mi>y</mi><mi>t</mi><mi>a</mi><mi>r</mi><mi>g</mi><mi>e</mi><mi>t</mi><mi mathvariant="normal">_</mi><mi>d</mi><mi>w</mi><mo>=</mo><mi>l</mi><mi>o</mi><mi>g</mi><mo stretchy="false">(</mo><mi>t</mi><mi>a</mi><mi>r</mi><mi>g</mi><mi>e</mi><mi>t</mi><mi mathvariant="normal">_</mi><mi>w</mi><mi mathvariant="normal">/</mi><mi>g</mi><mi>r</mi><mi>i</mi><mi>d</mi><mi mathvariant="normal">_</mi><mi>w</mi><mo stretchy="false">)</mo><mi>t</mi><mi>a</mi><mi>r</mi><mi>g</mi><mi>e</mi><mi>t</mi><mi mathvariant="normal">_</mi><mi>d</mi><mi>h</mi><mo>=</mo><mi>l</mi><mi>o</mi><mi>g</mi><mo stretchy="false">(</mo><mi>t</mi><mi>a</mi><mi>r</mi><mi>g</mi><mi>e</mi><mi>t</mi><mi mathvariant="normal">_</mi><mi>h</mi><mi mathvariant="normal">/</mi><mi>g</mi><mi>r</mi><mi>i</mi><mi>d</mi><mi mathvariant="normal">_</mi><mi>h</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">target\_dx = target\_x - grid\_xtarget\_dy = target\_y - grid\_ytarget\_dw = log(target\_w/grid\_w)target\_dh = log(target\_h/grid\_h)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.00444em;vertical-align:-0.31em;"></span><span class="mord mathdefault">t</span><span class="mord mathdefault">a</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="mord mathdefault">e</span><span class="mord mathdefault">t</span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord mathdefault">d</span><span class="mord mathdefault">x</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.9250799999999999em;vertical-align:-0.31em;"></span><span class="mord mathdefault">t</span><span class="mord mathdefault">a</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="mord mathdefault">e</span><span class="mord mathdefault">t</span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord mathdefault">x</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.00444em;vertical-align:-0.31em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mord mathdefault">i</span><span class="mord mathdefault">d</span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord mathdefault">x</span><span class="mord mathdefault">t</span><span class="mord mathdefault">a</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="mord mathdefault">e</span><span class="mord mathdefault">t</span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord mathdefault">d</span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.9250799999999999em;vertical-align:-0.31em;"></span><span class="mord mathdefault">t</span><span class="mord mathdefault">a</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="mord mathdefault">e</span><span class="mord mathdefault">t</span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.00444em;vertical-align:-0.31em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mord mathdefault">i</span><span class="mord mathdefault">d</span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="mord mathdefault">t</span><span class="mord mathdefault">a</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="mord mathdefault">e</span><span class="mord mathdefault">t</span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord mathdefault">d</span><span class="mord mathdefault" style="margin-right:0.02691em;">w</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.06em;vertical-align:-0.31em;"></span><span class="mord mathdefault" style="margin-right:0.01968em;">l</span><span class="mord mathdefault">o</span><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="mopen">(</span><span class="mord mathdefault">t</span><span class="mord mathdefault">a</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="mord mathdefault">e</span><span class="mord mathdefault">t</span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord mathdefault" style="margin-right:0.02691em;">w</span><span class="mord">/</span><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mord mathdefault">i</span><span class="mord mathdefault">d</span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord mathdefault" style="margin-right:0.02691em;">w</span><span class="mclose">)</span><span class="mord mathdefault">t</span><span class="mord mathdefault">a</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="mord mathdefault">e</span><span class="mord mathdefault">t</span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord mathdefault">d</span><span class="mord mathdefault">h</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.06em;vertical-align:-0.31em;"></span><span class="mord mathdefault" style="margin-right:0.01968em;">l</span><span class="mord mathdefault">o</span><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="mopen">(</span><span class="mord mathdefault">t</span><span class="mord mathdefault">a</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="mord mathdefault">e</span><span class="mord mathdefault">t</span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord mathdefault">h</span><span class="mord">/</span><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mord mathdefault">i</span><span class="mord mathdefault">d</span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord mathdefault">h</span><span class="mclose">)</span></span></span></span></span></p><ol start="3"><li><p>计算每个预测框与所有目标框的iou的最大值，从而结合ignore_thresh计算ignore_mask。由于计算iou的过程要将所有目标框展开成为(num_target_bboxes, 4)的格式，而每张图片上的目标框数不同，所以不能作为张量整体处理，只能单张逐张图片计算，对于每张图片，进行下述步骤：</p><ul><li>对target_bboxes进行reshape：(grid_size, grid_size, num_anchors, 4) <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mo>⟶</mo></mrow><annotation encoding="application/x-tex">\longrightarrow</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.522em;vertical-align:-0.011em;"></span><span class="mrel">⟶</span></span></span></span> (num_target_bboxes, 4)；</li><li>计算每个检测框与所有目标框的iou，尺寸为(grid_size, grid_size, num_anchors, num_target_bboxes)，计算iou的过程在后面会给出；</li><li>筛选出最大每个检测框与所有目标框的iou中最大的那个，得到的尺寸为(grid_size, grid_size, num_anchors)；</li><li>最后计算ignore_mask，最大iou小于ignore_thresh的检测框对应的值为1，否则为0。</li></ul></li><li><p>计算loss，公式如下（值得注意的是，下式的x, y, w, h都是偏移量而非真实值）：</p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>l</mi><mi>o</mi><mi>s</mi><mi>s</mi><mi mathvariant="normal">_</mi><mi>x</mi><mi>y</mi><mo>=</mo><mo>−</mo><msub><mi>λ</mi><mrow><mi>c</mi><mi>o</mi><mi>o</mi><mi>r</mi><mi>d</mi></mrow></msub><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>0</mn></mrow><msup><mi>S</mi><mn>2</mn></msup></munderover><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>0</mn></mrow><mi>B</mi></munderover><msubsup><mi>I</mi><mrow><mi>i</mi><mi>j</mi></mrow><mrow><mi>o</mi><mi>b</mi><mi>j</mi></mrow></msubsup><mo stretchy="false">{</mo><mo stretchy="false">[</mo><msubsup><mover accent="true"><mi>x</mi><mo>^</mo></mover><mi>i</mi><mi>j</mi></msubsup><mi>l</mi><mi>o</mi><mi>g</mi><mo stretchy="false">(</mo><msubsup><mi>x</mi><mi>i</mi><mi>j</mi></msubsup><mo stretchy="false">)</mo><mo>+</mo><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><msubsup><mover accent="true"><mi>x</mi><mo>^</mo></mover><mi>i</mi><mi>j</mi></msubsup><mo stretchy="false">)</mo><mi>l</mi><mi>o</mi><mi>g</mi><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><msubsup><mi>x</mi><mi>i</mi><mi>j</mi></msubsup><mo stretchy="false">)</mo><mo stretchy="false">]</mo><mo>+</mo><mo stretchy="false">[</mo><msubsup><mover accent="true"><mi>y</mi><mo>^</mo></mover><mi>i</mi><mi>j</mi></msubsup><mi>l</mi><mi>o</mi><mi>g</mi><mo stretchy="false">(</mo><msubsup><mi>y</mi><mi>i</mi><mi>j</mi></msubsup><mo stretchy="false">)</mo><mo>+</mo><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><msubsup><mover accent="true"><mi>y</mi><mo>^</mo></mover><mi>i</mi><mi>j</mi></msubsup><mo stretchy="false">)</mo><mi>l</mi><mi>o</mi><mi>g</mi><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><msubsup><mi>y</mi><mi>i</mi><mi>j</mi></msubsup><mo stretchy="false">)</mo><mo stretchy="false">]</mo><mo stretchy="false">}</mo><mi>l</mi><mi>o</mi><mi>s</mi><mi>s</mi><mi mathvariant="normal">_</mi><mi>w</mi><mi>h</mi><mo>=</mo><msub><mi>λ</mi><mrow><mi>c</mi><mi>o</mi><mi>o</mi><mi>r</mi><mi>d</mi></mrow></msub><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>0</mn></mrow><msup><mi>S</mi><mn>2</mn></msup></munderover><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>0</mn></mrow><mi>B</mi></munderover><msubsup><mi>I</mi><mrow><mi>i</mi><mi>j</mi></mrow><mrow><mi>o</mi><mi>b</mi><mi>j</mi></mrow></msubsup><mo stretchy="false">(</mo><mn>2</mn><mo>−</mo><msubsup><mi>w</mi><mi>i</mi><mi>j</mi></msubsup><mo>×</mo><msubsup><mi>h</mi><mi>i</mi><mi>j</mi></msubsup><mo stretchy="false">)</mo><mo stretchy="false">[</mo><mo stretchy="false">(</mo><msubsup><mi>w</mi><mi>i</mi><mi>j</mi></msubsup><mo>−</mo><msubsup><mover accent="true"><mi>w</mi><mo>^</mo></mover><mi>i</mi><mi>j</mi></msubsup><msup><mo stretchy="false">)</mo><mn>2</mn></msup><mo>+</mo><mo stretchy="false">(</mo><msubsup><mi>h</mi><mi>i</mi><mi>j</mi></msubsup><mo>−</mo><msubsup><mover accent="true"><mi>h</mi><mo>^</mo></mover><mi>i</mi><mi>j</mi></msubsup><msup><mo stretchy="false">)</mo><mn>2</mn></msup><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">loss\_xy=-\lambda_{coord}\sum_{i=0}^{S^{2}}\sum_{j=0}^{B}I_{ij}^{obj}\{[\hat{x}_{i}^{j}log(x_{i}^{j})+(1-\hat{x}_{i}^{j})log(1-x_{i}^{j})]+[\hat{y}_{i}^{j}log(y_{i}^{j})+(1-\hat{y}_{i}^{j})log(1-y_{i}^{j})]\}loss\_wh=\lambda_{coord}\sum_{i=0}^{S^{2}}\sum_{j=0}^{B}I_{ij}^{obj}(2-w_{i}^{j}×h_{i}^{j})[(w_{i}^{j}-\hat{w}_{i}^{j})^{2}+(h_{i}^{j}-\hat{h}_{i}^{j})^{2}]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.00444em;vertical-align:-0.31em;"></span><span class="mord mathdefault" style="margin-right:0.01968em;">l</span><span class="mord mathdefault">o</span><span class="mord mathdefault">s</span><span class="mord mathdefault">s</span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord mathdefault">x</span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:3.387702em;vertical-align:-1.4137769999999998em;"></span><span class="mord">−</span><span class="mord"><span class="mord mathdefault">λ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">c</span><span class="mord mathdefault mtight">o</span><span class="mord mathdefault mtight">o</span><span class="mord mathdefault mtight" style="margin-right:0.02778em;">r</span><span class="mord mathdefault mtight">d</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.9739250000000004em;"><span style="top:-1.872331em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">0</span></span></span></span><span style="top:-3.050005em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3000050000000005em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.05764em;">S</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8913142857142857em;"><span style="top:-2.931em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.277669em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.8283360000000006em;"><span style="top:-1.872331em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span><span class="mrel mtight">=</span><span class="mord mtight">0</span></span></span></span><span style="top:-3.050005em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3000050000000005em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.05017em;">B</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.4137769999999998em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07847em;">I</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9670159999999999em;"><span style="top:-2.4231360000000004em;margin-left:-0.07847em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span></span></span></span><span style="top:-3.1809080000000005em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">o</span><span class="mord mathdefault mtight">b</span><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.412972em;"><span></span></span></span></span></span></span><span class="mopen">{</span><span class="mopen">[</span><span class="mord"><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.69444em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault">x</span></span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.22222em;">^</span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9425719999999999em;"><span style="top:-2.4231360000000004em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span style="top:-3.180908em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.276864em;"><span></span></span></span></span></span></span><span class="mord mathdefault" style="margin-right:0.01968em;">l</span><span class="mord mathdefault">o</span><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9425719999999999em;"><span style="top:-2.4231360000000004em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span style="top:-3.180908em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.276864em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.219436em;vertical-align:-0.276864em;"></span><span class="mord"><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.69444em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault">x</span></span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.22222em;">^</span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9425719999999999em;"><span style="top:-2.4231360000000004em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span style="top:-3.180908em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.276864em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mord mathdefault" style="margin-right:0.01968em;">l</span><span class="mord mathdefault">o</span><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="mopen">(</span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.219436em;vertical-align:-0.276864em;"></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9425719999999999em;"><span style="top:-2.4231360000000004em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span style="top:-3.180908em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.276864em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mclose">]</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.219436em;vertical-align:-0.276864em;"></span><span class="mopen">[</span><span class="mord"><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.69444em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">y</span></span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.19444em;">^</span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.19444em;"><span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9425719999999999em;"><span style="top:-2.4231360000000004em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span style="top:-3.180908em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.276864em;"><span></span></span></span></span></span></span><span class="mord mathdefault" style="margin-right:0.01968em;">l</span><span class="mord mathdefault">o</span><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9425719999999999em;"><span style="top:-2.4231360000000004em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span style="top:-3.180908em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.276864em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.219436em;vertical-align:-0.276864em;"></span><span class="mord"><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.69444em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">y</span></span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.19444em;">^</span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.19444em;"><span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9425719999999999em;"><span style="top:-2.4231360000000004em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span style="top:-3.180908em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.276864em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mord mathdefault" style="margin-right:0.01968em;">l</span><span class="mord mathdefault">o</span><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="mopen">(</span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.2525719999999998em;vertical-align:-0.31em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9425719999999999em;"><span style="top:-2.4231360000000004em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span style="top:-3.180908em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.276864em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mclose">]</span><span class="mclose">}</span><span class="mord mathdefault" style="margin-right:0.01968em;">l</span><span class="mord mathdefault">o</span><span class="mord mathdefault">s</span><span class="mord mathdefault">s</span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord mathdefault" style="margin-right:0.02691em;">w</span><span class="mord mathdefault">h</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:3.387702em;vertical-align:-1.4137769999999998em;"></span><span class="mord"><span class="mord mathdefault">λ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">c</span><span class="mord mathdefault mtight">o</span><span class="mord mathdefault mtight">o</span><span class="mord mathdefault mtight" style="margin-right:0.02778em;">r</span><span class="mord mathdefault mtight">d</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.9739250000000004em;"><span style="top:-1.872331em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">0</span></span></span></span><span style="top:-3.050005em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3000050000000005em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.05764em;">S</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8913142857142857em;"><span style="top:-2.931em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.277669em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.8283360000000006em;"><span style="top:-1.872331em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span><span class="mrel mtight">=</span><span class="mord mtight">0</span></span></span></span><span style="top:-3.050005em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3000050000000005em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.05017em;">B</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.4137769999999998em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07847em;">I</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9670159999999999em;"><span style="top:-2.4231360000000004em;margin-left:-0.07847em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span></span></span></span><span style="top:-3.1809080000000005em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">o</span><span class="mord mathdefault mtight">b</span><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.412972em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord">2</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.219436em;vertical-align:-0.276864em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9425719999999999em;"><span style="top:-2.4231360000000004em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span style="top:-3.180908em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.276864em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.219436em;vertical-align:-0.276864em;"></span><span class="mord"><span class="mord mathdefault">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9425719999999999em;"><span style="top:-2.4231360000000004em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span style="top:-3.180908em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.276864em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mopen">[</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9425719999999999em;"><span style="top:-2.4231360000000004em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span style="top:-3.180908em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.276864em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.219436em;vertical-align:-0.276864em;"></span><span class="mord"><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.69444em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02691em;">w</span></span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.16666em;">^</span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9425719999999999em;"><span style="top:-2.4231360000000004em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span style="top:-3.180908em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.276864em;"><span></span></span></span></span></span></span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8641079999999999em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.219436em;vertical-align:-0.276864em;"></span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9425719999999999em;"><span style="top:-2.4231360000000004em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span style="top:-3.180908em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.276864em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.2347439999999998em;vertical-align:-0.276864em;"></span><span class="mord"><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9578799999999998em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault">h</span></span></span><span style="top:-3.26344em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.25em;">^</span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9425719999999999em;"><span style="top:-2.4231360000000004em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span style="top:-3.180908em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.276864em;"><span></span></span></span></span></span></span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8641079999999999em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span><span class="mclose">]</span></span></span></span></span></p><p>loss_conf_noobj=-\lambda_{noobj}\sum_{i=0}<sup>{S</sup>{2}}\sum_{j=0}<sup>{B}I_{ij}</sup>{noobj}[\hat{C}<em>{i}<sup>{j}log(C_{i}</sup>{j})+(1-\hat{C}</em>{i}<sup>{j})log(1-C_{i}</sup>{j})]<br />loss_cls=-\sum_{i=0}<sup>{S</sup>{2}}\sum_{j=0}<sup>{B}I_{ij}</sup>{obj}\sum_{c\in classes}[\hat{p}<em>{i}<sup>{j}©log(p_{i}</sup>{j}©)+(1-\hat{p}</em>{i}<sup>{j}©)log(1-p_{i}</sup>{j}©)]</p>其中：- loss_xy：中心坐标损失，论文中写的是均方误差，但作者给出的源码中是交叉熵；- loss_wh：宽、高损失，均方误差，由于大物体的宽、高大于小物体，所以会带来更大的损失，使用$2-w×h$作为权重可以缓解这种情况；- loss_conf_obj：有物体的置信度损失，交叉熵损失；- loss_conf_noobj：无物体的置信度损失，对于没有物体的地方，只考虑那些与所有目标框的iou都小于ignore_thresh的预测框；- loss_cls：分类损失，由于激活函数使用的是sigmoid，所以这里用二分类交叉熵而非多分类交叉熵。</li></ol><p>对于上述第4步的loss计算，分析如下：</p><ul><li>某个目标框的首选框（obj_mask对应值为1）或与任意一个目标框iou大于ignore_thresh的框（ignore_mask对应值为0），视为正例，参与loss计算；</li><li>并非任意一个目标框的首选框（obj_mask对应值为1）且与所有目标框iou都小于ignore_thresh的框（ignore_mask对应值为1），视为负例，参与loss计算；</li><li>并非任意一个目标框的首选框且与所有目标框iou都大于ignore_thresh的框，忽略。</li></ul><p>计算单张图片上每个预测框与所有目标框的iou的代码</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">united_iou</span><span class="params">(bboxes1, bboxes2)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    对于单张图片，求所有预测框和所有目标框的iou</span></span><br><span class="line"><span class="string">    bboxes1: (grid_size, grid_size, num_anchors, 4)</span></span><br><span class="line"><span class="string">    bboxes2: (num_bboxes, 4)</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="comment"># expand_dims</span></span><br><span class="line">    bboxes1 = tf.expand_dims(bboxes1, <span class="number">3</span>)    <span class="comment"># (grid_size, grid_size, num_anchors, 1, 4)</span></span><br><span class="line">    bboxes2 = tf.reshape(bboxes2, (<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, bboxes2.shape[<span class="number">0</span>], bboxes2.shape[<span class="number">1</span>]))    <span class="comment"># (1, 1, 1, num_bboxes, 4)</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># box area</span></span><br><span class="line">    bboxes1_area = bboxes1[..., <span class="number">2</span>] * bboxes1[..., <span class="number">3</span>]</span><br><span class="line">    bboxes2_area = bboxes2[..., <span class="number">2</span>] * bboxes2[..., <span class="number">3</span>]</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># xmin, xmax, ymin, ymax</span></span><br><span class="line">    bboxes1_xmin = bboxes1[..., <span class="number">0</span>] - bboxes1[..., <span class="number">2</span>] / <span class="number">2.</span></span><br><span class="line"></span><br><span class="line">    bboxes1_xmax = bboxes1[..., <span class="number">0</span>] + bboxes1[..., <span class="number">2</span>] / <span class="number">2.</span></span><br><span class="line">    bboxes1_ymin = bboxes1[..., <span class="number">1</span>] - bboxes1[..., <span class="number">3</span>] / <span class="number">2.</span></span><br><span class="line">    bboxes1_ymax = bboxes1[..., <span class="number">1</span>] + bboxes1[..., <span class="number">3</span>] / <span class="number">2.</span></span><br><span class="line"></span><br><span class="line">    bboxes2_xmin = bboxes2[..., <span class="number">0</span>] - bboxes2[..., <span class="number">2</span>] / <span class="number">2.</span></span><br><span class="line">    bboxes2_xmax = bboxes2[..., <span class="number">0</span>] + bboxes2[..., <span class="number">2</span>] / <span class="number">2.</span></span><br><span class="line">    bboxes2_ymin = bboxes2[..., <span class="number">1</span>] - bboxes2[..., <span class="number">3</span>] / <span class="number">2.</span></span><br><span class="line">    bboxes2_ymax = bboxes2[..., <span class="number">1</span>] + bboxes2[..., <span class="number">3</span>] / <span class="number">2.</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># intersection</span></span><br><span class="line">    intersect_width = tf.maximum(tf.minimum(bboxes1_xmax, bboxes2_xmax) - </span><br><span class="line">                                 tf.maximum(bboxes1_xmin, bboxes2_xmin), <span class="number">0</span>)</span><br><span class="line">    intersect_height = tf.maximum(tf.minimum(bboxes1_ymax, bboxes2_ymax) - </span><br><span class="line">                                  tf.maximum(bboxes1_ymin, bboxes2_ymin), <span class="number">0</span>)</span><br><span class="line">    intersection = intersect_width * intersect_height</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># iou: (grid_size, grid_size, num_bboxes)</span></span><br><span class="line">    iou = intersection / (bboxes1_area + bboxes2_area - intersection)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> iou</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 模型实现 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> CNN </tag>
            
            <tag> Object Detection </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>yolov3实现——网络框架搭建</title>
      <link href="/2020/07/08/yolov3-backbone-neck/"/>
      <url>/2020/07/08/yolov3-backbone-neck/</url>
      
        <content type="html"><![CDATA[<h1 id="backbone"><a class="markdownIt-Anchor" href="#backbone"></a> Backbone</h1><h2 id="darknet53"><a class="markdownIt-Anchor" href="#darknet53"></a> Darknet53</h2><p>论文中给出的Darknet53的结构图如下，输入尺寸为256×256。</p><p><img src="darknet53.png" alt="Darknet53" /></p><h2 id="构造过程"><a class="markdownIt-Anchor" href="#构造过程"></a> 构造过程</h2><h3 id="conv_block"><a class="markdownIt-Anchor" href="#conv_block"></a> conv_block</h3><p>上图中的Convolutional指的是Conv-BN-Activation的组合（后面称为Conv块），若忽略filters个数的不同，整个yolov3网络只存在四种不同的Conv块，且backbone中只出现了前三种。这个结论是解析yolov3.cfg得到的，解析过程移步<a href="https://mao-jy.github.io/2020/07/07/yolo-cfg-analysis/#convolutional">这里</a>。</p><table><thead><tr><th style="text-align:center"></th><th style="text-align:center">batch_normalize</th><th style="text-align:center">size</th><th style="text-align:center">stride</th><th>pad</th><th>activation</th></tr></thead><tbody><tr><td style="text-align:center">conv_block_1</td><td style="text-align:center">1</td><td style="text-align:center">3</td><td style="text-align:center">1</td><td>1</td><td>leaky</td></tr><tr><td style="text-align:center">conv_block_2</td><td style="text-align:center">1</td><td style="text-align:center">3</td><td style="text-align:center">2</td><td>1</td><td>leaky</td></tr><tr><td style="text-align:center">conv_block_3</td><td style="text-align:center">1</td><td style="text-align:center">1</td><td style="text-align:center">1</td><td>1</td><td>leaky</td></tr><tr><td style="text-align:center">conv_block_4</td><td style="text-align:center">0</td><td style="text-align:center">1</td><td style="text-align:center">1</td><td>1</td><td>linear</td></tr></tbody></table><p><strong>注：batch_normalize表示是否含有BN层；pad为1表示padding=‘same’；activation表示激活函数，linear表示无激活函数。</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">conv_block</span><span class="params">(x, filters, size, strides, bn=True)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    conv_block: Conv - BN - Activation</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    x = Conv2D(filters, size, strides=strides, padding=<span class="string">'same'</span>)(x)</span><br><span class="line">    <span class="keyword">if</span> bn:</span><br><span class="line">        x = BatchNormalization()(x)</span><br><span class="line">        x = LeakyReLU(alpha=<span class="number">0.1</span>)(x)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure><h3 id="residual_block"><a class="markdownIt-Anchor" href="#residual_block"></a> residual_block</h3><p>两个卷积块和一个shortcut构成一个residual_block：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">residual_block</span><span class="params">(x, filters)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    residual_block：conv_block_3 - conv_block_1 - shortcut</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    filter1, filter2 = filters</span><br><span class="line">    x_prev = x</span><br><span class="line">    </span><br><span class="line">    x = conv_block(x, filter1, size=<span class="number">1</span>, strides=<span class="number">1</span>)</span><br><span class="line">    x = conv_block(x, filter2, size=<span class="number">3</span>, strides=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    x = Add()([x_prev, x])</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure><h3 id="darknet_block"><a class="markdownIt-Anchor" href="#darknet_block"></a> darknet_block</h3><p>存在多个重复的下列结构：降采样(stride=2) - 若干个residual_block，将这种结构定义为darknet_block：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">darknet_block</span><span class="params">(x, filters, repeat)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    darknet_block：conv_block_2 - (repeat * residual_block)</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    filter1, filter2, filter3 = filters</span><br><span class="line">    </span><br><span class="line">    x = conv_block(x, filter1, <span class="number">3</span>, <span class="number">2</span>)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(repeat):</span><br><span class="line">        x = residual_block(x, [filter2, filter3])</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure><h3 id="darknet"><a class="markdownIt-Anchor" href="#darknet"></a> darknet</h3><p>将上述结构进行拼接，得到darknet：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">darknet</span><span class="params">(input_shape, name=None)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    darknet：conv_block_1 - (5 * darknet_block)</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    x_input = Input(shape=input_shape)</span><br><span class="line">    </span><br><span class="line">    x = conv_block(x_input, filters=<span class="number">32</span>, size=<span class="number">3</span>, strides=<span class="number">1</span>)</span><br><span class="line">    </span><br><span class="line">    x = darknet_block(x, filters=[<span class="number">64</span>, <span class="number">32</span>, <span class="number">64</span>], repeat=<span class="number">1</span>)</span><br><span class="line">    x = darknet_block(x, filters=[<span class="number">128</span>, <span class="number">64</span>, <span class="number">128</span>], repeat=<span class="number">2</span>)</span><br><span class="line">    x_36 = x = darknet_block(x, filters=[<span class="number">256</span>, <span class="number">128</span>, <span class="number">256</span>], repeat=<span class="number">8</span>)</span><br><span class="line">    x_61 = x = darknet_block(x, filters=[<span class="number">512</span>, <span class="number">256</span>, <span class="number">512</span>], repeat=<span class="number">8</span>)</span><br><span class="line">    x = darknet_block(x, filters=[<span class="number">1024</span>, <span class="number">512</span>, <span class="number">1024</span>], repeat=<span class="number">4</span>)</span><br><span class="line">    </span><br><span class="line">    model = Model(x_input, [x_36, x_61, x], name=name)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> model</span><br></pre></td></tr></table></figure><h1 id="neck"><a class="markdownIt-Anchor" href="#neck"></a> Neck</h1><p>通过解析yolov3.cfg，可知neck会对三个尺度分别产生一个output（完整的解析移步<a href="%5Bhttps://mao-jy.github.io/2020/07/07/yolo-cfg-analysis/#%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84%5D(https://mao-jy.github.io/2020/07/07/yolo-cfg-analysis/#%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84)">这里</a>），产生方法如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"># -------------- neck_1 + head_1 -------------------</span><br><span class="line">conv_block_3(512)    # 输入为第五个darknet_block的输出</span><br><span class="line">conv_block_1(1024)</span><br><span class="line">conv_block_3(512)</span><br><span class="line">conv_block_1(1024)</span><br><span class="line">conv_block_3(512)</span><br><span class="line">conv_block_1(1024)</span><br><span class="line">conv_block_4(255)    # 卷积层替代全连接层</span><br><span class="line">yolo(6, 7, 8)    # head_1</span><br><span class="line"></span><br><span class="line"># -------------- neck_2 + head_2 -------------------</span><br><span class="line">route(-4)    # 将前面第四层的输出作为下一层的输入</span><br><span class="line">conv_block_3(256)</span><br><span class="line">upsample(2)</span><br><span class="line">route(-1, 61)    # 将前一层的输出和整个网络第61个块的输出（即第四个darknet_block的输出）做concat，并作为下一层的输入</span><br><span class="line">conv_block_3(256)</span><br><span class="line">conv_block_1(512)</span><br><span class="line">conv_block_3(256)</span><br><span class="line">conv_block_1(512)</span><br><span class="line">conv_block_3(256)</span><br><span class="line">conv_block_1(512)</span><br><span class="line">conv_block_4(255)    # 卷积层替代全连接层</span><br><span class="line">yolo(3, 4, 5)    # head_2</span><br><span class="line"></span><br><span class="line"># -------------- neck_3 + head_3 -------------------</span><br><span class="line">route(-4)    # 将前面第四层的输出作为下一层的输入</span><br><span class="line">conv_block_3(128)</span><br><span class="line">upsample(2)</span><br><span class="line">route(-1, 36)    # 将前一层的输出和整个网络第36个块的输出（即第三个darknet_block的输出）做concat，并作为下一层的输入</span><br><span class="line">conv_block_3(128)</span><br><span class="line">conv_block_1(256)</span><br><span class="line">conv_block_3(128)</span><br><span class="line">conv_block_1(256)</span><br><span class="line">conv_block_3(128)</span><br><span class="line">conv_block_1(256)</span><br><span class="line">conv_block_4(255)    # 卷积层替代全连接层</span><br><span class="line">yolo(0, 1, 2)    # head_3</span><br></pre></td></tr></table></figure><p>其中neck_2，neck_3分别需要用到neck_1，neck_2的中间结果作为输入，所以将整个neck分成两部分，yolo_conv和yolo_output。</p><h2 id="yolo_conv"><a class="markdownIt-Anchor" href="#yolo_conv"></a> yolo_conv</h2><p>构造yolo_conv方法，使其能够实现下面三种卷积序列：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"># -------------- yolo_conv_1 -------------------</span><br><span class="line">conv_block_3(512)    # 输入为第五个darknet_block的输出</span><br><span class="line">conv_block_1(1024)</span><br><span class="line">conv_block_3(512)</span><br><span class="line">conv_block_1(1024)</span><br><span class="line">conv_block_3(512)</span><br><span class="line"></span><br><span class="line"># -------------- yolo_conv_2 -------------------</span><br><span class="line">route(-4)    # 将前面第四层的输出作为下一层的输入</span><br><span class="line">conv_block_3(256)</span><br><span class="line">upsample(2)</span><br><span class="line">route(-1, 61)    # 将前一层的输出和整个网络第61个块的输出（即第四个darknet_block的输出）做concat，并作为下一层的输入</span><br><span class="line">conv_block_3(256)</span><br><span class="line">conv_block_1(512)</span><br><span class="line">conv_block_3(256)</span><br><span class="line">conv_block_1(512)</span><br><span class="line">conv_block_3(256)</span><br><span class="line"></span><br><span class="line"># -------------- yolo_conv_3 -------------------</span><br><span class="line">route(-4)    # 将前面第四层的输出作为下一层的输入</span><br><span class="line">conv_block_3(128)</span><br><span class="line">upsample(2)</span><br><span class="line">route(-1, 36)    # 将前一层的输出和整个网络第36个块的输出（即第三个darknet_block的输出）做concat，并作为下一层的输入</span><br><span class="line">conv_block_3(128)</span><br><span class="line">conv_block_1(256)</span><br><span class="line">conv_block_3(128)</span><br><span class="line">conv_block_1(256)</span><br><span class="line">conv_block_3(128)</span><br></pre></td></tr></table></figure><p>代码为：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">yolo_conv</span><span class="params">(input_shape, filters, name=None)</span>:</span></span><br><span class="line"></span><br><span class="line">    filter1, filter2 = filters</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> len(input_shape) == <span class="number">2</span>:</span><br><span class="line">        </span><br><span class="line">        x_input_1 = Input(shape=input_shape[<span class="number">0</span>])</span><br><span class="line">        x_input_2 = Input(shape=input_shape[<span class="number">1</span>])</span><br><span class="line">        x_input = [x_input_1, x_input_2]</span><br><span class="line">        </span><br><span class="line">        x = conv_block(x_input_1, filter1, size=<span class="number">1</span>, strides=<span class="number">1</span>)</span><br><span class="line">        x = UpSampling2D(<span class="number">2</span>)(x)</span><br><span class="line">        x = Concatenate()([x, x_input_2])</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        x = x_input = Input(shape=input_shape)</span><br><span class="line">    </span><br><span class="line">    x = conv_block(x, filter1, size=<span class="number">1</span>, strides=<span class="number">1</span>)</span><br><span class="line">    x = conv_block(x, filter2, size=<span class="number">3</span>, strides=<span class="number">1</span>)</span><br><span class="line">    x = conv_block(x, filter1, size=<span class="number">1</span>, strides=<span class="number">1</span>)</span><br><span class="line">    x = conv_block(x, filter2, size=<span class="number">3</span>, strides=<span class="number">1</span>)</span><br><span class="line">    x = conv_block(x, filter1, size=<span class="number">1</span>, strides=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    model = Model(x_input, x, name=name)</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">return</span> model</span><br></pre></td></tr></table></figure><h2 id="yolo_output"><a class="markdownIt-Anchor" href="#yolo_output"></a> yolo_output</h2><p>构造yolo_output方法，使yolo_conv - yolo_output的组合为neck，三个yolo_output的卷积序列如下（即yolo_output应该能够实现下面三种卷积序列）（其中yolo是用于解码的块，不需要在这里实现）：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"># -------------- head_1 -------------------</span><br><span class="line">conv_block_1(1024)</span><br><span class="line">conv_block_4(255)    # 卷积层替代全连接层</span><br><span class="line"></span><br><span class="line"># -------------- head_2 -------------------</span><br><span class="line">conv_block_1(512)</span><br><span class="line">conv_block_4(255)    # 卷积层替代全连接层</span><br><span class="line"></span><br><span class="line"># -------------- head_3 -------------------</span><br><span class="line">conv_block_1(256)</span><br><span class="line">conv_block_4(255)    # 卷积层替代全连接层</span><br></pre></td></tr></table></figure><p>代码为：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">yolo_output</span><span class="params">(input_shape, filters, num_classes, num_anchors, name=None)</span>:</span></span><br><span class="line">    </span><br><span class="line">    x_input = Input(shape=input_shape)</span><br><span class="line">    </span><br><span class="line">    x = conv_block(x_input, filters, size=<span class="number">3</span>, strides=<span class="number">1</span>)</span><br><span class="line">    x = conv_block(x, filters=(<span class="number">5</span> + num_classes) * num_anchors, size=<span class="number">1</span>, strides=<span class="number">1</span>, bn=<span class="literal">False</span>)</span><br><span class="line">    </span><br><span class="line">    model = Model(x_input, x, name=name)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> model</span><br></pre></td></tr></table></figure><h1 id="yolov3"><a class="markdownIt-Anchor" href="#yolov3"></a> YOLOv3</h1><p>将上面的Backbone和Head进行拼接，即可获得YOLOv3的完整网络结构，结构图如下：</p><p><img src="yolov3.png" alt="YOLOv3" /></p><p>代码为：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">yolov3</span><span class="params">(input_shape, anchors, masks, num_classes)</span>:</span></span><br><span class="line">    </span><br><span class="line">    anchors_1, anchors_2, anchors_3 = anchors[masks[<span class="number">0</span>]], anchors[masks[<span class="number">1</span>]], anchors[masks[<span class="number">2</span>]] </span><br><span class="line">    </span><br><span class="line">    x_input = Input(shape=input_shape, name=<span class="string">'input'</span>)</span><br><span class="line">    </span><br><span class="line">    x_36, x_61, x_darknet = darknet(x_input.shape[<span class="number">1</span>:], name=<span class="string">'darknet'</span>)(x_input)</span><br><span class="line"></span><br><span class="line">    x_neg_4 = yolo_conv(x_darknet.shape[<span class="number">1</span>:], [<span class="number">512</span>, <span class="number">1024</span>], name=<span class="string">'yolo_conv_1'</span>)(x_darknet)</span><br><span class="line">    output_1 = yolo_output(x_neg_4.shape[<span class="number">1</span>:], <span class="number">1024</span>, num_classes, len(anchors_1), name=<span class="string">'yolo_output_1'</span>)(x_neg_4)</span><br><span class="line"></span><br><span class="line">    x_neg_4 = yolo_conv((x_neg_4.shape[<span class="number">1</span>:], x_61.shape[<span class="number">1</span>:]), [<span class="number">256</span>, <span class="number">512</span>], name=<span class="string">'yolo_conv_2'</span>)([x_neg_4, x_61])</span><br><span class="line">    output_2 = yolo_output(x_neg_4.shape[<span class="number">1</span>:], <span class="number">512</span>, num_classes, len(anchors_2), name=<span class="string">'yolo_output_2'</span>)(x_neg_4)</span><br><span class="line">    </span><br><span class="line">    x_neg_4 = yolo_conv((x_neg_4.shape[<span class="number">1</span>:], x_36.shape[<span class="number">1</span>:]), [<span class="number">128</span>, <span class="number">256</span>], name=<span class="string">'yolo_conv_3'</span>)([x_neg_4, x_36])</span><br><span class="line">    output_3 = yolo_output(x_neg_4.shape[<span class="number">1</span>:], <span class="number">256</span>, num_classes, len(anchors_3), name=<span class="string">'yolo_output_3'</span>)(x_neg_4)</span><br><span class="line"></span><br><span class="line">    model = Model(x_input, [output_1, output_2, output_3], name=<span class="string">'yolov3'</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> model</span><br></pre></td></tr></table></figure><p>执行下列代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">anchors = np.array([[<span class="number">10</span>, <span class="number">13</span>], [<span class="number">16</span>, <span class="number">30</span>], [<span class="number">33</span>, <span class="number">23</span>], </span><br><span class="line">                    [<span class="number">30</span>, <span class="number">61</span>], [<span class="number">62</span>, <span class="number">45</span>], [<span class="number">59</span>, <span class="number">119</span>], </span><br><span class="line">                    [<span class="number">116</span>, <span class="number">90</span>], [<span class="number">156</span>, <span class="number">198</span>], [<span class="number">373</span>, <span class="number">326</span>]])</span><br><span class="line">masks =  np.array( [[<span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>], [<span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>], [<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>]])</span><br><span class="line"></span><br><span class="line">model = yolov3((<span class="number">416</span>, <span class="number">416</span>, <span class="number">3</span>), anchors, masks, <span class="number">80</span>)</span><br><span class="line">model.summary()</span><br></pre></td></tr></table></figure><p>得到的输出为：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">Model: &quot;yolov3&quot;</span><br><span class="line">__________________________________________________________________________________________________</span><br><span class="line">Layer (type)                    Output Shape         Param #     Connected to                     </span><br><span class="line">&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;</span><br><span class="line">input (InputLayer)              [(None, 416, 416, 3) 0                                            </span><br><span class="line">__________________________________________________________________________________________________</span><br><span class="line">darknet (Model)                 [(None, 52, 52, 256) 40638496    input[0][0]                      </span><br><span class="line">__________________________________________________________________________________________________</span><br><span class="line">yolo_conv_1 (Model)             (None, 13, 13, 512)  11027968    darknet[1][2]                    </span><br><span class="line">__________________________________________________________________________________________________</span><br><span class="line">yolo_conv_2 (Model)             (None, 26, 26, 256)  2959360     yolo_conv_1[1][0]                </span><br><span class="line">                                                                 darknet[1][1]                    </span><br><span class="line">__________________________________________________________________________________________________</span><br><span class="line">yolo_conv_3 (Model)             (None, 52, 52, 128)  742400      yolo_conv_2[1][0]                </span><br><span class="line">                                                                 darknet[1][0]                    </span><br><span class="line">__________________________________________________________________________________________________</span><br><span class="line">yolo_output_1 (Model)           (None, 13, 13, 255)  4985087     yolo_conv_1[1][0]                </span><br><span class="line">__________________________________________________________________________________________________</span><br><span class="line">yolo_output_2 (Model)           (None, 26, 26, 255)  1313023     yolo_conv_2[1][0]                </span><br><span class="line">__________________________________________________________________________________________________</span><br><span class="line">yolo_output_3 (Model)           (None, 52, 52, 255)  361727      yolo_conv_3[1][0]                </span><br><span class="line">&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;</span><br><span class="line">Total params: 62,028,061</span><br><span class="line">Trainable params: 61,975,453</span><br><span class="line">Non-trainable params: 52,608</span><br><span class="line">__________________________________________________________________________________________________</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 模型实现 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> CNN </tag>
            
            <tag> Object Detection </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>yolov3实现——cfg文件解析</title>
      <link href="/2020/07/07/yolov3-cfg-analysis/"/>
      <url>/2020/07/07/yolov3-cfg-analysis/</url>
      
        <content type="html"><![CDATA[<h1 id="简介"><a class="markdownIt-Anchor" href="#简介"></a> 简介</h1><p>cfg文件中的内容以块的形式存在，块的类别有:</p><ul><li>[net]</li><li>[convolutional]</li><li>[shortcut]</li><li>[route]</li><li>[upsample]</li><li>[yolo]</li></ul><p>cfg文件不仅指明了这些块的参数，而且文件本身也作为一个pipeline而存在。去除最开头的[net]块后，每一个块的输出作为下一个块的输入，其中第一个块的输入为整个网络的输入即预处理后的图片，整个网络以三个[yolo]块为结束。</p><p>yolov3.cfg配置文件：<a href="https://github.com/pjreddie/darknet/blob/master/cfg/yolov3.cfg" target="_blank" rel="noopener">https://github.com/pjreddie/darknet/blob/master/cfg/yolov3.cfg</a></p><h1 id="详细分析"><a class="markdownIt-Anchor" href="#详细分析"></a> 详细分析</h1><h2 id="net"><a class="markdownIt-Anchor" href="#net"></a> [net]</h2><p>内容为网络训练的相关参数，包含batch_size、图片尺寸、学习率衰减等相关参数。</p><h2 id="convolutional"><a class="markdownIt-Anchor" href="#convolutional"></a> [convolutional]</h2><p>这里的convolutional指的是Conv-BN-Activation的组合，而非单纯的卷积层。为了方便理解，若两个卷积层除filters以外的参数（如size，stride，activation等）完全相同，则认为两个卷积块相同。基于上述方法分析cfg文件，发现整个yolo网络只存在4种convolutional块，参数如下表所示（其中第四种最特殊，只出现在yolo块之前，替代全连接层）：</p><table><thead><tr><th style="text-align:center"></th><th style="text-align:center">batch_normalize</th><th style="text-align:center">size</th><th style="text-align:center">stride</th><th style="text-align:center">pad</th><th style="text-align:center">activation</th><th>出现次数</th></tr></thead><tbody><tr><td style="text-align:center">conv_block_1</td><td style="text-align:center">1</td><td style="text-align:center">3</td><td style="text-align:center">1</td><td style="text-align:center">1</td><td style="text-align:center">leaky</td><td>33</td></tr><tr><td style="text-align:center">conv_block_2</td><td style="text-align:center">1</td><td style="text-align:center">3</td><td style="text-align:center">2</td><td style="text-align:center">1</td><td style="text-align:center">leaky</td><td>5（backbone中的5次降采样）</td></tr><tr><td style="text-align:center">conv_block_3</td><td style="text-align:center">1</td><td style="text-align:center">1</td><td style="text-align:center">1</td><td style="text-align:center">1</td><td style="text-align:center">leaky</td><td>34</td></tr><tr><td style="text-align:center">conv_block_4</td><td style="text-align:center">0</td><td style="text-align:center">1</td><td style="text-align:center">1</td><td style="text-align:center">1</td><td style="text-align:center">linear</td><td>3（最终输出块，在3个yolo块之前）</td></tr></tbody></table><p><strong>注：batch_normalize表示是否含有BN层；pad为1表示padding=‘same’；activation表示激活函数，linear表示无激活函数。</strong></p><p>从cfg中提取所有convolutional块的代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line">f = open(<span class="string">'yolov3.cfg'</span>, <span class="string">'r'</span>, encoding=<span class="string">'utf-8'</span>)</span><br><span class="line">lines = f.read().splitlines()</span><br><span class="line">f.close()</span><br><span class="line"></span><br><span class="line">lines = [x <span class="keyword">for</span> x <span class="keyword">in</span> lines <span class="keyword">if</span> x <span class="keyword">and</span> <span class="keyword">not</span> x.startswith(<span class="string">'#'</span>)]</span><br><span class="line">lines = [x.strip() <span class="keyword">for</span> x <span class="keyword">in</span> lines]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 取得所有的convlutional块，每一个块为一个字典（key不包含'filters'），存放在blocks中</span></span><br><span class="line">blocks = []</span><br><span class="line">flag = <span class="literal">False</span></span><br><span class="line"><span class="keyword">for</span> line <span class="keyword">in</span> lines:</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> line.startswith(<span class="string">'\n'</span>):</span><br><span class="line">        <span class="keyword">continue</span></span><br><span class="line"></span><br><span class="line">    line = line.strip()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> line.startswith(<span class="string">'['</span>):</span><br><span class="line">        <span class="keyword">if</span> line.startswith(<span class="string">'[convolutional]'</span>):</span><br><span class="line">            flag = <span class="literal">True</span></span><br><span class="line">            blocks.append(&#123;&#125;)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            flag = <span class="literal">False</span></span><br><span class="line">        <span class="keyword">continue</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> flag:</span><br><span class="line">        key, value = line.split(<span class="string">'='</span>)</span><br><span class="line">        key, value = key.rstrip(), value.lstrip()</span><br><span class="line">        <span class="keyword">if</span> key != <span class="string">'filters'</span>:</span><br><span class="line">            blocks[<span class="number">-1</span>][key] = value</span><br><span class="line"></span><br><span class="line"><span class="comment"># 去除重复的convolutional块</span></span><br><span class="line">hash_block = []</span><br><span class="line"><span class="keyword">for</span> block <span class="keyword">in</span> blocks:</span><br><span class="line">    <span class="keyword">if</span> block <span class="keyword">not</span> <span class="keyword">in</span> hash_block:</span><br><span class="line">        hash_block.append(block)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> block <span class="keyword">in</span> hash_block:</span><br><span class="line">    print(block)</span><br></pre></td></tr></table></figure><h2 id="shortcut"><a class="markdownIt-Anchor" href="#shortcut"></a> [shortcut]</h2><p>即为ResNet中提出的shortcut connection，在yolov3中，shortcut仅存在于backbone（Darknet）中，cfg中的shortcut的格式为：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[shortcut]</span><br><span class="line">from&#x3D;-3</span><br><span class="line">activation&#x3D;linear</span><br></pre></td></tr></table></figure><p>表示将前一个块的输出与向前数第三个块的输出进行相加，linear表示不需要激活函数。令当前块的下标为0，伪代码为：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">blocks[0].output &#x3D; blocks[-1].output + blocks[-3].output    # blocks表示cfg文件中所有的块</span><br></pre></td></tr></table></figure><h2 id="route"><a class="markdownIt-Anchor" href="#route"></a> [route]</h2><p>route起到一种超链接的作用，在整个cfg文件中，route块以两种形式存在：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[route]</span><br><span class="line">layers &#x3D; -4</span><br><span class="line"></span><br><span class="line">[route]</span><br><span class="line">layers &#x3D; -1, 61</span><br></pre></td></tr></table></figure><p>第一种表示超链接到向前数第四个块，令当前块的下标为0。因为网络存在3个最终输出，当第一条路径走到尽头时，需要route块来超链接到之前的块，进行另一条路径的计算。块的伪代码为：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">blocks[0].output &#x3D; blocks[-4].output    # blocks表示cfg文件中所有的块</span><br></pre></td></tr></table></figure><p>第二种表示将指示的两个块的输出做concat，用于多尺度特征的堆叠，伪代码为：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">blocks[0].output &#x3D; concat([blocks[-1].output, blocks[61].output], axis&#x3D;-1)    # blocks表示cfg文件中所有的块</span><br></pre></td></tr></table></figure><p>其中61指的是块从前向后的编号，且编号不包含第一个[net]块，编号从0开始。</p><h2 id="upsample"><a class="markdownIt-Anchor" href="#upsample"></a> [upsample]</h2><p>上采样层，yolov3中只有一种上采样层，用于不同尺度的特征图之间的堆叠。cfg文件中upsample块只有下面一种格式：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[upsample]</span><br><span class="line">stride&#x3D;2</span><br></pre></td></tr></table></figure><h2 id="yolo"><a class="markdownIt-Anchor" href="#yolo"></a> [yolo]</h2><p>yolo块指明当前输出对应的是哪个尺度的anchors，该块的出现标志着当前路径走到了尽头。cfg文件中三个yolo块的格式如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">[yolo]</span><br><span class="line">mask &#x3D; 6,7,8</span><br><span class="line">anchors &#x3D; 10,13,  16,30,  33,23,  30,61,  62,45,  59,119,  116,90,  156,198,  373,326</span><br><span class="line">classes&#x3D;80</span><br><span class="line">num&#x3D;9</span><br><span class="line">jitter&#x3D;.3</span><br><span class="line">ignore_thresh &#x3D; .7</span><br><span class="line">truth_thresh &#x3D; 1</span><br><span class="line">random&#x3D;1</span><br><span class="line"></span><br><span class="line">[yolo]</span><br><span class="line">mask &#x3D; 3,4,5</span><br><span class="line">anchors &#x3D; 10,13,  16,30,  33,23,  30,61,  62,45,  59,119,  116,90,  156,198,  373,326</span><br><span class="line">classes&#x3D;80</span><br><span class="line">num&#x3D;9</span><br><span class="line">jitter&#x3D;.3</span><br><span class="line">ignore_thresh &#x3D; .7</span><br><span class="line">truth_thresh &#x3D; 1</span><br><span class="line">random&#x3D;1</span><br><span class="line"></span><br><span class="line">[yolo]</span><br><span class="line">mask &#x3D; 0,1,2</span><br><span class="line">anchors &#x3D; 10,13,  16,30,  33,23,  30,61,  62,45,  59,119,  116,90,  156,198,  373,326</span><br><span class="line">classes&#x3D;80</span><br><span class="line">num&#x3D;9</span><br><span class="line">jitter&#x3D;.3</span><br><span class="line">ignore_thresh &#x3D; .7</span><br><span class="line">truth_thresh &#x3D; 1</span><br><span class="line">random&#x3D;1</span><br></pre></td></tr></table></figure><h1 id="网络结构"><a class="markdownIt-Anchor" href="#网络结构"></a> 网络结构</h1><p>将cfg中的块以缩写的形式表示（不包含[net]块）：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br></pre></td><td class="code"><pre><span class="line"># &#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D; backbone &#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;</span><br><span class="line"></span><br><span class="line">conv_block_1(32)    # 0</span><br><span class="line"></span><br><span class="line"># -------------- darknet_block_1 &#x3D; dowmsample + 1 * residual_block ------------------</span><br><span class="line"># downsample</span><br><span class="line">conv_block_2(64)    # 1</span><br><span class="line"></span><br><span class="line"># residual_block_1</span><br><span class="line">conv_block_3(32)    # 2</span><br><span class="line">conv_block_1(64)    # 3</span><br><span class="line">shortcut(-3)    # 4</span><br><span class="line"></span><br><span class="line"># -------------- darknet_block_2 &#x3D; dowmsample + 2 * residual_block -------------------</span><br><span class="line"># downsample</span><br><span class="line">conv_block_2(128)    # </span><br><span class="line"></span><br><span class="line"># residual_block_2_1</span><br><span class="line">conv_block_3(64)    # 6</span><br><span class="line">conv_block_1(128)    # 7</span><br><span class="line">shortcut(-3)    # 8</span><br><span class="line"></span><br><span class="line"># residual_block_2_2</span><br><span class="line">conv_block_3(64)    # 9</span><br><span class="line">conv_block_1(128)    # 10</span><br><span class="line">shortcut(-3)    # 11</span><br><span class="line"></span><br><span class="line"># -------------- darknet_block_3 &#x3D; dowmsample + 8 * residual_block -------------------</span><br><span class="line"># downsample</span><br><span class="line">conv_block_2(256)    # 12</span><br><span class="line"></span><br><span class="line"># residual_block_3_1</span><br><span class="line">conv_block_3(128)    # 13</span><br><span class="line">conv_block_1(256)    # 14</span><br><span class="line">shortcut(-3)    # 15</span><br><span class="line"></span><br><span class="line"># residual_block_3_2</span><br><span class="line">conv_block_3(128)    # 16</span><br><span class="line">conv_block_1(256)    # 17</span><br><span class="line">shortcut(-3)    # 18</span><br><span class="line"></span><br><span class="line"># residual_block_3_3</span><br><span class="line">conv_block_3(128)    # 19</span><br><span class="line">conv_block_1(256)    # 20</span><br><span class="line">shortcut(-3)    # 21</span><br><span class="line"></span><br><span class="line"># residual_block_3_4</span><br><span class="line">conv_block_3(128)    # 22</span><br><span class="line">conv_block_1(256)    # 23</span><br><span class="line">shortcut(-3)    # 24</span><br><span class="line"></span><br><span class="line"># residual_block_3_5</span><br><span class="line">conv_block_3(128)    # 25</span><br><span class="line">conv_block_1(256)    # 26</span><br><span class="line">shortcut(-3)    # 27</span><br><span class="line"></span><br><span class="line"># residual_block_3_6</span><br><span class="line">conv_block_3(128)    # 28</span><br><span class="line">conv_block_1(256)    # 29</span><br><span class="line">shortcut(-3)    # 30</span><br><span class="line"></span><br><span class="line"># residual_block_3_7</span><br><span class="line">conv_block_3(128)    # 31</span><br><span class="line">conv_block_1(256)    # 32</span><br><span class="line">shortcut(-3)    # 33</span><br><span class="line"></span><br><span class="line"># residual_block_3_8</span><br><span class="line">conv_block_3(128)    # 34</span><br><span class="line">conv_block_1(256)    # 35</span><br><span class="line">shortcut(-3)    # 36</span><br><span class="line"></span><br><span class="line"># -------------- darknet_block_4 &#x3D; dowmsample + 8 * residual_block -------------------</span><br><span class="line"># downsample</span><br><span class="line">conv_block_2(512)    # 37</span><br><span class="line"></span><br><span class="line"># residual_block_4_1</span><br><span class="line">conv_block_3(256)    # 38</span><br><span class="line">conv_block_1(512)    # 39</span><br><span class="line">shortcut(-3)    # 40</span><br><span class="line"></span><br><span class="line"># residual_block_4_2</span><br><span class="line">conv_block_3(256)    # 41</span><br><span class="line">conv_block_1(512)    # 42</span><br><span class="line">shortcut(-3)    # 43</span><br><span class="line"></span><br><span class="line"># residual_block_4_3</span><br><span class="line">conv_block_3(256)    # 44</span><br><span class="line">conv_block_1(512)    # 45</span><br><span class="line">shortcut(-3)    # 46</span><br><span class="line"></span><br><span class="line"># residual_block_4_4</span><br><span class="line">conv_block_3(256)    # 47</span><br><span class="line">conv_block_1(512)    # 48</span><br><span class="line">shortcut(-3)    # 49</span><br><span class="line"></span><br><span class="line"># residual_block_4_5</span><br><span class="line">conv_block_3(256)    # 50</span><br><span class="line">conv_block_1(512)    # 51</span><br><span class="line">shortcut(-3)    # 52</span><br><span class="line"></span><br><span class="line"># residual_block_4_6</span><br><span class="line">conv_block_3(256)    # 53</span><br><span class="line">conv_block_1(512)    # 54</span><br><span class="line">shortcut(-3)    # 55</span><br><span class="line"></span><br><span class="line"># residual_block_4_7</span><br><span class="line">conv_block_3(256)    # 56</span><br><span class="line">conv_block_1(512)    # 57</span><br><span class="line">shortcut(-3)    # 58</span><br><span class="line"></span><br><span class="line"># residual_block_4_8</span><br><span class="line">conv_block_3(256)    # 59</span><br><span class="line">conv_block_1(512)    # 60</span><br><span class="line">shortcut(-3)    # 61</span><br><span class="line"></span><br><span class="line"># -------------- darknet_block_5 &#x3D; dowmsample + 4 * residual_block -------------------</span><br><span class="line"># downsample</span><br><span class="line">conv_block_2(1024)    # 62</span><br><span class="line"></span><br><span class="line"># residual_block_5_1</span><br><span class="line">conv_block_3(512)    # 63</span><br><span class="line">conv_block_1(1024)    # 64</span><br><span class="line">shortcut(-3)    # 65</span><br><span class="line"></span><br><span class="line"># residual_block_5_2</span><br><span class="line">conv_block_3(512)    # 66</span><br><span class="line">conv_block_1(1024)    # 67</span><br><span class="line">shortcut(-3)    # 68</span><br><span class="line"></span><br><span class="line"># residual_block_5_3</span><br><span class="line">conv_block_3(512)    # 69</span><br><span class="line">conv_block_1(1024)    # 70</span><br><span class="line">shortcut(-3)    # 71</span><br><span class="line"></span><br><span class="line"># residual_block_5_4</span><br><span class="line">conv_block_3(512)    # 72</span><br><span class="line">conv_block_1(1024)    # 73</span><br><span class="line">shortcut(-3)    # 74</span><br><span class="line"></span><br><span class="line"># &#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D; neck + head &#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;</span><br><span class="line"># ---------------- 1 ----------------------</span><br><span class="line">conv_block_3(512)</span><br><span class="line">conv_block_1(1024)</span><br><span class="line">conv_block_3(512)</span><br><span class="line">conv_block_1(1024)</span><br><span class="line">conv_block_3(512)</span><br><span class="line">conv_block_1(1024)</span><br><span class="line">conv_block_4(255)</span><br><span class="line">yolo(6, 7, 8)</span><br><span class="line"></span><br><span class="line"># ---------------- 2 ----------------------</span><br><span class="line">route(-4)</span><br><span class="line">conv_block_3(256)</span><br><span class="line">upsample(2)</span><br><span class="line">route(-1, 61)</span><br><span class="line">conv_block_3(256)</span><br><span class="line">conv_block_1(512)</span><br><span class="line">conv_block_3(256)</span><br><span class="line">conv_block_1(512)</span><br><span class="line">conv_block_3(256)</span><br><span class="line">conv_block_1(512)</span><br><span class="line">conv_block_4(255)</span><br><span class="line">yolo(3, 4, 5)</span><br><span class="line"></span><br><span class="line"># ---------------- 3 ----------------------</span><br><span class="line">route(-4)</span><br><span class="line">conv_block_3(128)</span><br><span class="line">upsample(2)</span><br><span class="line">route(-1, 36)</span><br><span class="line">conv_block_3(128)</span><br><span class="line">conv_block_1(256)</span><br><span class="line">conv_block_3(128)</span><br><span class="line">conv_block_1(256)</span><br><span class="line">conv_block_3(128)</span><br><span class="line">conv_block_1(256)</span><br><span class="line">conv_block_4(255)</span><br><span class="line">yolo(0, 1, 2)</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 模型实现 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> CNN </tag>
            
            <tag> Object Detection </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>《python深度学习》阅读记录（代码向） Part 2</title>
      <link href="/2020/07/05/python-dl-reading-log-2/"/>
      <url>/2020/07/05/python-dl-reading-log-2/</url>
      
        <content type="html"><![CDATA[<h1 id="cnn简介"><a class="markdownIt-Anchor" href="#cnn简介"></a> CNN简介</h1><ol><li>CNN的性质：<ul><li>具有平移不变性：因为是同一个卷积核在整张图上进行移动，所以在图片上不同位置的相同特征都会被卷积核识别；</li><li>能够学到模式的空间层次结构：第一个卷积层学习较小局部模式，第二个卷积层学习更大区域的模式，以此类推。</li></ul></li><li>边界效应：对于Conv2D层，valid表示不填充，same表示填充使得输出输出宽高相同。默认值为valid。</li><li>卷积层步幅为2意味着特征图的宽高被做了2倍的下采样(不考虑边界效应影响)，这种方法在实践中很少被使用，一般会使用最大池化来进行下采样。</li><li>卷积核常用3×3的窗口，步长为1；最大池化常用2×2的窗口，步长为2，以此进行2倍下采样。</li><li>使用下采样的原因：<ul><li>减少需要处理的特征图的元素个数；</li><li>通过让连续卷积层的观察窗口越来越大，从而引入空间过滤器的层级结构。</li></ul></li><li>下采样方法（其中最大池化往往能够带来更多的信息）：<ul><li>卷积层的步幅；</li><li>最大池化；</li><li>平均池化。</li></ul></li></ol><h1 id="imagedatagenerator"><a class="markdownIt-Anchor" href="#imagedatagenerator"></a> ImageDataGenerator</h1><h2 id="cnn序列示例"><a class="markdownIt-Anchor" href="#cnn序列示例"></a> CNN序列示例</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> models, layers</span><br><span class="line"></span><br><span class="line">model = models.Sequential()</span><br><span class="line">model.add(layers.Conv2D(<span class="number">32</span>, (<span class="number">3</span>, <span class="number">3</span>), activation=<span class="string">'relu'</span>, input_shape=(<span class="number">150</span>, <span class="number">150</span>, <span class="number">3</span>)))</span><br><span class="line">model.add(layers.MaxPooling2D((<span class="number">2</span>, <span class="number">2</span>)))</span><br><span class="line">model.add(layers.Conv2D(<span class="number">64</span>, (<span class="number">3</span>, <span class="number">3</span>), activation=<span class="string">'relu'</span>))</span><br><span class="line">model.add(layers.MaxPooling2D((<span class="number">2</span>, <span class="number">2</span>)))</span><br><span class="line">model.add(layers.Conv2D(<span class="number">128</span>, (<span class="number">3</span>, <span class="number">3</span>), activation=<span class="string">'relu'</span>))</span><br><span class="line">model.add(layers.MaxPooling2D((<span class="number">2</span>, <span class="number">2</span>)))</span><br><span class="line">model.add(layers.Conv2D(<span class="number">128</span>, (<span class="number">3</span>, <span class="number">3</span>), activation=<span class="string">'relu'</span>))</span><br><span class="line">model.add(layers.MaxPooling2D((<span class="number">2</span>, <span class="number">2</span>)))</span><br><span class="line">model.add(layers.Flatten())</span><br><span class="line">model.add(layers.Dense(<span class="number">512</span>, activation=<span class="string">'relu'</span>))</span><br><span class="line">model.add(layers.Dense(<span class="number">1</span>, activation=<span class="string">'sigmoid'</span>))</span><br><span class="line"></span><br><span class="line">model.summary()</span><br></pre></td></tr></table></figure><h2 id="python生成器"><a class="markdownIt-Anchor" href="#python生成器"></a> python生成器</h2><p>python生成器使用yield云算法来构造的，是一个类似于迭代器的对象，可以和for, in运算符一起使用。示例如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">generator</span><span class="params">()</span>:</span></span><br><span class="line">    i = <span class="number">0</span></span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">        i += <span class="number">1</span></span><br><span class="line">        <span class="keyword">yield</span> i</span><br><span class="line">        </span><br><span class="line"><span class="keyword">for</span> item <span class="keyword">in</span> generator():</span><br><span class="line">    print(item)</span><br><span class="line">    <span class="keyword">if</span> item &gt; <span class="number">4</span>:</span><br><span class="line">        <span class="keyword">break</span></span><br></pre></td></tr></table></figure><h2 id="数据生成器"><a class="markdownIt-Anchor" href="#数据生成器"></a> 数据生成器</h2><p>文件结构为：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">|-- dogs-vs-cats-small</span><br><span class="line">    |-- train</span><br><span class="line">        |-- dogs</span><br><span class="line">            |-- dog.0.jpg</span><br><span class="line">            |-- ...</span><br><span class="line">            |-- dog.999.jpg</span><br><span class="line">        |-- cats</span><br><span class="line">            |-- cat.0.jpg</span><br><span class="line">            |-- ...</span><br><span class="line">            |-- cat.999.jpg</span><br><span class="line">    |-- val</span><br><span class="line">        |-- dogs</span><br><span class="line">            |-- dog.1000.jpg</span><br><span class="line">            |-- ...</span><br><span class="line">            |-- dog.1499.jpg</span><br><span class="line">        |-- cats</span><br><span class="line">            |-- cat.1000.jpg</span><br><span class="line">            |-- ...</span><br><span class="line">            |-- cat.1499.jpg</span><br></pre></td></tr></table></figure><p>训练代码为：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> keras.preprocessing.image <span class="keyword">import</span> ImageDataGenerator</span><br><span class="line"></span><br><span class="line">train_datagen = ImageDataGenerator(rescale=<span class="number">1.</span>/<span class="number">255</span>)</span><br><span class="line">val_datagen = ImageDataGenerator(rescale=<span class="number">1.</span>/<span class="number">255</span>)</span><br><span class="line"></span><br><span class="line">train_generator = train_datagen.flow_from_directory(</span><br><span class="line">    train_dir, </span><br><span class="line">    target_size=(<span class="number">150</span>, <span class="number">150</span>),</span><br><span class="line">    batch_size = <span class="number">20</span>, </span><br><span class="line">    class_mode=<span class="string">'binary'</span>    <span class="comment"># 因为使用了binary_crossentropy作为损失函数</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">val_generator = val_datagen.flow_from_directory(</span><br><span class="line">    val_dir, </span><br><span class="line">    target_size=(<span class="number">150</span>, <span class="number">150</span>),</span><br><span class="line">    batch_size = <span class="number">20</span>, </span><br><span class="line">    class_mode=<span class="string">'binary'</span>    <span class="comment"># 因为使用了binary_crossentropy作为损失函数</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">history = model.fit_generator(</span><br><span class="line">    train_generator,</span><br><span class="line">    steps_per_epoch=<span class="number">100</span>,    <span class="comment"># 训练集共有2000张图片，batch_size为20</span></span><br><span class="line">    epochs=<span class="number">30</span>, </span><br><span class="line">    validation_data=val_generator, </span><br><span class="line">    validation_steps=<span class="number">50</span>    <span class="comment"># 验证集共有1000张图片，batch_size为20</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">model.save(<span class="string">'last.h5'</span>)    <span class="comment"># 保存模型</span></span><br></pre></td></tr></table></figure><h1 id="数据增强"><a class="markdownIt-Anchor" href="#数据增强"></a> 数据增强</h1><h2 id="增强代码"><a class="markdownIt-Anchor" href="#增强代码"></a> 增强代码</h2><p>数据增强利用多种能够生成可信图像的随机变换来增加样本，以降低过拟合、提高泛化能力。但是数据增强还是不能完全消除过拟合，于是像模型中添加一个Dropout层。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 网络</span></span><br><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> models, layers</span><br><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> optimizers</span><br><span class="line"></span><br><span class="line">model = models.Sequential()</span><br><span class="line">model.add(layers.Conv2D(<span class="number">32</span>, (<span class="number">3</span>, <span class="number">3</span>), activation=<span class="string">'relu'</span>, input_shape=(<span class="number">150</span>, <span class="number">150</span>, <span class="number">3</span>)))</span><br><span class="line">model.add(layers.MaxPooling2D((<span class="number">2</span>, <span class="number">2</span>)))</span><br><span class="line">model.add(layers.Conv2D(<span class="number">64</span>, (<span class="number">3</span>, <span class="number">3</span>), activation=<span class="string">'relu'</span>))</span><br><span class="line">model.add(layers.MaxPooling2D((<span class="number">2</span>, <span class="number">2</span>)))</span><br><span class="line">model.add(layers.Conv2D(<span class="number">128</span>, (<span class="number">3</span>, <span class="number">3</span>), activation=<span class="string">'relu'</span>))</span><br><span class="line">model.add(layers.MaxPooling2D((<span class="number">2</span>, <span class="number">2</span>)))</span><br><span class="line">model.add(layers.Conv2D(<span class="number">128</span>, (<span class="number">3</span>, <span class="number">3</span>), activation=<span class="string">'relu'</span>))</span><br><span class="line">model.add(layers.MaxPooling2D((<span class="number">2</span>, <span class="number">2</span>)))</span><br><span class="line">model.add(layers.Flatten())</span><br><span class="line">model.add(layers.Dropout(<span class="number">0.5</span>))</span><br><span class="line">model.add(layers.Dense(<span class="number">512</span>, activation=<span class="string">'relu'</span>))</span><br><span class="line">model.add(layers.Dense(<span class="number">1</span>, activation=<span class="string">'sigmoid'</span>))</span><br><span class="line"></span><br><span class="line">model.compile(</span><br><span class="line">    loss=<span class="string">'binary_crossentropy'</span>, </span><br><span class="line">    optimizer=optimizers.RMSprop(lr=<span class="number">1e-4</span>), </span><br><span class="line">    metrics=[<span class="string">'acc'</span>]</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">model.summary()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 数据</span></span><br><span class="line"><span class="keyword">from</span> keras.preprocessing.image <span class="keyword">import</span> ImageDataGenerator</span><br><span class="line"></span><br><span class="line">train_datagen = ImageDataGenerator(</span><br><span class="line">    rescale=<span class="number">1.</span>/<span class="number">255</span>, </span><br><span class="line">    rotation_range=<span class="number">40</span>, </span><br><span class="line">    width_shift_range=<span class="number">0.2</span>, </span><br><span class="line">    height_shift_range=<span class="number">0.2</span>,</span><br><span class="line">    shear_range=<span class="number">0.2</span>, </span><br><span class="line">    zoom_range=<span class="number">0.2</span>, </span><br><span class="line">    horizontal_flip=<span class="literal">True</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">test_datagen = ImageDataGenerator(rescale=<span class="number">1.</span>/<span class="number">255</span>)</span><br><span class="line"></span><br><span class="line">train_generator = train_datagen.flow_from_directory(</span><br><span class="line">    train_dir, </span><br><span class="line">    target_size=(<span class="number">150</span>, <span class="number">150</span>), </span><br><span class="line">    batch_size=<span class="number">32</span>, </span><br><span class="line">    class_mode=<span class="string">'binary'</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">val_generator = test_datagen.flow_from_directory(</span><br><span class="line">    val_dir, </span><br><span class="line">    target_size=(<span class="number">150</span>, <span class="number">150</span>), </span><br><span class="line">    batch_size=<span class="number">32</span>, </span><br><span class="line">    class_mode=<span class="string">'binary'</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练</span></span><br><span class="line">history = model.fit(</span><br><span class="line">    train_generator, </span><br><span class="line">    steps_per_epoch=<span class="number">100</span>, </span><br><span class="line">    epochs=<span class="number">100</span>, </span><br><span class="line">    validation_data=val_generator, </span><br><span class="line">    validation_steps=<span class="number">50</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure><h2 id="增强效果可视化"><a class="markdownIt-Anchor" href="#增强效果可视化"></a> 增强效果可视化</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> keras.preprocessing <span class="keyword">import</span> image</span><br><span class="line"><span class="keyword">from</span> keras.preprocessing.image <span class="keyword">import</span> ImageDataGenerator</span><br><span class="line"></span><br><span class="line">datagen = ImageDataGenerator(</span><br><span class="line">    rotation_range=<span class="number">40</span>,    <span class="comment"># 取值范围0~180，随机旋转的角度范围</span></span><br><span class="line">    width_shift_range=<span class="number">0.2</span>,    <span class="comment"># 取值范围0~1，在水平方向平移的范围</span></span><br><span class="line">    height_shift_range=<span class="number">0.2</span>,    <span class="comment"># 取值范围0~1，在竖直方向平移的范围</span></span><br><span class="line">    shear_range=<span class="number">0.2</span>,    <span class="comment"># 随机错切变换的角度（这里设置成0.2没有效果，调大才有明显视觉效果）</span></span><br><span class="line">    zoom_range=<span class="number">0.2</span>,    <span class="comment"># 图像随机缩放的范围</span></span><br><span class="line">    horizontal_flip=<span class="literal">True</span>,    <span class="comment"># 是否将一般图像左右翻转</span></span><br><span class="line">    fill_mode=<span class="string">'nearest'</span>    <span class="comment"># 像素填充的方法</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">fnames = [os.path.join(train_cats_dir, name) <span class="keyword">for</span> name <span class="keyword">in</span> os.listdir(train_cats_dir)]</span><br><span class="line">img_path = fnames[<span class="number">3</span>]</span><br><span class="line"></span><br><span class="line">img = image.load_img(img_path, target_size=(<span class="number">150</span>, <span class="number">150</span>))</span><br><span class="line">x = image.img_to_array(img)</span><br><span class="line">x = x.reshape((<span class="number">1</span>,) + x.shape)</span><br><span class="line"></span><br><span class="line">i = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> batch <span class="keyword">in</span> datagen.flow(x, batch_size=<span class="number">1</span>):</span><br><span class="line">    plt.figure(i)</span><br><span class="line">    imgplot = plt.imshow(image.array_to_img(batch[<span class="number">0</span>]))    <span class="comment"># 这里的image.array_to_img可以去掉，plt.imshow()可以直接对numpy数组进行显示</span></span><br><span class="line">    i += <span class="number">1</span></span><br><span class="line">    <span class="keyword">if</span> i % <span class="number">4</span> == <span class="number">0</span>:</span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line">        </span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><h1 id="预训练"><a class="markdownIt-Anchor" href="#预训练"></a> 预训练</h1><p>使用预训练的两种方法：特征提取(feature extraction)和微调模型(fine-tuning)。</p><h2 id="特征提取"><a class="markdownIt-Anchor" href="#特征提取"></a> 特征提取</h2><p>使用预训练网络的卷积基。</p><p>全连接层的表示不包含物体在输入图像中的位置信息，舍弃了空间的概念，物体的位置信息由卷积特征图描述。</p><p>卷积层的通用性取决于该层在模型中的深度，更靠近底部的层提取的是局部的、高度通用的特征图（如视觉边缘、颜色和纹理等），而更靠近顶部提取的是更加抽象的概念（如“猫耳朵”或“狗眼睛”）。因此，如果用户数据集和预训练数据集有很大差异，那么最好只使用模型的前几层来做特征提取，而不是整个卷积基。</p><p>由于全连接层是随机初始化，反向传播的权重更新非常大，所以一定要冻结卷积基，否则会对预训练的参数造成很大破坏，而且时间还会大大延长。</p><h3 id="特征提取和分类单独进行"><a class="markdownIt-Anchor" href="#特征提取和分类单独进行"></a> 特征提取和分类单独进行</h3><p>在数据集上运行卷积基，把结果保存，然后再独立地输入到密集分类其中，这样能够节省大量时间，但缺点在于不能进行数据增强。节省时间的原因在于每张图片只需要进行一次卷积基的计算，而卷积是模型中耗时最长的。</p><ul><li><p>加载模型以及参数</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 加载模型以及参数</span></span><br><span class="line"><span class="keyword">from</span> keras.applications <span class="keyword">import</span> VGG16</span><br><span class="line"></span><br><span class="line">conv_base = VGG16(weights=<span class="string">'vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5'</span>, </span><br><span class="line">                  include_top=<span class="literal">False</span>,    <span class="comment"># 不包含全连接层</span></span><br><span class="line">                  input_shape=(<span class="number">150</span>, <span class="number">150</span>, <span class="number">3</span>))    <span class="comment"># input为可选参数，如不设置，则网络可以接受任意形状的输入</span></span><br></pre></td></tr></table></figure></li><li><p>特征提取</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">datagen = ImageDataGenerator(rescale=<span class="number">1.</span>/<span class="number">255</span>)</span><br><span class="line">batch_size = <span class="number">20</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">extract_features</span><span class="params">(directory, sample_count)</span>:</span></span><br><span class="line">    features_map = np.zeros((sample_count, <span class="number">4</span>, <span class="number">4</span>, <span class="number">512</span>))</span><br><span class="line">    labels = np.zeros((sample_count))</span><br><span class="line"></span><br><span class="line">    generator = datagen.flow_from_directory(</span><br><span class="line">        directory, </span><br><span class="line">        target_size=(<span class="number">150</span>, <span class="number">150</span>), </span><br><span class="line">        batch_size=batch_size, </span><br><span class="line">        class_mode=<span class="string">'binary'</span></span><br><span class="line">    )</span><br><span class="line">    </span><br><span class="line">    i = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> input_batch, labels_batch <span class="keyword">in</span> generator:</span><br><span class="line">        features_map[i * batch_size: (i + <span class="number">1</span>) * batch_size] = conv_base.predict(input_batch)</span><br><span class="line">        labels[i * batch_size: (i + <span class="number">1</span>) * batch_size] = labels_batch</span><br><span class="line">        i += <span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> i * batch_size &gt;= sample_count:</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">            </span><br><span class="line">    <span class="keyword">return</span> features_map, labels</span><br><span class="line"></span><br><span class="line">train_features, train_labels = extract_features(train_dir, <span class="number">2000</span>)    </span><br><span class="line">val_features, val_labels = extract_features(val_dir, <span class="number">1000</span>)   </span><br><span class="line"></span><br><span class="line">train_features = np.reshape(train_features, (<span class="number">2000</span>, <span class="number">8192</span>))</span><br><span class="line">val_features = np.reshape(val_features, (<span class="number">1000</span>, <span class="number">8192</span>))</span><br></pre></td></tr></table></figure></li><li><p>分类器训练</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">model &#x3D; models.Sequential()</span><br><span class="line">model.add(layers.Dense(256, activation&#x3D;&#39;relu&#39;, input_dim&#x3D;8192))</span><br><span class="line">model.add(layers.Dropout(0.5))</span><br><span class="line">model.add(layers.Dense(1, activation&#x3D;&#39;sigmoid&#39;))</span><br><span class="line"></span><br><span class="line">model.compile(loss&#x3D;&#39;binary_crossentropy&#39;, </span><br><span class="line">              optimizer&#x3D;RMSprop(lr&#x3D;2e-5),  </span><br><span class="line">              metrics&#x3D;[&#39;acc&#39;])</span><br><span class="line"></span><br><span class="line">history &#x3D; model.fit(train_features, train_labels, </span><br><span class="line">          epochs&#x3D;30, </span><br><span class="line">          batch_size&#x3D;20, </span><br><span class="line">          validation_data&#x3D;(val_features, val_labels))</span><br></pre></td></tr></table></figure></li></ul><h3 id="端到端模式"><a class="markdownIt-Anchor" href="#端到端模式"></a> 端到端模式</h3><p>将卷积基和密集分类器作为一个端到端的网络进行训练，这样可以进行数据增强，但时间会大大增加。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 加载模型以及参数</span></span><br><span class="line"><span class="keyword">from</span> keras.applications <span class="keyword">import</span> VGG16</span><br><span class="line"></span><br><span class="line">conv_base = VGG16(weights=<span class="string">'vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5'</span>, </span><br><span class="line">                  include_top=<span class="literal">False</span>,    <span class="comment"># 不包含全连接层</span></span><br><span class="line">                  input_shape=(<span class="number">150</span>, <span class="number">150</span>, <span class="number">3</span>))    <span class="comment"># input为可选参数，如不设置，则网络可以接受任意形状的输入</span></span><br><span class="line"></span><br><span class="line">model = models.Sequential()</span><br><span class="line">conv_base.trainable = <span class="literal">False</span>    <span class="comment"># 冻结卷积基</span></span><br><span class="line">model.add(conv_base)</span><br><span class="line">model.add(layers.Flatten())</span><br><span class="line">model.add(layers.Dense(<span class="number">256</span>, activation=<span class="string">'relu'</span>))</span><br><span class="line">model.add(layers.Dense(<span class="number">1</span>, activation=<span class="string">'sigmoid'</span>))</span><br><span class="line"></span><br><span class="line">train_datagen = ImageDataGenerator(</span><br><span class="line">    rescale=<span class="number">1.</span>/<span class="number">255</span>, </span><br><span class="line">    rotation_range=<span class="number">40</span>, </span><br><span class="line">    width_shift_range=<span class="number">0.2</span>, </span><br><span class="line">    height_shift_range=<span class="number">0.2</span>, </span><br><span class="line">    shear_range=<span class="number">0.2</span>, </span><br><span class="line">    zoom_range=<span class="number">0.2</span>, </span><br><span class="line">    horizontal_flip=<span class="literal">True</span>, </span><br><span class="line">    fill_mode=<span class="string">'nearest'</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">test_datagen = ImageDataGenerator(rescale=<span class="number">1.</span>/<span class="number">255</span>)</span><br><span class="line"></span><br><span class="line">train_generator = train_datagen.flow_from_directory(</span><br><span class="line">    train_dir, </span><br><span class="line">    target_size=(<span class="number">150</span>, <span class="number">150</span>), </span><br><span class="line">    batch_size=<span class="number">20</span>, </span><br><span class="line">    class_mode=<span class="string">'binary'</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">val_generator = test_datagen.flow_from_directory(</span><br><span class="line">    val_dir, </span><br><span class="line">    target_size=(<span class="number">150</span>, <span class="number">150</span>), </span><br><span class="line">    batch_size=<span class="number">20</span>, </span><br><span class="line">    class_mode=<span class="string">'binary'</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">model.compile(loss=<span class="string">'binary_crossentropy'</span>, </span><br><span class="line">              optimizer=RMSprop(<span class="number">2e-5</span>), </span><br><span class="line">              metrics=<span class="string">'acc'</span>)</span><br><span class="line"></span><br><span class="line">history = model.fit_generator(train_generator, </span><br><span class="line">          steps_per_epoch=<span class="number">100</span>, </span><br><span class="line">          epochs=<span class="number">30</span>, </span><br><span class="line">          validation_data=val_generator, </span><br><span class="line">          validation_steps=<span class="number">50</span>)</span><br></pre></td></tr></table></figure><h2 id="模型微调"><a class="markdownIt-Anchor" href="#模型微调"></a> 模型微调</h2><p>将卷积基顶部的几层解冻，即略微调整了复用模型中更加抽象的表示，让这些表示和自己的数据集更加相关，微调步骤如下：</p><ol><li>在卷积基上添加全连接层；</li><li>冻结卷积基，训练全连接层；</li><li>解冻卷积基靠后的某些层，继续训练；</li></ol><p>不能一开始就解冻卷积基某些层的原因：一开始全连接层参数随机初始化，损失值会非常大，参数更新会很大，会破坏预训练参数学到的东西。</p><p>设置trainable参数的方法：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 方法1，索引</span></span><br><span class="line">model.layers[n].trainable = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 方法2，迭代</span></span><br><span class="line"><span class="keyword">for</span> layer <span class="keyword">in</span> model.layers:</span><br><span class="line">    <span class="keyword">if</span> layer.name == <span class="string">'block1_conv1'</span>:</span><br><span class="line">    layer.trainable = <span class="literal">False</span></span><br><span class="line"> </span><br><span class="line"><span class="comment"># 方法3，定义的时候进行设置</span></span><br><span class="line">frozen_layer = Dense(<span class="number">32</span>, trainable=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 方法4</span></span><br><span class="line">print(model._get_trainable_state())</span><br><span class="line"><span class="keyword">for</span> k, v <span class="keyword">in</span> model._get_trainable_state().items():</span><br><span class="line">    k.trainable = <span class="literal">False</span></span><br></pre></td></tr></table></figure><p>有以下两种情况：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">conv_base.trainable = <span class="literal">False</span>    <span class="comment"># 生效</span></span><br><span class="line">conv_base.layers[<span class="number">5</span>] = <span class="literal">True</span>    <span class="comment"># 失效</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">conv_base.trainable = <span class="literal">True</span>    <span class="comment"># 生效</span></span><br><span class="line">conv_base.layers[<span class="number">5</span>] = <span class="literal">False</span>    <span class="comment"># 生效</span></span><br></pre></td></tr></table></figure><p>由此可见，False的优先级更高。</p><h1 id="cnn可视化"><a class="markdownIt-Anchor" href="#cnn可视化"></a> CNN可视化</h1><h2 id="可视化卷积神经网络的中间输出中间激活"><a class="markdownIt-Anchor" href="#可视化卷积神经网络的中间输出中间激活"></a> 可视化卷积神经网络的中间输出（中间激活）</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Model</span><br><span class="line"></span><br><span class="line">layer_outputs = [layer.output <span class="keyword">for</span> layer <span class="keyword">in</span> model.layers[:<span class="number">8</span>]]    <span class="comment"># 因为模型特征提取部分前8个layer，第9个layer开始进入全连接层</span></span><br><span class="line">activation_model = Model(inputs=model.input, outputs=layer_outputs)</span><br><span class="line"></span><br><span class="line">activations = activation_model.predict(img_tensor)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取层名称</span></span><br><span class="line">layer_names = []</span><br><span class="line"><span class="keyword">for</span> layer <span class="keyword">in</span> model.layers[:<span class="number">8</span>]:</span><br><span class="line">    layer_names.append(layer.name)</span><br><span class="line">    </span><br><span class="line">images_per_row = <span class="number">16</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> layer_name, layer_activation <span class="keyword">in</span> zip(layer_names, activations):</span><br><span class="line">    n_features = layer_activation.shape[<span class="number">-1</span>]</span><br><span class="line">    size = layer_activation.shape[<span class="number">1</span>]</span><br><span class="line">    </span><br><span class="line">    num_rows = n_features // images_per_row</span><br><span class="line">    display_grid = np.zeros((size * num_rows, size * images_per_row))</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> row <span class="keyword">in</span> range(num_rows):</span><br><span class="line">        <span class="keyword">for</span> col <span class="keyword">in</span> range(images_per_row):</span><br><span class="line">            channel_image = layer_activation[<span class="number">0</span>, :, :, row * images_per_row + col]</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 对特征进行后处理，使其更加美观</span></span><br><span class="line">            channel_image -= channel_image.mean()</span><br><span class="line">            channel_image /= channel_image.std()</span><br><span class="line">            channel_image *= <span class="number">64</span></span><br><span class="line">            channel_image += <span class="number">128</span></span><br><span class="line">            channel_image = np.clip(channel_image, <span class="number">0</span>, <span class="number">255</span>).astype(<span class="string">'uint8'</span>)</span><br><span class="line">            </span><br><span class="line">            display_grid[row * size: (row + <span class="number">1</span>) * size, col * size: (col + <span class="number">1</span>) * size] = channel_image</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 改变窗口大小</span></span><br><span class="line">    scale = <span class="number">1.</span>/size</span><br><span class="line">    plt.figure(figsize=(scale * display_grid.shape[<span class="number">1</span>], </span><br><span class="line">                        scale * display_grid.shape[<span class="number">0</span>]))    <span class="comment"># figsize=(width, height), float</span></span><br><span class="line">    plt.title(layer_name)</span><br><span class="line">    plt.grid(<span class="literal">False</span>)</span><br><span class="line">    plt.imshow(display_grid, aspect=<span class="string">'auto'</span>, cmap=<span class="string">'viridis'</span>)</span><br></pre></td></tr></table></figure><p><strong>结论：</strong></p><ul><li>一开始视觉信息会比较多，有许多边缘探测器，几乎保留了原图中的所有信息；</li><li>随着层数加深，越来越抽象，开始表示更高层次的概念，如猫耳朵，猫眼睛。层数越深，视觉信息就会越来越少，类别信息会越来越多；</li><li>激活的稀疏度越来越高，许多激活是空白的，表示输入图像中不存在这些过滤器编码模式（比如某个过滤器是检测耳朵的，而这只猫没有耳朵，则这个过滤器就会是空白的）；</li><li>信息蒸馏管道：将无关信息过滤（比如说具体外观），放大和细化有用的信息（如类别），这和人类记忆一个东西是一样的（你可能记得那是一辆自行车，但你很难记得那辆自行车的细节，因为大多数细节都别“蒸馏”了，只留下了类别概念“自行车”）。</li></ul><h2 id="可视化卷积神经网络的过滤器"><a class="markdownIt-Anchor" href="#可视化卷积神经网络的过滤器"></a> 可视化卷积神经网络的过滤器</h2><p>固定VGG的预训练参数，对图像进行随机初始化和梯度下降，以此达到使某一个特征图的某一个通道的激活最大，这样得到的图像可以反应这个过滤器的作用。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> keras.applications <span class="keyword">import</span> VGG16</span><br><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> backend <span class="keyword">as</span> K</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">model = VGG16(include_top=<span class="literal">True</span>, weights=<span class="string">'vgg16_weights_tf_dim_ordering_tf_kernels.h5'</span>)</span><br><span class="line">model.summary()</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">deprocess_image</span><span class="params">(x)</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 标准化，均值为0.5，标准差为0.1</span></span><br><span class="line">    x -= x.mean()</span><br><span class="line">    x /= (x.std() + <span class="number">1e-5</span>)    <span class="comment"># 1e-5防止分母为0</span></span><br><span class="line">    x *= <span class="number">0.1</span></span><br><span class="line">    </span><br><span class="line">    x += <span class="number">0.5</span></span><br><span class="line">    x = np.clip(x, <span class="number">0</span>, <span class="number">1</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 转换为RGB</span></span><br><span class="line">    x *= <span class="number">255</span></span><br><span class="line">    x = np.clip(x, <span class="number">0</span>, <span class="number">255</span>).astype(<span class="string">'uint8'</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> x</span><br><span class="line">    </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">generate_pattern</span><span class="params">(layer_name, filter_index, size=<span class="number">150</span>)</span>:</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 定义iterate</span></span><br><span class="line">    layer_output = model.get_layer(layer_name).output</span><br><span class="line">    loss = K.mean(layer_output[:, :, :, filter_index])</span><br><span class="line">    </span><br><span class="line">    grads = K.gradients(loss, model.input)[<span class="number">0</span>]</span><br><span class="line">    grads /= (K.sqrt(K.mean(K.square(grads))) + <span class="number">1e-5</span>)    <span class="comment"># 将grads除以其L2范数，1e-5是为了防止分母为0</span></span><br><span class="line"></span><br><span class="line">    iterate = K.function([model.input], [loss, grads])    <span class="comment"># iterate为一个函数，它将[model.input]转换为[loss, grads]</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 对随机初始化的图像进行40次梯度下降</span></span><br><span class="line">    input_img_data = np.random.random((<span class="number">1</span>, size, size, <span class="number">3</span>)) * <span class="number">20</span> + <span class="number">128</span>    <span class="comment"># 随机初始化一张图片</span></span><br><span class="line">    step = <span class="number">1.</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">40</span>):</span><br><span class="line">        loss_value, grads_value = iterate(input_img_data)</span><br><span class="line">        input_img_data += grads_value * step</span><br><span class="line">        </span><br><span class="line">    img = input_img_data[<span class="number">0</span>]</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> deprocess_image(img)</span><br></pre></td></tr></table></figure><p>显示使某一层的某一个通道的激活最大的图像，这个图像反应了这个过滤器的作用。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">plt.imshow(generate_pattern(<span class="string">'block3_conv1'</span>, <span class="number">0</span>))</span><br></pre></td></tr></table></figure><p>显示使某一层前64个通道的激活最大的图像。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">layer_name = <span class="string">'block1_conv1'</span></span><br><span class="line">size = <span class="number">64</span></span><br><span class="line">margin = <span class="number">5</span></span><br><span class="line"></span><br><span class="line">results = np.zeros((size * <span class="number">8</span> + margin * <span class="number">7</span>, size * <span class="number">8</span> + margin * <span class="number">7</span>, <span class="number">3</span>), dtype=<span class="string">'uint8'</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">8</span>):</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> range(<span class="number">8</span>):</span><br><span class="line">        filter_image = generate_pattern(layer_name, i * <span class="number">8</span> + j, size=size)</span><br><span class="line">        </span><br><span class="line">        begin_row = i * size + i * margin</span><br><span class="line">        end_row = begin_row + size</span><br><span class="line">        begin_col = j * size + j * margin</span><br><span class="line">        end_col = begin_col + size</span><br><span class="line">        </span><br><span class="line">        results[begin_row: end_row, begin_col: end_col, :] = filter_image</span><br><span class="line">        </span><br><span class="line">plt.figure(figsize=(<span class="number">10</span>, <span class="number">10</span>))</span><br><span class="line">plt.imshow(results)</span><br></pre></td></tr></table></figure><p>通过实验结果可以发现，第一层主要对应边缘和颜色，第二层过滤器对应颜色和边缘组成的简单纹理，再往后会对应越来越复杂的边缘和纹理的组合（以至于类似于自然图像的纹理）。</p><h2 id="可视化类激活的热力图"><a class="markdownIt-Anchor" href="#可视化类激活的热力图"></a> 可视化类激活的热力图</h2><p>类激活图表示了每一部分对最终决策的重要性。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> keras.applications <span class="keyword">import</span> VGG16</span><br><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> backend <span class="keyword">as</span> K</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">model = VGG16(include_top=<span class="literal">True</span>, weights=<span class="string">'vgg16_weights_tf_dim_ordering_tf_kernels.h5'</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> keras.preprocessing <span class="keyword">import</span> image</span><br><span class="line"><span class="keyword">from</span> keras.applications.vgg16 <span class="keyword">import</span> preprocess_input, decode_predictions</span><br><span class="line"></span><br><span class="line">img = image.load_img(<span class="string">'ele.png'</span>, target_size=(<span class="number">224</span>, <span class="number">224</span>))</span><br><span class="line"></span><br><span class="line">x = image.img_to_array(img)</span><br><span class="line">x = np.expand_dims(x, <span class="number">0</span>)</span><br><span class="line">x = preprocess_input(x)</span><br><span class="line"></span><br><span class="line">preds = model.predict(x)</span><br><span class="line">print(decode_predictions(preds, top=<span class="number">3</span>)[<span class="number">0</span>])</span><br><span class="line">print(np.argmax(preds))    <span class="comment"># 输出为386，即非洲象的类别号是386</span></span><br></pre></td></tr></table></figure><p>Grad-CAM算法</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">african_elephant_output = model.output[:, <span class="number">386</span>]</span><br><span class="line">last_conv_layer = model.get_layer(<span class="string">'block5_conv3'</span>)    <span class="comment"># 获取vgg16的最后一个卷积层</span></span><br><span class="line"></span><br><span class="line">grads = K.gradients(african_elephant_output, last_conv_layer.output)[<span class="number">0</span>]    <span class="comment"># 获取非洲象结果相对于block5_conv3输出特征图的梯度</span></span><br><span class="line">pooled_grads = K.mean(grads, axis=(<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>))    <span class="comment"># 获取每个通道的平均梯度（共有512个通道，所以输出512个浮点数）</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># iterate为一个函数，输入为模型输入，输出为最后一个卷积层输出的特征图的每个通道梯度的平均值，以及这个卷积层输出的特征图</span></span><br><span class="line">iterate = K.function([model.input], [pooled_grads, last_conv_layer.output[<span class="number">0</span>]])</span><br><span class="line"></span><br><span class="line">pooled_grads_value, last_conv_layer_value = iterate([x])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将特征图的每个通道乘以这个通道数对最后结果的“重要程度”</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">512</span>):</span><br><span class="line">    last_conv_layer_value[:, :, i] *= pooled_grads_value[i]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 特征图的逐通道的平均值，即为类激活的热力图</span></span><br><span class="line">heatmap = np.mean(last_conv_layer_value, <span class="number">-1</span>)</span><br></pre></td></tr></table></figure><p>热力图后处理</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">heatmap = np.maximum(<span class="number">0</span>, heatmap)</span><br><span class="line">heatmap /= np.max(heatmap)</span><br><span class="line">plt.matshow(heatmap)</span><br></pre></td></tr></table></figure><p>热力图于原始图像的叠加</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"></span><br><span class="line">img = cv2.imread(<span class="string">'ele.png'</span>)</span><br><span class="line">heatmap = cv2.resize(heatmap, (img.shape[<span class="number">1</span>], img.shape[<span class="number">0</span>]))    <span class="comment"># cv2的resize需要先宽后高</span></span><br><span class="line">heatmap = np.uint8(heatmap * <span class="number">255</span>)    <span class="comment"># 热力图转换为RGB模式</span></span><br><span class="line">heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)    <span class="comment"># 热力图应用于原图</span></span><br><span class="line">superimposed_img = heatmap * <span class="number">0.4</span> + img</span><br><span class="line"></span><br><span class="line">cv2.imwrite(<span class="string">'ele_cam.jpg'</span>, superimposed_img)</span><br></pre></td></tr></table></figure><h1 id="附录"><a class="markdownIt-Anchor" href="#附录"></a> 附录</h1><p>损失不降低但精度仍然不断提高的原因：损失是损失值的平均，但影响精度的是损失值的分布。</p>]]></content>
      
      
      <categories>
          
          <category> 阅读记录 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Deep Learning </tag>
            
            <tag> Python </tag>
            
            <tag> Keras </tag>
            
            <tag> Tensorflow </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ResNet</title>
      <link href="/2020/07/03/ResNet/"/>
      <url>/2020/07/03/ResNet/</url>
      
        <content type="html"><![CDATA[<h1 id="概述"><a class="markdownIt-Anchor" href="#概述"></a> 概述</h1><p>AlexNet将卷积神经网络带入CV领域，VGG和GoogLeNet致力于加深卷积神经网络来提升模型的表现力，而当网络达到一定深度后，研究者们发现一味地加深并不能继续提升效果，反而会使得模型收敛困难，而且表现并不如浅层网络。下图是在CIFAR-10上分别训练20层和56层卷积神经网络地结果，无论在训练集还是测试集，更深的56层反而比20层表现更差，我们称之为网络退化，ResNet主要是为了解决这个问题被提出。</p><p><img src="Network_Degradation.png" alt="Network Degradation" /></p><p>ResNet提出于2015年，深度最大达到了前所未有的152层，一举获得了当年ILSVRC分类竞赛的冠军，达到了Top-5 3.57%的错误率。以ResNet为基础，何凯明团队还获取了当年的ILSVRC定位任务冠军和检测任务冠军，以及COCO数据集上的检测任务冠军和分割任务冠军。</p><p>论文：<a href="https://arxiv.org/pdf/1512.03385.pdf" target="_blank" rel="noopener">Deep Residual Learning for Image Recognition</a></p><p>代码实现：<a href="https://github.com/mao-jy/Model-Implementation/tree/master/ResNet50" target="_blank" rel="noopener">ResNet50</a></p><h1 id="网络详解"><a class="markdownIt-Anchor" href="#网络详解"></a> 网络详解</h1><h2 id="shortcut-connection"><a class="markdownIt-Anchor" href="#shortcut-connection"></a> Shortcut Connection</h2><p>前面说过，同样的数据集上，56层的效果反而不如20层，说明多出来的36层不能进行恒等变换（即多个非线性变换的叠加不能近似于恒等变换），因此，我们需要提供这个恒等变换的可能，来防止网络退化的情况。</p><p><img src="Shortcut_Connection.png" alt="Shortcut Connection" /></p><p>上图所示为残差块的基本结构，在极端的情况下，需要恒等变换，这种结构会比多个非线性变换叠加更加容易拟合恒等映射。从另一个角度来看，由于“快捷连接”的存在，深层的特征图一定比浅层的特征图具有更加丰富的信息。按直觉来说relu放在相加前更容易拟合恒等变换（将参数全部置零即可），但是在这里却将relu放在了相加后，关于relu的位置问题在2016年ResNet v2的论文<a href="https://arxiv.org/pdf/1603.05027.pdf" target="_blank" rel="noopener">Identity Mappings in Deep Residual Networks</a>中会有相关讨论。</p><h2 id="残差块"><a class="markdownIt-Anchor" href="#残差块"></a> 残差块</h2><p>基于上述思想，作者给出了两种残差块的设计，如下图所示。如今特征提取常用的ResNet50和ResNet101都是用了下图右的结构，其中1×1卷积主要是为了降维和升维，以此减少计算量，因为中间的通道数小于两边的通道数，这种结构又被成为“瓶颈”结构。</p><p><img src="Residual_Block.png" alt="Residual Block" /></p><h2 id="resnet"><a class="markdownIt-Anchor" href="#resnet"></a> ResNet</h2><p>将上述两种结构进行堆叠，就得到了ResNet，其中conv3_1，conv4_1，conv5_1的卷积步长为2，进行降采样，降采样的细节下面会介绍。具体参数如下表。</p><p><img src="ResNet.png" alt="ResNet" /></p><h1 id="resnet50的实现"><a class="markdownIt-Anchor" href="#resnet50的实现"></a> ResNet50的实现</h1><p><img src="ResNet50.png" alt="ResNet50" /></p><h2 id="zero-pad"><a class="markdownIt-Anchor" href="#zero-pad"></a> ZERO PAD</h2><p>在网上许多博客与实现代码中，整个网络只有唯一的零填充（在上图的最开始位置），但在keras.application中的ResNet50，会在最大池化层之前加一层零填充，即stage 1的结构为：卷积-BN-ReLU-零填充-最大池化，不过这个无关紧要，加不加都可以。</p><h2 id="残差块-2"><a class="markdownIt-Anchor" href="#残差块-2"></a> 残差块</h2><p>残差块的具体实现有下面两种形式：</p><p><img src="identity_block.png" alt="Identity Block" /></p><p><img src="conv_block.png" alt="Convolutional Block" /></p><p>下面给出两种残差块中卷积层的具体参数：</p><table><thead><tr><th style="text-align:center"></th><th style="text-align:center">Identity Block</th><th style="text-align:center">Convolutional Block</th></tr></thead><tbody><tr><td style="text-align:center">1×1</td><td style="text-align:center">strides: (1, 1), padding: valid</td><td style="text-align:center">strides: (2, 2), padding: valid</td></tr><tr><td style="text-align:center">3×3</td><td style="text-align:center">strides: (1, 1), padding: same</td><td style="text-align:center">strides: (1, 1), padding: same</td></tr><tr><td style="text-align:center">1×1</td><td style="text-align:center">strides: (1, 1), padding: valid</td><td style="text-align:center">strides: (1, 1), padding: valid</td></tr><tr><td style="text-align:center">shortcut</td><td style="text-align:center">/</td><td style="text-align:center">kernel_size: (1, 1) strides(2, 2) padding: valid</td></tr></tbody></table><h2 id="avg-pool"><a class="markdownIt-Anchor" href="#avg-pool"></a> AVG POOL</h2><p>最后的AVG POOL是全局平均池化层，其实现代码为：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">x = Lambda(<span class="keyword">lambda</span> y: K.mean(y,axis=[<span class="number">1</span>,<span class="number">2</span>]),name=<span class="string">'avgpool'</span>)(x)    <span class="comment"># import keras.backend as K</span></span><br></pre></td></tr></table></figure><p>达到的效果是将每一个特征图转换为一个值，如(7, 7, 2048)的特征图，经过全局平均池化层后就会变成(2048,)，后面不需要Flatten，直接与全连接层相连。</p><h2 id="使用预训练"><a class="markdownIt-Anchor" href="#使用预训练"></a> 使用预训练</h2><p>keras提供的预训练模型与自己写的模型结构不一定完全匹配，所以想要加载预训练模型最快捷的方式就是寻找出含有可训练参数的层，按照keras.applications.ResNet50的规范给它们命名，并在加载参数的时候执行下面的语句：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model.load_weights(<span class="string">'resnet50.h5'</span>, by_name=<span class="literal">True</span>)    <span class="comment"># 加载同名层的参数，其他层不加载</span></span><br></pre></td></tr></table></figure><p>ResNet50中含有可训练参数的层为所有卷积层和所有BN层。</p>]]></content>
      
      
      <categories>
          
          <category> 模型解析 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Deep Learning </tag>
            
            <tag> CNN </tag>
            
            <tag> CNN五大经典模型 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>VGG</title>
      <link href="/2020/07/02/VGG/"/>
      <url>/2020/07/02/VGG/</url>
      
        <content type="html"><![CDATA[<h1 id="概述"><a class="markdownIt-Anchor" href="#概述"></a> 概述</h1><p>VGGNet是牛津大学计算机视觉几何组(Visual Geometry Group)和Google DeepMind共同研发出的卷积神经网络，于ILSVRC-2014分类竞赛中达到了Top-5 7.32%的错误率，获得亚军，冠军为GoogLeNet，虽然排名第二，但差距很小，且VGGNet在各项迁移学习任务中地表现却优于后者。</p><p>既然与GoogLeNet同出一年，那么设计上有些相同的思想也不足为奇，比如说都是为了研究深度对于神经网络的影响，都是基于AlexNet结构进行模型构造，都使用了Network In Network中的某些思想等。</p><p>论文：<a href="https://arxiv.org/pdf/1409.1556.pdf" target="_blank" rel="noopener">Very Deep Convolutional Networks for Large-Scale Image Recognition</a></p><h1 id="网络详解"><a class="markdownIt-Anchor" href="#网络详解"></a> 网络详解</h1><p><img src="VGG-16_20200702.png" alt="VGG-16" /></p><p><strong>注：上图为VGG-16结构图。</strong></p><ul><li><p>VGGNet中统一使用了3×3的卷核和2×2的池化窗口。与AlexNet不同，VGG全部采用了3×3的卷积核。不难发现，5×5卷积得到的感受野和两个3×3卷积的堆叠得到的感受野相同，7×7卷积的感受野和三个3×3卷积的堆叠得到的感受野相同，但比起大卷积，3×3卷积的优势在于：</p><ul><li>增加了非线性映射，这会使决策函数更加具有判别性，即3×3卷积-非线性函数-3×3卷积-非线性函数的结构比5×5卷积-非线性函数的结构更加具有表现力。</li><li>参数量小。假设输入输出都为C个通道，7×7的卷积需要7×7×C×C=49C<sup>2</sup>个参数，而3个堆叠的3×3卷积只需要(3×3×C×C)×3=27C<sup>2</sup>个参数。</li></ul></li><li><p>去除了AlexNet和GoogLeNet中使用的LRN，作者通过实验发现，LRN对于精度没有提升，反而会增加时间和内存消耗</p></li><li><p>作者根据不同深度进行了多组对比实验，最后结果是VGG-16和VGG-19明显优于其他网络，所以我们通常所说的VGG或者VGGNet一般是指VGG-16或VGG-19，具体的各个网络结构如下图所示。与GoogLeNet相同的一点是， 作者也尝试了1×1的卷积，给出的结论是：1×1卷积确实有效，但效果不如3×3卷积好。个人认为1×1卷积的主要优势在于改变维度（升维或降维），其次才是增加非线性，堆叠多个3×3的卷积可以在提取空间特征的同时增加非线性，GoogLeNet中发现1×1卷积有用的原因很可能是其沿用了AlexNet中的大卷积（5×5卷积和7×7卷积），所以需要1×1卷积来增加非线性。</p></li></ul><p><img src="VGGNet_20200702.png" alt="VGGNet" /></p><h1 id="总结"><a class="markdownIt-Anchor" href="#总结"></a> 总结</h1><ul><li><p>相较于之前的AlexNet和GoogLeNet，VGG-16的优点是不言而喻的：结构简单。VGGNet给出了以下两个结论：</p><ul><li><p>用3×3卷积核的堆叠替代5×5或7×7卷积核能取得更好的效果。</p></li><li><p>验证了增加深度可以提高网络性能。</p></li></ul></li><li><p>VGGNet的缺点是参数量过大，VGG-16共含138M的参数，全连接层含~124M的参数，第一层全连接层含7×7×512×4096~103M的参数，也就是说大部分的参数产生于第一层全连接层，所以想要降低VGG的参数量必然要从全连接层入手。</p></li><li><p>VGG中比较有趣的一点是，随着网络的加深，尺寸会减半，而深度会翻倍，个人猜测设计的思想是每次特征图尺寸减半，感受野的宽、高会翻倍，每个特征点必然包含更多信息，所以需要用两倍的特征值来表示。</p></li><li><p>关于上面一点，还有一些思考，比如说特征图从224×224×64变成112×112×128，宽、高减半，特征图的深度从64变成了128，这里的深度不一定只能变成128，保持64不变可能也可以，变成256可能也可以，或者是任何一个数字都可以，但128更加符合直觉（即用两倍的特征值来表示宽、高翻倍后的感受野），且“特征图宽、高减半，深度翻倍”这个做法通过大量实验证明可行。我给出上述猜测的原因是1×1卷积的降维，如果经过某个卷积层后的特征图可以进行降维，然后继续计算，且得到不错的结果，说明实际上该特征图是“维度冗余”的，即可以用更少的特征层来表达当前的信息，当前的特征层其实是一种稀疏的形式。这只是个人的一些猜想，具体是否是这样还需要大量实验的佐证。</p></li></ul>]]></content>
      
      
      <categories>
          
          <category> 模型解析 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Deep Learning </tag>
            
            <tag> CNN </tag>
            
            <tag> CNN五大经典模型 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>GoogLeNet</title>
      <link href="/2020/06/28/GoogLeNet/"/>
      <url>/2020/06/28/GoogLeNet/</url>
      
        <content type="html"><![CDATA[<h1 id="概述"><a class="markdownIt-Anchor" href="#概述"></a> 概述</h1><p>提高网络性能最直接的方法就是构建更深更大的模型，但直接增加模型的深度和宽度往往会带来以下问题：</p><ul><li>过拟合问题。模型过大，参数过多，如果没有足够的数据用于训练，过拟合问题将十分严重。</li><li>计算成本。宽度和深度的增加必然会带来计算成本的剧增，实用性是一个必须考虑的问题。</li></ul><p>解决上述问题的基本方法就是用稀疏连接替代稠密连接，但计算机对于稀疏连接的计算是十分低效的（查找和缓存开销大），解决这个问题的办法就是将稀疏矩阵聚类成多个稠密的子矩阵进行计算。在这种思想的指导下，GoogLeNet诞生了，并一举拿下ILSVRC-2014分类竞赛冠军，达到了Top-5 6.67%的错误率。</p><p>GoogLeNet的名字一方面是因为来源于谷歌，另一方面也是对LeNet-5的致敬。为了解决过拟合和计算成本问题，该模型提出了极具创意的结构——Inception，在论文中，作者还引用了同名电影Inception（盗梦空间）中的图：<a href="https://knowyourmeme.com/memes/we-need-to-go-deeper" target="_blank" rel="noopener">We Need To Go Deeper</a>，这也表明了GoogLeNet和Inception的出发点，即构建更深更大的网络（当然，是在考虑可行性的前提下）。</p><p>论文：<a href="https://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Szegedy_Going_Deeper_With_2015_CVPR_paper.pdf" target="_blank" rel="noopener">Going Deeper with Convolutions</a></p><h1 id="网络详解"><a class="markdownIt-Anchor" href="#网络详解"></a> 网络详解</h1><h2 id="inception"><a class="markdownIt-Anchor" href="#inception"></a> Inception</h2><h3 id="稀疏矩阵与稠密矩阵"><a class="markdownIt-Anchor" href="#稀疏矩阵与稠密矩阵"></a> 稀疏矩阵与稠密矩阵</h3><p>将稀疏矩阵转换成稠密矩阵进行计算的示例如下图所示，将左边的稀疏矩阵（大量0元素）转换成右边的稠密矩阵，分别计算，显然能够减少大量的计算，而这种方法应用在Inception结构中，就是将特征维度上进行分解（比如说输出256维的特征图，对于该特征图的某个像素点，需要想办法使得输出的前128维为一个稠密矩阵，接下来64维是一个稠密矩阵，最后的64维是一个稠密矩阵）。</p><p><img src="sparse_matrix__20200628.png" alt="sparse_matrix" /></p><h3 id="naive-inception"><a class="markdownIt-Anchor" href="#naive-inception"></a> Naive Inception</h3><p>Inception结构如下图所示，将输入分别进行1×1，3×3，5×5的卷积和最大池化，然后将结果进行堆叠，为了保证最后能够堆叠，上述卷积和池化必须保证前后的宽、高不变。对于这种结构的好处，作者从以下几点来解释：</p><ul><li>进行了多尺度进行卷积，能够提取到不同尺度的特征，使得最后的分类结果更加准确；</li><li>该结构等价于将稀疏矩阵分解为密集矩阵来加速收敛。传统的卷积只进行一种尺寸的卷积（如3×3，通道数256），这样输出的256个特征都是从3×3这个尺寸上提取出来的，相当于这256个特征是稀疏的，而使用了Inception结构后，最后得到的输出会将1×1卷积的结果聚集在一起，3×3卷积的结果聚集在一起，5×5卷积的结果聚集在一起，这就相当于多个密集分布的子特征集。相关性较强的特征聚集在了一起，不相关的非关键特征会被弱化，因此能够提取“纯度”更高的信息，收敛速度自然也会更快。</li><li>赫布理论，一种生物学上的概念，大概的意思是说两个神经元若总是同时兴奋，那么它们之间就会形成一种“组合”，达到相互促进的效果。应用到Inception中的解释是，训练收敛的最终目的是要提取独立特征，而Inception主动将相关性强的特征进行汇聚，从而促进这些强相关特征组合成一个个的独立特征，加速收敛。</li></ul><p>还有一点需要注意，作者认为max pooling也能起到特征提取的作用，且此处的max pooling层的stride为1，保证了池化前后的宽、高相同。</p><p><img src="Inception_Naive_20200628.png" alt="Inception_Naive" /></p><h3 id="降维inception"><a class="markdownIt-Anchor" href="#降维inception"></a> 降维Inception</h3><p>试想这么一个结构，输入尺寸为28×28×192，输出尺寸为28×28×32，通过Inception中的5×5卷积，计算需要进行乘法计算的次数。输出了28×28×32个特征点，所以总共要进行28×28×32次卷积计算，每次卷积计算需要进行的乘法次数为5×5×192，因此总共需要进行28×28×32×5×5×192~1.2亿次乘法计算。</p><p><img src="computational_cost_20200628.png" alt="computational_cost" /></p><p>仅仅一次卷积就需要进行上亿次乘法计算，即使是在今天，这个计算量仍然是不可接受的，为了解决这个问题，需要对输入进行降维，然后再进行卷积。在上面的例子终极那加入一个×1的卷积，如下图，共需要进行28×28×16×1×1×192 + 28×28×32×5×5×16 ~ 0.12亿次乘法计算，大大减少了计算量。</p><p><img src="computational_cost_with_dimensionality_reduction_20200628.png" alt="computational_cost_with_dimensionality_reduction" /></p><p>使用上述方法对Inception结构进行优化，在3×3和5×5的卷积前分别加上一个1×1的卷积，在max pooling层后面也加上一个1×1的卷积，且这些卷积后面都会加上ReLU激活函数。对于相同尺寸的感受野，叠加更多的卷积，可以得到更加丰富的特征，这是1×1卷积除降维外的另一个好处。1×1卷积是在最大池化层之后，而不是之前，这是因为：池化层是为了提取图像的原始特征，一旦它接在1×1卷积之后就失去了最初的本意。</p><p><img src="Inception_with_dimensionality_reduction_20200628.png" alt="Inception_with_dimensionality_reduction" /></p><p>这种使用卷积层来进行降维的结构也被称为“瓶颈”结构，我第一次见到这种结构是在ResNet中，当时就有些怀疑这种方法的可行性，因为将特征图从高维降到低维，必定会有信息损失，作者在文中对于这点进行了解释：“This is based on the success of embeddings: even low dimensional embeddings might contain a lot of information about a relatively large image patch.”，个人感觉这个可以理解为稀疏矩阵和稠密矩阵之间的关系，降维前特征图大，但是“无用信息”或者“弱特征信息”也很多，这种“瓶颈”结构相当于是一种对信息的压缩，以少量“弱信息”的损失来换取计算量的大幅度减少。从另一个角度来看，1×1的卷积相当于对特征图上的每一个位置的不同通道数做一次全连接，这个全连接会减少神经元的个数，从而达到压缩特征维度的作用。使用1×1卷积的思想来自于<a href="https://arxiv.org/pdf/1312.4400.pdf" target="_blank" rel="noopener">Network In Network</a>。</p><p>至此，最初版本的Inception就介绍完了，GoogLeNet就是大量Inception的拼接，后续还有许多变种，以及和ResNet结合的结构，都是基于此完成的。</p><h2 id="googlenet"><a class="markdownIt-Anchor" href="#googlenet"></a> GoogLeNet</h2><ul><li><p>了解Inception的结构之后，再看GoogLeNet的结构图就十分轻松了。整个模型使用了9个Inception结构（个别的会在上面的结构图上再加上一个max pooling层），共22层。</p></li><li><p>所有的卷积层后都会使用ReLU函数进行激活。</p></li><li><p>局部响应标准化(LRN, Local Response Normalization)请移步<a href="https://mao-jy.github.io/2020/06/27/AlexNet/#%E5%B1%80%E9%83%A8%E5%93%8D%E5%BA%94%E6%A0%87%E5%87%86%E5%8C%96lrn-local-response-normalization">这里</a>。</p></li><li><p>结构图下面附上具体的参数表，输入图片的尺寸为224×224×3。其中&quot;#3×3 reduce&quot;和&quot;#5×5 reduce&quot;的值分别表示在3×3卷积和5×5卷积之前用于降维的1×1卷积核的个数。</p></li><li><p>卷积后使用了一个平均池化层替代全连接层，大大降低了参数量。如果这里改用全连接层，则将会新增7×7×1024×1024~51M的参数量，而整个模型总共才~6.8M的参数量，这也是为什么GoogleNet有22层，但参数量却仅有AlexNet的十分之一的原因。这种以全局平均池化代替全连接的思想来自<a href="https://arxiv.org/pdf/1312.4400.pdf" target="_blank" rel="noopener">Network In Network</a>，即减少参数量，又能提高模型的可解释性。</p></li><li><p>设置三个softmax函数是为了防止梯度消失。训练过程中，计算三个loss并赋予不同的权重再相加，论文中写的是前两个辅助分类器的loss分别赋予权重0.3；预测过程中，去除前两个辅助分类器。</p></li></ul><p><img src="GoogLeNet_20200628.png" alt="GoogLeNet" /></p><p><img src="GoogLeNet_parameter_20200628.png" alt="GoogLeNet_parameter" /></p>]]></content>
      
      
      <categories>
          
          <category> 模型解析 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Deep Learning </tag>
            
            <tag> CNN </tag>
            
            <tag> CNN五大经典模型 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>AlexNet</title>
      <link href="/2020/06/27/AlexNet/"/>
      <url>/2020/06/27/AlexNet/</url>
      
        <content type="html"><![CDATA[<h1 id="概述"><a class="markdownIt-Anchor" href="#概述"></a> 概述</h1><p>AlexNet为ILSVRC-2012分类竞赛的冠军模型，达到了Top-5 15.32%的错误率。在此之前，计算机视觉方面的问题大都是使用非深度的机器学习方法，而AlexNet则把卷积神经网络带入到广大计算机视觉研究者的视野中。论文出自Hinton带领的小组，第一作者是Hinton的学生Alex，AlexNet也因此得名。</p><p>整个模型共分为8层，结构大致为：卷积-池化-卷积-池化-卷积-卷积-卷积-池化-全连接-全连接-全连接（其中卷积-池化看作1层）。模型中还加入了一些如今都在广泛使用的结构如ReLU激活函数和Dropout；也加入了一种类似于批标准化(Batch Normalization)的方法：局部响应归一化(LRN， Local Response Normalization)；比赛中还使用了些许数据增强的方法。</p><p>论文：<a href="http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf" target="_blank" rel="noopener">ImageNet Classification with Deep Convolutional Neural Networks</a></p><h1 id="网络详解"><a class="markdownIt-Anchor" href="#网络详解"></a> 网络详解</h1><p><img src="AlexNet_Andrew_Ng_20200627.png" alt="AlexNet_Andrew_Ng" /></p><p><strong>说明：由于论文中使用了两个GPU训练，结构图看起来不是特别清晰，所以选择了吴恩达深度学习课程上给出的结构图，且论文中的训练方法也有些特殊，相关介绍会在最后给出。此外，卷积层输出尺寸的计算可以使用公式<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>O</mi><mi>U</mi><mi>T</mi><mi>P</mi><mi>U</mi><mi>T</mi><mi mathvariant="normal">_</mi><mi>N</mi><mo>=</mo><mo stretchy="false">⌊</mo><mfrac><mrow><mi>I</mi><mi>N</mi><mi>P</mi><mi>U</mi><mi>T</mi><mi mathvariant="normal">_</mi><mi>N</mi><mo>+</mo><mn>2</mn><mi>P</mi><mo>−</mo><mi>K</mi></mrow><mi>S</mi></mfrac><mo stretchy="false">⌋</mo><mo>+</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">OUTPUT\_N = \lfloor \frac{INPUT\_N + 2P-K}{S} \rfloor + 1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.99333em;vertical-align:-0.31em;"></span><span class="mord mathdefault" style="margin-right:0.02778em;">O</span><span class="mord mathdefault" style="margin-right:0.10903em;">U</span><span class="mord mathdefault" style="margin-right:0.13889em;">T</span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mord mathdefault" style="margin-right:0.10903em;">U</span><span class="mord mathdefault" style="margin-right:0.13889em;">T</span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord mathdefault" style="margin-right:0.10903em;">N</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.350331em;vertical-align:-0.345em;"></span><span class="mopen">⌊</span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.005331em;"><span style="top:-2.6550000000000002em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.05764em;">S</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.527em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.07847em;">I</span><span class="mord mathdefault mtight" style="margin-right:0.10903em;">N</span><span class="mord mathdefault mtight" style="margin-right:0.13889em;">P</span><span class="mord mathdefault mtight" style="margin-right:0.10903em;">U</span><span class="mord mathdefault mtight" style="margin-right:0.13889em;">T</span><span class="mord mtight" style="margin-right:0.02778em;">_</span><span class="mord mathdefault mtight" style="margin-right:0.10903em;">N</span><span class="mbin mtight">+</span><span class="mord mtight">2</span><span class="mord mathdefault mtight" style="margin-right:0.13889em;">P</span><span class="mbin mtight">−</span><span class="mord mathdefault mtight" style="margin-right:0.07153em;">K</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose">⌋</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span></span></span></span>，其中INPUT_N为输入尺寸，OUTPUT_N为输出尺寸，P为填充尺寸，K为卷积核的尺寸，S为卷积步长。池化层输出尺寸也可用上述公式计算。</strong></p><h2 id="各层结构"><a class="markdownIt-Anchor" href="#各层结构"></a> 各层结构</h2><p>各层的详细参数上图中已经给出，不重复描述。下面给出各层的详细结构（有些东西并未在图中体现出来）：</p><ul><li><p>卷积-LRN-最大池化-ReLU</p></li><li><p>卷积-LRN-最大池化-ReLU</p></li><li><p>卷积-ReLU</p></li><li><p>卷积-ReLU</p></li><li><p>卷积-最大池化-ReLU-Flatten</p></li><li><p>全连接-ReLU-Dropout</p></li><li><p>全连接-ReLU-Dropout</p></li><li><p>全连接-softmax</p></li></ul><h2 id="模型组件"><a class="markdownIt-Anchor" href="#模型组件"></a> 模型组件</h2><p>本部分给出几个比较值得一提的模型组件，没有给出的不是因为不重要，而是概念过于常见，没有必要展开叙述。</p><h3 id="relu"><a class="markdownIt-Anchor" href="#relu"></a> ReLU</h3><p>在此之前我们会使用sigmoid或tanh作为模型的激活函数，但对于梯度下降来说，非饱和非线性的函数（如ReLU）要比饱和非线性函数快上许多。下图是论文作者在CIFAR-10数据集上进行的实验，使用了四层卷积的网络结构，其中实线表示ReLU激活函数的收敛过程，虚线表示tanh激活函数的收敛过程，同样是到达0.25的Training error rate，ReLU要比tanh快上6倍左右。且作者还指出，网络结构不同，实验结果也可能不同，但ReLU总是比饱和线性函数快上几倍。</p><p><img src="ReLU_20200627.png" alt="ReLU" /></p><p><strong>注：对于函数y=f(x)，当<span class="katex"><span class="katex-mathml"><math><semantics><mrow><munder><mo><mi>lim</mi><mo>⁡</mo></mo><mrow><mi>x</mi><mo>→</mo><mo>+</mo><mi mathvariant="normal">∞</mi></mrow></munder><msup><mi>f</mi><mo mathvariant="normal">′</mo></msup><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">\lim\limits_{x \to +\infty} f&#x27;(x) = 0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.5102229999999999em;vertical-align:-0.758331em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.69444em;"><span style="top:-2.1em;margin-left:0em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">x</span><span class="mrel mtight">→</span><span class="mord mtight">+</span><span class="mord mtight">∞</span></span></span></span><span style="top:-2.7em;"><span class="pstrut" style="height:2.7em;"></span><span><span class="mop">lim</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.758331em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.751892em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">0</span></span></span></span>时，则称函数f(x)右饱和；当<span class="katex"><span class="katex-mathml"><math><semantics><mrow><munder><mo><mi>lim</mi><mo>⁡</mo></mo><mrow><mi>x</mi><mo>→</mo><mo>−</mo><mi mathvariant="normal">∞</mi></mrow></munder><msup><mi>f</mi><mo mathvariant="normal">′</mo></msup><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">\lim\limits_{x \to -\infty} f&#x27;(x) = 0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.5102229999999999em;vertical-align:-0.758331em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.69444em;"><span style="top:-2.1em;margin-left:0em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">x</span><span class="mrel mtight">→</span><span class="mord mtight">−</span><span class="mord mtight">∞</span></span></span></span><span style="top:-2.7em;"><span class="pstrut" style="height:2.7em;"></span><span><span class="mop">lim</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.758331em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.751892em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">0</span></span></span></span>时，则称函数f(x)左饱和。当f(x)同时满足左饱和和右饱和时，则称f(x)为饱和函数。</strong></p><h3 id="局部响应标准化lrn-local-response-normalization"><a class="markdownIt-Anchor" href="#局部响应标准化lrn-local-response-normalization"></a> 局部响应标准化(LRN, Local Response Normalization)</h3><ol><li><p>对于饱和函数，需要进行标准化来使得输入尽量落在非饱和区域，加快收敛速度。而对于非饱和函数，并没有这种需要，但实验表明LRN仍有助于泛化。LRN的公式为：</p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msubsup><mi>b</mi><mrow><mi>x</mi><mo separator="true">,</mo><mi>y</mi></mrow><mi>i</mi></msubsup><mo>=</mo><msubsup><mi>a</mi><mrow><mi>x</mi><mo separator="true">,</mo><mi>y</mi></mrow><mi>i</mi></msubsup><mi mathvariant="normal">/</mi><mo stretchy="false">(</mo><mi>k</mi><mo>+</mo><mi>α</mi><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mi>m</mi><mi>a</mi><mi>x</mi><mo stretchy="false">(</mo><mn>0</mn><mo separator="true">,</mo><mi>i</mi><mo>−</mo><mi>n</mi><mi mathvariant="normal">/</mi><mn>2</mn><mo stretchy="false">)</mo></mrow><mrow><mi>m</mi><mi>i</mi><mi>n</mi><mo stretchy="false">(</mo><mi>N</mi><mo>−</mo><mn>1</mn><mo separator="true">,</mo><mi>i</mi><mo>+</mo><mi>n</mi><mi mathvariant="normal">/</mi><mn>2</mn><mo stretchy="false">)</mo></mrow></munderover><mo stretchy="false">(</mo><msubsup><mi>a</mi><mrow><mi>x</mi><mo separator="true">,</mo><mi>y</mi></mrow><mi>j</mi></msubsup><msup><mo stretchy="false">)</mo><mn>2</mn></msup><msup><mo stretchy="false">)</mo><mi>β</mi></msup></mrow><annotation encoding="application/x-tex">b_{x, y}^{i} = a_{x, y}^{i} / (k + \alpha \sum_{j = max(0, i - n / 2)}^{min(N - 1, i + n / 2)} (a_{x, y}^{j})^2)^{\beta}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.2577720000000001em;vertical-align:-0.383108em;"></span><span class="mord"><span class="mord mathdefault">b</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.874664em;"><span style="top:-2.4530000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">x</span><span class="mpunct mtight">,</span><span class="mord mathdefault mtight" style="margin-right:0.03588em;">y</span></span></span></span><span style="top:-3.1130000000000004em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.383108em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.2577720000000001em;vertical-align:-0.383108em;"></span><span class="mord"><span class="mord mathdefault">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.874664em;"><span style="top:-2.4530000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">x</span><span class="mpunct mtight">,</span><span class="mord mathdefault mtight" style="margin-right:0.03588em;">y</span></span></span></span><span style="top:-3.1130000000000004em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.383108em;"><span></span></span></span></span></span></span><span class="mord">/</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.03148em;">k</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:3.4770100000000004em;vertical-align:-1.5160049999999998em;"></span><span class="mord mathdefault" style="margin-right:0.0037em;">α</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.9610050000000006em;"><span style="top:-1.8089950000000001em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span><span class="mrel mtight">=</span><span class="mord mathdefault mtight">m</span><span class="mord mathdefault mtight">a</span><span class="mord mathdefault mtight">x</span><span class="mopen mtight">(</span><span class="mord mtight">0</span><span class="mpunct mtight">,</span><span class="mord mathdefault mtight">i</span><span class="mbin mtight">−</span><span class="mord mathdefault mtight">n</span><span class="mord mtight">/</span><span class="mord mtight">2</span><span class="mclose mtight">)</span></span></span></span><span style="top:-3.050005em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.386005em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">m</span><span class="mord mathdefault mtight">i</span><span class="mord mathdefault mtight">n</span><span class="mopen mtight">(</span><span class="mord mathdefault mtight" style="margin-right:0.10903em;">N</span><span class="mbin mtight">−</span><span class="mord mtight">1</span><span class="mpunct mtight">,</span><span class="mord mathdefault mtight">i</span><span class="mbin mtight">+</span><span class="mord mathdefault mtight">n</span><span class="mord mtight">/</span><span class="mord mtight">2</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.5160049999999998em;"><span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.874664em;"><span style="top:-2.4530000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">x</span><span class="mpunct mtight">,</span><span class="mord mathdefault mtight" style="margin-right:0.03588em;">y</span></span></span></span><span style="top:-3.1130000000000004em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.383108em;"><span></span></span></span></span></span></span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8641079999999999em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8991079999999999em;"><span style="top:-3.1130000000000004em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.05278em;">β</span></span></span></span></span></span></span></span></span></span></span></span></span></p></li><li><p>其中<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msubsup><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mi>m</mi><mi>a</mi><mi>x</mi><mo stretchy="false">(</mo><mn>0</mn><mo separator="true">,</mo><mi>i</mi><mo>−</mo><mi>n</mi><mi mathvariant="normal">/</mi><mn>2</mn><mo stretchy="false">)</mo></mrow><mrow><mi>m</mi><mi>i</mi><mi>n</mi><mo stretchy="false">(</mo><mi>N</mi><mo>−</mo><mn>1</mn><mo separator="true">,</mo><mi>i</mi><mo>+</mo><mi>n</mi><mi mathvariant="normal">/</mi><mn>2</mn><mo stretchy="false">)</mo></mrow></msubsup><mo stretchy="false">(</mo><msubsup><mi>a</mi><mrow><mi>x</mi><mo separator="true">,</mo><mi>y</mi></mrow><mi>j</mi></msubsup><msup><mo stretchy="false">)</mo><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">\sum_{j = max(0, i - n / 2)}^{min(N - 1, i + n / 2)} (a_{x, y}^{j})^2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.5599999999999998em;vertical-align:-0.5151999999999999em;"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:-0.0000050000000000050004em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.0448em;"><span style="top:-2.3598em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span><span class="mrel mtight">=</span><span class="mord mathdefault mtight">m</span><span class="mord mathdefault mtight">a</span><span class="mord mathdefault mtight">x</span><span class="mopen mtight">(</span><span class="mord mtight">0</span><span class="mpunct mtight">,</span><span class="mord mathdefault mtight">i</span><span class="mbin mtight">−</span><span class="mord mathdefault mtight">n</span><span class="mord mtight">/</span><span class="mord mtight">2</span><span class="mclose mtight">)</span></span></span></span><span style="top:-3.2198em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">m</span><span class="mord mathdefault mtight">i</span><span class="mord mathdefault mtight">n</span><span class="mopen mtight">(</span><span class="mord mathdefault mtight" style="margin-right:0.10903em;">N</span><span class="mbin mtight">−</span><span class="mord mtight">1</span><span class="mpunct mtight">,</span><span class="mord mathdefault mtight">i</span><span class="mbin mtight">+</span><span class="mord mathdefault mtight">n</span><span class="mord mtight">/</span><span class="mord mtight">2</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.5151999999999999em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.824664em;"><span style="top:-2.4530000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">x</span><span class="mpunct mtight">,</span><span class="mord mathdefault mtight" style="margin-right:0.03588em;">y</span></span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.383108em;"><span></span></span></span></span></span></span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span>是对于同一位置，不同卷积核得到的卷积值（以当前核为中心，取前后各<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>n</mi><mi mathvariant="normal">/</mi><mn>2</mn></mrow><annotation encoding="application/x-tex">n / 2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault">n</span><span class="mord">/</span><span class="mord">2</span></span></span></span>个卷积值）的平方进行求和。几个超参数的设置为<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>k</mi><mo>=</mo><mn>2</mn><mo separator="true">,</mo><mi>n</mi><mo>−</mo><mn>5</mn><mo separator="true">,</mo><mi>α</mi><mo>=</mo><mn>1</mn><msup><mn>0</mn><mrow><mo>−</mo><mn>4</mn></mrow></msup><mo separator="true">,</mo><mi>b</mi><mi>e</mi><mi>t</mi><mi>a</mi><mo>=</mo><mn>0.75</mn></mrow><annotation encoding="application/x-tex">k=2, n-5, \alpha=10^{-4}, beta=0.75</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.03148em;">k</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.8388800000000001em;vertical-align:-0.19444em;"></span><span class="mord">2</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault">n</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.8388800000000001em;vertical-align:-0.19444em;"></span><span class="mord">5</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.0037em;">α</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.008548em;vertical-align:-0.19444em;"></span><span class="mord">1</span><span class="mord"><span class="mord">0</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mord mtight">4</span></span></span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault">b</span><span class="mord mathdefault">e</span><span class="mord mathdefault">t</span><span class="mord mathdefault">a</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">0</span><span class="mord">.</span><span class="mord">7</span><span class="mord">5</span></span></span></span>，这些值是在验证集上得出的。LRN相当于一种局部神经元之间的竞争机制，响应比较大的值会变得相对更大，同时横向抑制响应较小的值，以此提高泛化能力。在ImageNet数据集上，这个方法能减少top-1 1.4%，top-5 1.2%的错误率，在CIFAR-10数据集上能减少2%左右的错误率。</p></li></ol><h3 id="重叠池化"><a class="markdownIt-Anchor" href="#重叠池化"></a> 重叠池化</h3><p>不同于传统的池化，AlexNet中使用的池化层步长小于池化窗口，这就使得池化窗口会出现重叠的情况，这种方法降低了top-1 0.4%和top-5 0.3%的错误率，但是重叠池化可能存在难以拟合的情况。</p><h3 id="dropout"><a class="markdownIt-Anchor" href="#dropout"></a> Dropout</h3><p>为了防止过拟合，使用了Dropout(0.5)，这种技术降低了神经元之间复杂的“相互协作”，但同时也会减缓拟合速度。</p><h1 id="附录论文中的网络结构"><a class="markdownIt-Anchor" href="#附录论文中的网络结构"></a> 附录：论文中的网络结构</h1><p><img src="AlexNet_20200627.png" alt="AlexNet" /></p><ul><li>论文中的网络结构和前面的网络结构大体相似，但有些细节不同，而且由于使用了双GPU进行运算，网络结构中有些地方也是为了进行并行运算，所以图片看起来有些复杂。上面缺少的部分不是截图少截了，而是论文中的原图就是如此。</li><li>论文中模型图有个错误，输入尺寸标为224×224×3，但实际上应该是227×227×3，这是如今主流的解释。个人理解为，如果不进行pad，那么输入必须是227×227×3才能与卷积后的尺寸对应；如果令pad=3，那么输入为224×224×3就可以和卷积后尺寸对应。</li><li>图中的第二层卷积，其输入并不是第一层输出的全部96层特征层，而是每块GPU以自身的48个特征图作为输入，分别运算。图中的第四、五层卷积与第二层卷积相同，都是以自身所在GPU的特征层作为输入，而不是以上一层的全部特征层作为输入。</li></ul>]]></content>
      
      
      <categories>
          
          <category> 模型解析 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Deep Learning </tag>
            
            <tag> CNN </tag>
            
            <tag> CNN五大经典模型 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>LeNet-5</title>
      <link href="/2020/06/26/LeNet-5/"/>
      <url>/2020/06/26/LeNet-5/</url>
      
        <content type="html"><![CDATA[<h1 id="概述"><a class="markdownIt-Anchor" href="#概述"></a> 概述</h1><p>LeNet-5又被成为LetNet，诞生于1998年，是第一个典型的卷积神经网络。LeNet共包含七层（不含输入层），每一层都包含可训练参数。网络结构大致为：输入-卷积-池化-卷积-池化-卷积-全连接-全连接。而如果将卷积和池化看作一层，则整个网络正好有五层。</p><p>论文：<a href="https://d1wqtxts1xzle7.cloudfront.net/61181394/Gradient_Based_Learning_Lecun20191110-2628-k1dtd1.pdf?1573449385=&amp;response-content-disposition=inline%3B+filename%3DGradient_Based_Learning_Lecun.pdf&amp;Expires=1593245349&amp;Signature=S6BzrdDamkQho9CLVhDsmsXpbUjsEZYUmnpMi6cBRZ~Aam8sXp7HTIJgicCelNYsaG~djv0bCVQ~HmTU6IftTnLjUnIWJIEsW5ncWWb9ShqC3gN8DepQm~qKMD~uTNTBlIkyOQ-Vc57iNVIiJjZonYtsnl7EKzJYBoXWvm3DXB4itj2HuZk0ury1Gj3DSZel8Z5w2HlPDJZeMcpBWkqeyZY-0fvoYgZh-vAmmFpnwgShPMGgnFM~or~gBIpzUITj8bpY22XZRpCHOHOoUdj-Ai1Jl~CUtw4hhlJDK~7fJfsgSRN7oqzBgk1yXeLFkqlNUpOxR5FHvJiulRNC4d7OOw__&amp;Key-Pair-Id=APKAJLOHF5GGSLRBV4ZA" target="_blank" rel="noopener">Gradient-based learning applied to document recognition</a></p><h1 id="网络详解"><a class="markdownIt-Anchor" href="#网络详解"></a> 网络详解</h1><p><img src="LeNet_20200626.png" alt="LeNet" /></p><p><strong>说明：C表示卷积层，S表示下采样层（池化层），F表示全连接层，数字表示该层在整个网络中位于第几层。</strong></p><h2 id="input层-输入层"><a class="markdownIt-Anchor" href="#input层-输入层"></a> INPUT层-输入层</h2><p>输入图片尺寸为(32, 32, 1)，这个尺寸比数据集中最大的字符都要大，原因是后面的两次卷积是valid方式（pad=0），所以经过两次卷积后的特征图上的所有像素对应初始输入图片的一系列感受野的中心只有20×20大小的区域。上面是论文中的说法，具体的操作方法是：将小图片通过类似于padding的方式变成32×32图片（具体怎么变成32×32这个尺寸论文中并未提及，直接padding是我认为最合理的方式，用以应对卷积层的边界效应），然后进行标准化，送入后面的卷积层。</p><h2 id="c1层-卷积层"><a class="markdownIt-Anchor" href="#c1层-卷积层"></a> C1层-卷积层</h2><ul><li>输入：(32, 32, 1)</li><li>输出：(28, 28, 6)</li><li>卷积核大小：(5, 5)</li><li>卷积核个数：6</li><li>步长：1</li><li>padding: valid</li><li>参数量：(5 × 5 + 1) × 6 = 156</li></ul><h2 id="s2层-池化层下采样层"><a class="markdownIt-Anchor" href="#s2层-池化层下采样层"></a> S2层-池化层（下采样层）</h2><ul><li>输入：(28, 28, 6)</li><li>输入：(14, 14, 6)</li><li>池化窗口：(2, 2)</li><li>池化方式：将2×2窗口四个数字相加，乘以权重，加上偏置，最后使用sigmoid函数激活。</li><li>参数量：(1 + 1) × 6 = 12</li></ul><h2 id="c3层-卷积层"><a class="markdownIt-Anchor" href="#c3层-卷积层"></a> C3层-卷积层</h2><ul><li><p>输入：(14, 14, 6)</p></li><li><p>输出：(10, 10, 16)</p></li><li><p>卷积核大小：(5, 5)</p></li><li><p>卷积核个数：6, 6, 3, 1</p></li><li><p>步长：1</p></li><li><p>padding: valid</p></li><li><p>卷积方式：本层的卷积方式比较特殊，输入的特征图（即S2的输出，后面用S2作为简写）共有6个特征层，输出的特征图共有16个特征层。前6个特征层以S2连续的3个特征层作为输入，接下来6个特征层以S2连续的4个特征层作为输入，再往后的3个特征层以S2的不连续的4个特征层作为输入，最后的1个特征层以S2的连续的6个特征层（即S2所有特征层）作为输入。上述描述比较抽象，看下面的图，行表头表示输入的层（共有6层），列表头表示输出的特征层（共有16层），第0个输出特征层以第0, 1, 2个输入特征层作为输入，进行卷积；第11个输出特征层以第0, 1, 4, 5个输入特征层作为输入进行卷积。</p></li></ul><p><img src="LeNet_C3_20200626.png" alt="LeNet_C3" /></p><ul><li>参数量：(5 × 5 × 3 +1) × 6 + (5 × 5 × 4 + 1) × 6 + (5 × 5 × 4 + 1) × 3 + (5 × 5 × 6 + 1) × 1 = 456 + 606 + 303 + 151 = 1516</li></ul><h2 id="s4层-池化层下采样层"><a class="markdownIt-Anchor" href="#s4层-池化层下采样层"></a> S4层-池化层（下采样层）</h2><ul><li>输入：(10, 10, 16)</li><li>输出：(5, 5, 16)</li><li>池化窗口：(2, 2)</li><li>激活函数：sigmoid</li><li>池化方式：与C2相同，将2×2窗口四个数字相加，乘以权重，加上偏置。</li><li>参数量：(1 + 1) × 16 = 32</li></ul><h2 id="c5-卷积层"><a class="markdownIt-Anchor" href="#c5-卷积层"></a> C5-卷积层</h2><ul><li>输入：(5, 5, 16)</li><li>输出：(1, 1, 120)</li><li>卷积核大小：(5, 5)</li><li>卷积核个数：120</li><li>步长：1</li><li>padding: valid</li><li>卷积方式：正常卷积方式，但是这里的卷积核宽、高正好与输入的宽、高相同，所以起到了和全连接层等同的作用。</li><li>参数量：(5 × 5 × 16 + 1) × 120 = 48120</li></ul><h2 id="f6层-全连接层"><a class="markdownIt-Anchor" href="#f6层-全连接层"></a> F6层-全连接层</h2><ul><li>输入：120</li><li>输出：84</li><li>参数量：(120 + 1) × 84 = 10164</li><li>激活函数：使用sigmoid激活函数。</li></ul><h2 id="输出层-全连接层"><a class="markdownIt-Anchor" href="#输出层-全连接层"></a> 输出层-全连接层</h2><p>输出层使用的也是全连接的方式，共有10个节点，代表0~9，节点值与0越接近，则其对应数字的得分越高。10个节点值的计算方法并不是正常全连接层的输入乘以权重再加上偏置，而是使用径向基函数（RBF）的方式，计算公式为：</p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>y</mi><mi>i</mi></msub><mo>=</mo><munder><mo>∑</mo><mi>j</mi></munder><mo stretchy="false">(</mo><msub><mi>x</mi><mi>j</mi></msub><mo>−</mo><msub><mi>w</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub><msup><mo stretchy="false">)</mo><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">y_{i} = \sum_{j}(x_{j} - w_{ij})^{2}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.463782em;vertical-align:-1.413777em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.050005em;"><span style="top:-1.8723309999999997em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span></span></span></span><span style="top:-3.0500049999999996em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.413777em;"><span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.150216em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8641079999999999em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span></span></span></p><p>上式<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>y</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">y_{i}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>表示第<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>i</mi><mo stretchy="false">(</mo><mn>0</mn><mo>⩽</mo><mi>i</mi><mo>⩽</mo><mn>9</mn><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">i(0 \leqslant  i \leqslant  9)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault">i</span><span class="mopen">(</span><span class="mord">0</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel amsrm">⩽</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.79619em;vertical-align:-0.13667em;"></span><span class="mord mathdefault">i</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel amsrm">⩽</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">9</span><span class="mclose">)</span></span></span></span>个输出，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>x</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">x_{j}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.716668em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span>表示第<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>j</mi><mo stretchy="false">(</mo><mn>0</mn><mo>⩽</mo><mi>j</mi><mo>⩽</mo><mn>83</mn><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">j(0 \leqslant  j \leqslant  83)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.05724em;">j</span><span class="mopen">(</span><span class="mord">0</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel amsrm">⩽</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.85396em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.05724em;">j</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel amsrm">⩽</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">8</span><span class="mord">3</span><span class="mclose">)</span></span></span></span>个输入，选择与0距离最近的y<sub>i</sub>对应的i值作为最终预测结果。</p><h1 id="附录"><a class="markdownIt-Anchor" href="#附录"></a> 附录</h1><p>最后分享一个看起来比较直观的<a href="https://www.cs.ryerson.ca/~aharley/vis/conv/" target="_blank" rel="noopener">LeNet可视化项目</a>。</p>]]></content>
      
      
      <categories>
          
          <category> 模型解析 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Deep Learning </tag>
            
            <tag> CNN </tag>
            
            <tag> CNN五大经典模型 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>《python深度学习》阅读记录（代码向） Part 1</title>
      <link href="/2020/06/24/python-dl-reading-log-1/"/>
      <url>/2020/06/24/python-dl-reading-log-1/</url>
      
        <content type="html"><![CDATA[<h1 id="二分类"><a class="markdownIt-Anchor" href="#二分类"></a> 二分类</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> models, layers</span><br><span class="line"></span><br><span class="line">model = models.Sequential()</span><br><span class="line">model.add(layers.Dense(<span class="number">16</span>, activation=<span class="string">'relu'</span>, input_shape=(<span class="number">10000</span>,)))</span><br><span class="line">model.add(layers.Dense(<span class="number">16</span>, activation=<span class="string">'relu'</span>))</span><br><span class="line">model.add(layers.Dense(<span class="number">1</span>, activation=<span class="string">'sigmoid'</span>))</span><br><span class="line"></span><br><span class="line">model.compile(optimizer=<span class="string">'rmsprop'</span>, </span><br><span class="line">              loss=<span class="string">'binary_crossentropy'</span>, </span><br><span class="line">              metrics=[<span class="string">'accuracy'</span>])</span><br><span class="line"></span><br><span class="line">model.fit(x_train, y_train, epochs=<span class="number">4</span>, batch_size=<span class="number">512</span>)</span><br><span class="line"></span><br><span class="line">results = model.evaluate(x_test, y_test)</span><br></pre></td></tr></table></figure><p><strong>备注：</strong></p><ol><li><p>model.compile还可以写成下面的形式(三个组件也可以是自己定义方法)：</p> <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> optimizers, losses, metrics</span><br><span class="line">model.compile(optimizer=optimizers.RMSprop(lr=<span class="number">0.001</span>), </span><br><span class="line">              loss=losses.binary_crossentropy, </span><br><span class="line">              metrics=[metrics.binary_accuracy])</span><br></pre></td></tr></table></figure></li><li><p>画图</p> <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">loss_values = history_dict[<span class="string">'loss'</span>]</span><br><span class="line">val_loss_values = history_dict[<span class="string">'val_loss'</span>]</span><br><span class="line"></span><br><span class="line">epochs = range(<span class="number">1</span>, len(loss_values) + <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">plt.plot(epochs, loss_values, <span class="string">'bo'</span>, label=<span class="string">'Training loss'</span>)</span><br><span class="line">plt.plot(epochs, val_loss_values, <span class="string">'b'</span>, label=<span class="string">'Validation loss'</span>)</span><br><span class="line">plt.title(<span class="string">'Training and validation loss'</span>)</span><br><span class="line">plt.xlabel(<span class="string">'Epoch'</span>)</span><br><span class="line">plt.ylabel(<span class="string">'Loss'</span>)</span><br><span class="line">plt.legend()</span><br><span class="line"></span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">plt.clf()<span class="comment"># 清空图像，这里也可以使用plt.figure()来创建一个新的图</span></span><br><span class="line"></span><br><span class="line">acc = history_dict[<span class="string">'accuracy'</span>]</span><br><span class="line">val_acc = history_dict[<span class="string">'val_accuracy'</span>]</span><br><span class="line"></span><br><span class="line">plt.plot(epochs, acc, <span class="string">'bo'</span>, label=<span class="string">'Training acc'</span>)</span><br><span class="line">plt.plot(epochs, val_acc, <span class="string">'b'</span>, label=<span class="string">'Validation acc'</span>)</span><br><span class="line">plt.title(<span class="string">'Training and validation acc'</span>)</span><br><span class="line">plt.xlabel(<span class="string">'Epoch'</span>)</span><br><span class="line">plt.ylabel(<span class="string">'Loss'</span>)</span><br><span class="line">plt.legend()</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></li></ol><br><h1 id="多分类"><a class="markdownIt-Anchor" href="#多分类"></a> 多分类</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> (models, layers)</span><br><span class="line"></span><br><span class="line">model = models.Sequential()</span><br><span class="line">model.add(layers.Dense(<span class="number">64</span>, activation=<span class="string">'relu'</span>, input_shape=(<span class="number">10000</span>,)))</span><br><span class="line">model.add(layers.Dense(<span class="number">64</span>, activation=<span class="string">'relu'</span>))</span><br><span class="line">model.add(layers.Dense(<span class="number">46</span>, activation=<span class="string">'softmax'</span>))</span><br><span class="line"></span><br><span class="line">model.compile(optimizer=<span class="string">'rmsprop'</span>, </span><br><span class="line">          loss=<span class="string">'categorical_crossentropy'</span>, </span><br><span class="line">          metrics=[<span class="string">'accuracy'</span>])</span><br><span class="line"></span><br><span class="line">model.fit(partial_x_train, </span><br><span class="line">          partial_y_train, </span><br><span class="line">          epochs=<span class="number">9</span>, </span><br><span class="line">          batch_size=<span class="number">512</span>, </span><br><span class="line">          validation_data=(x_val, y_val))</span><br><span class="line"></span><br><span class="line">results = model.evaluate(x_test, one_hot_y_test)</span><br><span class="line"></span><br><span class="line">predictions = model.predict(x_test[<span class="number">0</span>])</span><br><span class="line">np.argmax(predictions[<span class="number">0</span>])</span><br></pre></td></tr></table></figure><p><strong>备注：</strong></p><ol><li>keras.utils.np_utils.to_categorical  将类别标签转换成one-hot标签</li><li>对于多分类问题，将target转换成one-hot损失函数为categorical_crossentropy，若不转换，损失函数为sparse_categorical_crossentropy</li><li>如果减小中间层的神经元个数，会造成信息瓶颈，降低最终的精度上限</li></ol><br><h1 id="回归"><a class="markdownIt-Anchor" href="#回归"></a> 回归</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> models, layers</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">build_model</span><span class="params">()</span>:</span></span><br><span class="line">    model = models.Sequential()</span><br><span class="line">    model.add(layers.Dense(<span class="number">64</span>, activation=<span class="string">'relu'</span>, input_shape=(<span class="number">13</span>,)))</span><br><span class="line">    model.add(layers.Dense(<span class="number">64</span>, activation=<span class="string">'relu'</span>))</span><br><span class="line">    model.add(layers.Dense(<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">    model.compile(optimizer=<span class="string">'rmsprop'</span>, loss=<span class="string">'mse'</span>, metrics=[<span class="string">'mae'</span>])</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> model</span><br><span class="line"></span><br><span class="line">model.fit(train_data, </span><br><span class="line">          train_labels, </span><br><span class="line">          epochs=<span class="number">80</span>,</span><br><span class="line">          batch_size=<span class="number">16</span>,</span><br><span class="line">          verbose=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">test_mse, test_mae = model.evaluate(test_data, test_labels)</span><br></pre></td></tr></table></figure><p><strong>备注：</strong></p><ol><li><p>回归问题常用的损失函数是均方误差(MSE)，常见回归指标是平均绝对误差(MAE)</p></li><li><p>数据过少，隐藏层也应该较少，否则容易过拟合</p></li><li><p>数据具有不同的取值范围(如房价预测问题)，应该进行预处理，对每个特征单独进行缩放</p></li><li><p>使用K折交叉验证原因：数据点少，验证集会非常小，验证分数可能会有很大波动（验证分数方差很大），这样就无法进行可靠评估。而当数据集非常小并且对模型评估的准确性有要求时，应该使用重复的K折交叉验证。</p></li><li><p>models.fit和models.evaluate都有verbose属性，用于控制输出到控制台上的信息。verbose=0不会输出任何信息，verbose=1为每个epoch输出一个进度条，verbose=2为每个epoch输出一行记录，默认为1，models.fit可以设置为0, 1, 2，models.evaluate可以设置为0, 1两个数值。</p></li><li><p>models.fit中加入validation_data=(val_data, val_targets)，则返回的值中会包含验证机集每个epoch的loss和metrics，即两个列表，这无疑会增加时耗；models.evaluate会返回最终训练出来的模型在验证集上的loss和metrics。后者分别是前者列表的最后一个值</p></li><li><p>曲线(如loss曲线)平滑方法：指数移动平均值</p> <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">smooth_curve</span><span class="params">(points, factor=<span class="number">0.9</span>)</span>:</span></span><br><span class="line">    smoothed_points = []</span><br><span class="line">    <span class="keyword">for</span> point <span class="keyword">in</span> points:</span><br><span class="line">        <span class="keyword">if</span> smoothed_points:</span><br><span class="line">            smoothed_points.append(smoothed_points[<span class="number">-1</span>] * factor + point * (<span class="number">1</span> - factor))</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            smoothed_points.append(point)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> smoothed_points</span><br></pre></td></tr></table></figure></li></ol><br><h1 id="过拟合"><a class="markdownIt-Anchor" href="#过拟合"></a> 过拟合</h1><h2 id="正则化"><a class="markdownIt-Anchor" href="#正则化"></a> 正则化</h2><p>只在训练时加入，所以训练集loss会高于验证集loss，为了让权重值不会过大，也可以理解为抑制单个权重的重要性</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> regularizers</span><br><span class="line"></span><br><span class="line">model = models.Sequential()</span><br><span class="line">model.add(layers.Dense(<span class="number">16</span>, kernel_regularizer=regularizers.l2(<span class="number">0.001</span>),</span><br><span class="line">       activation=<span class="string">'relu'</span>, input_shape=(<span class="number">1000</span>,)))</span><br><span class="line">model.add(layers.Dense(<span class="number">16</span>, kernel_regularizer=regularizers.l2(<span class="number">0.001</span>),</span><br><span class="line">                     activation=<span class="string">'relu'</span>))</span><br><span class="line">model.add(layers.Dense(<span class="number">1</span>, activation=<span class="string">'sigmoid'</span>))</span><br></pre></td></tr></table></figure><p><strong>备注：</strong></p><ol><li>l1正则化：regularizers.l1(0.001)<br />l2正则化：regularizers.l2(0.001)<br />同时做l1和l2正则化：regularizers.l1_l2(l1=0.001, l2=0.001)</li></ol><h2 id="dropout"><a class="markdownIt-Anchor" href="#dropout"></a> Dropout</h2><p>dropout比率通常处于0.2~0.5范围内，某层权重值之间可能存在某种协作关系，这种协作关系会学习到某些不显著的偶然模式，加入dropout相当于打破这种可能的协作关系，也可以理解为在某层的输出值中加入噪声<br />训练时，对于某层的每个输出，以dropout_ratio为几率将该输出置零，然后将剩余层的值除以drop_ratio；预测时，将该层的所有输出乘drop_ratio，以此达到降低过拟合的效果</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">model = models.Sequential()</span><br><span class="line">model.add(layers.Dense(<span class="number">16</span>, activation=<span class="string">'relu'</span>, input_shape=(<span class="number">10000</span>,)))</span><br><span class="line">model.add(layers.Dropout(<span class="number">0.5</span>))</span><br><span class="line">model.add(layers.Dense(<span class="number">16</span>, activation=<span class="string">'relu'</span>))</span><br><span class="line">model.add(layers.Dropout(<span class="number">0.5</span>))</span><br><span class="line">model.add(layers.Dense(<span class="number">1</span>, activation=<span class="string">'sigmoid'</span>))</span><br></pre></td></tr></table></figure><h2 id="总结"><a class="markdownIt-Anchor" href="#总结"></a> 总结</h2><p>降低过拟合的常用方法：</p><ol><li>更多训练数据</li><li>减小网络容量</li><li>正则化</li><li>dropout</li></ol>]]></content>
      
      
      <categories>
          
          <category> 阅读记录 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Deep Learning </tag>
            
            <tag> Python </tag>
            
            <tag> Keras </tag>
            
            <tag> Tensorflow </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
