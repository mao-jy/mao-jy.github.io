<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>AlexNet | Jeff_M</title><meta name="description" content="概述 AlexNet为ILSVRC-2012分类竞赛的冠军模型，达到了Top-5 15.32%的错误率。在此之前，计算机视觉方面的问题大都是使用非深度的机器学习方法，而AlexNet则把卷积神经网络带入到广大计算机视觉研究者的视野中。论文出自Hinton带领的小组，第一作者是Hinton的学生Alex，AlexNet也因此得名。 整个模型共分为8层，结构大致为：卷积-池化-卷积-池化-卷积-卷积"><meta name="keywords" content="Deep Learning,CNN,CNN五大经典模型"><meta name="author" content="Jeff_M"><meta name="copyright" content="Jeff_M"><meta name="format-detection" content="telephone=no"><link rel="shortcut icon" href="/img/favicon.jpg"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="dns-prefetch" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="https://hm.baidu.com"/><link rel="dns-prefetch" href="https://hm.baidu.com"/><link rel="preconnect" href="https://fonts.googleapis.com" crossorigin="crossorigin"/><link rel="dns-prefetch" href="https://fonts.googleapis.com"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="dns-prefetch" href="//busuanzi.ibruce.info"/><meta name="baidu-site-verification" content="AoyFE4i7Ib"/><meta name="twitter:card" content="summary"><meta name="twitter:title" content="AlexNet"><meta name="twitter:description" content="概述 AlexNet为ILSVRC-2012分类竞赛的冠军模型，达到了Top-5 15.32%的错误率。在此之前，计算机视觉方面的问题大都是使用非深度的机器学习方法，而AlexNet则把卷积神经网络带入到广大计算机视觉研究者的视野中。论文出自Hinton带领的小组，第一作者是Hinton的学生Alex，AlexNet也因此得名。 整个模型共分为8层，结构大致为：卷积-池化-卷积-池化-卷积-卷积"><meta name="twitter:image" content="http://mao-jy.github.io/AlexNet_Andrew_Ng_20200627.png"><meta property="og:type" content="article"><meta property="og:title" content="AlexNet"><meta property="og:url" content="http://mao-jy.github.io/2020/06/27/AlexNet/"><meta property="og:site_name" content="Jeff_M"><meta property="og:description" content="概述 AlexNet为ILSVRC-2012分类竞赛的冠军模型，达到了Top-5 15.32%的错误率。在此之前，计算机视觉方面的问题大都是使用非深度的机器学习方法，而AlexNet则把卷积神经网络带入到广大计算机视觉研究者的视野中。论文出自Hinton带领的小组，第一作者是Hinton的学生Alex，AlexNet也因此得名。 整个模型共分为8层，结构大致为：卷积-池化-卷积-池化-卷积-卷积"><meta property="og:image" content="http://mao-jy.github.io/AlexNet_Andrew_Ng_20200627.png"><meta property="article:published_time" content="2020-06-27T06:57:50.000Z"><meta property="article:modified_time" content="2020-07-04T13:44:41.161Z"><script src="https://cdn.jsdelivr.net/npm/js-cookie/dist/js.cookie.min.js"></script><script>var autoChangeMode = 'false'
var t = Cookies.get("theme")
if (autoChangeMode == '1'){
  var isDarkMode = window.matchMedia("(prefers-color-scheme: dark)").matches
  var isLightMode = window.matchMedia("(prefers-color-scheme: light)").matches
  var isNotSpecified = window.matchMedia("(prefers-color-scheme: no-preference)").matches
  var hasNoSupport = !isDarkMode && !isLightMode && !isNotSpecified

  if (t === undefined){
    if (isLightMode) activateLightMode()
    else if (isDarkMode) activateDarkMode()
    else if (isNotSpecified || hasNoSupport){
      console.log('You specified no preference for a color scheme or your browser does not support it. I Schedule dark mode during night time.')
      var now = new Date()
      var hour = now.getHours()
      var isNight = hour < 6 || hour >= 18
      isNight ? activateDarkMode() : activateLightMode()
  }
  } else if (t == 'light') activateLightMode()
  else activateDarkMode()

} else if (autoChangeMode == '2'){
  now = new Date();
  hour = now.getHours();
  isNight = hour < 6 || hour >= 18
  if(t === undefined) isNight? activateDarkMode() : activateLightMode()
  else if (t === 'light') activateLightMode()
  else activateDarkMode() 
} else {
  if ( t == 'dark' ) activateDarkMode()
  else if ( t == 'light') activateLightMode()
}

function activateDarkMode(){
  document.documentElement.setAttribute('data-theme', 'dark')
  if (document.querySelector('meta[name="theme-color"]') !== null){
    document.querySelector('meta[name="theme-color"]').setAttribute('content','#000')
  }
}
function activateLightMode(){
  document.documentElement.setAttribute('data-theme', 'light')
  if (document.querySelector('meta[name="theme-color"]') !== null){
  document.querySelector('meta[name="theme-color"]').setAttribute('content','#fff')
  }
}</script><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@latest/css/font-awesome.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.css"><link rel="canonical" href="http://mao-jy.github.io/2020/06/27/AlexNet/"><link rel="prev" title="GoogLeNet" href="http://mao-jy.github.io/2020/06/28/GoogLeNet/"><link rel="next" title="LeNet-5" href="http://mao-jy.github.io/2020/06/26/LeNet-5/"><script>var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?a7f76f8d587b417aa8c72343706a229e";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Titillium+Web"><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"找不到您查询的内容:${query}"}},
  translate: {"defaultEncoding":2,"translateDelay":0,"cookieDomain":"https://xxx/","msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"簡"},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  bookmark: {
    message_prev: '按',
    message_next: '键将本页加入书签'
  },
  runtime_unit: '天',
  runtime: true,
  copyright: {"languages":{"author":"作者: Jeff_M","link":"链接: ","source":"来源: Jeff_M","info":"著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。"}},
  ClickShowText: undefined,
  medium_zoom: false,
  fancybox: true,
  Snackbar: {"bookmark":{"message_prev":"按","message_next":"键将本页加入书签"},"chs_to_cht":"你已切换为繁体","cht_to_chs":"你已切换为简体","day_to_night":"你已切换为深色模式","night_to_day":"你已切换为浅色模式","bgLight":"#49b1f5","bgDark":"#2d3035","position":"bottom-left"},
  baiduPush: false,
  highlightCopy: true,
  highlightLang: true,
  highlightShrink: 'false',
  isFontAwesomeV5: false,
  isPhotoFigcaption: false,
  islazyload: false,
  isanchor: true
  
}</script><link rel="stylesheet" href="/css/footer.min.css"><script>jsdelivr_url = "https://cdn.jsdelivr.net/gh/mao-jy/mao-jy.github.io/"</script><script>var GLOBAL_CONFIG_SITE = { 
  isPost: true,
  isHome: false,
  isSidebar: true  
  }</script><noscript><style>
#page-header {
  opacity: 1
}
.justified-gallery img{
  opacity: 1
}
</style></noscript><meta name="generator" content="Hexo 4.2.1"></head><body><div id="loading-box"><div class="loading-left-bg"></div><div class="loading-right-bg"></div><div class="spinner-box"><div class="configure-border-1"><div class="configure-core"></div></div><div class="configure-border-2"><div class="configure-core"></div></div><div class="loading-word">加载中...</div></div></div><div id="mobile-sidebar"><div id="menu_mask"></div><div id="mobile-sidebar-menus"><div class="mobile_author_icon"><img class="avatar-img" src="/img/avatar.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="mobile_post_data"><div class="mobile_data_item is-center"><div class="mobile_data_link"><a href="/archives/"><div class="headline">文章</div><div class="length_num">10</div></a></div></div><div class="mobile_data_item is-center">      <div class="mobile_data_link"><a href="/tags/"><div class="headline">标签</div><div class="length_num">7</div></a></div></div><div class="mobile_data_item is-center">     <div class="mobile_data_link"><a href="/categories/"><div class="headline">分类</div><div class="length_num">3</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fa fa-link"></i><span> 友链</span></a></div></div></div></div><i class="fa fa-arrow-right on" id="toggle-sidebar" aria-hidden="true">     </i><div id="sidebar"><div class="sidebar-toc"><div class="sidebar-toc__title">目录</div><div class="sidebar-toc__progress"><span class="progress-notice">你已经读了</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar">     </div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#概述"><span class="toc-number">1.</span> <span class="toc-text"> 概述</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#网络详解"><span class="toc-number">2.</span> <span class="toc-text"> 网络详解</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#各层结构"><span class="toc-number">2.1.</span> <span class="toc-text"> 各层结构</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#模型组件"><span class="toc-number">2.2.</span> <span class="toc-text"> 模型组件</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#relu"><span class="toc-number">2.2.1.</span> <span class="toc-text"> ReLU</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#局部响应标准化lrn-local-response-normalization"><span class="toc-number">2.2.2.</span> <span class="toc-text"> 局部响应标准化(LRN, Local Response Normalization)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#重叠池化"><span class="toc-number">2.2.3.</span> <span class="toc-text"> 重叠池化</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#dropout"><span class="toc-number">2.2.4.</span> <span class="toc-text"> Dropout</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#附录论文中的网络结构"><span class="toc-number">3.</span> <span class="toc-text"> 附录：论文中的网络结构</span></a></li></ol></div></div></div><div id="body-wrap"><div id="web_bg" data-type="photo"></div><div class="post-bg" id="nav" style="background-image: url(https://cdn.jsdelivr.net/gh/mao-jy/mao-jy.github.io/2020/06/27/AlexNet/AlexNet_Andrew_Ng_20200627.png)"><div id="page-header"><span class="pull_left" id="blog_name"><a class="blog_title" id="site-name" href="/">Jeff_M</a></span><span class="pull_right menus"><div id="search_button"><a class="site-page social-icon search"><i class="fa fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fa fa-link"></i><span> 友链</span></a></div></div><span class="toggle-menu close"><a class="site-page"><i class="fa fa-bars fa-fw" aria-hidden="true"></i></a></span></span></div><div id="post-info"><div id="post-title"><div class="posttitle">AlexNet</div></div><div id="post-meta"><div class="meta-firstline"><time class="post-meta__date"><span class="post-meta__date-created" title="发表于 2020-06-27 14:57:50"><i class="fa fa-calendar" aria-hidden="true"></i> 发表于 2020-06-27</span><span class="post-meta__separator">|</span><span class="post-meta__date-updated" title="更新于 2020-07-04 21:44:41"><i class="fa fa-history" aria-hidden="true"></i> 更新于 2020-07-04</span></time><span class="post-meta__categories"><span class="post-meta__separator">|</span><i class="fa fa-inbox post-meta__icon" aria-hidden="true"></i><a class="post-meta__categories" href="/categories/%E6%A8%A1%E5%9E%8B%E8%A7%A3%E6%9E%90/">模型解析</a></span></div><div class="meta-secondline"> <span class="post-meta-wordcount"><i class="post-meta__icon fa fa-file-word-o" aria-hidden="true"></i><span>字数总计:</span><span class="word-count">1.6k</span><span class="post-meta__separator">|</span><i class="post-meta__icon fa fa-clock-o" aria-hidden="true"></i><span>阅读时长: 5 分钟</span></span></div><div class="meta-thirdline"><span class="post-meta-pv-cv"><span class="post-meta__separator">|</span><i class="fa fa-eye post-meta__icon" aria-hidden="true"> </i><span>阅读量:</span><span id="busuanzi_value_page_pv"></span></span><span class="post-meta-commentcount"></span></div></div></div></div><main class="layout_post" id="content-inner"><article id="post"><div class="post-content" id="article-container"><h1 id="概述"><a class="markdownIt-Anchor" href="#概述"></a> 概述</h1>
<p>AlexNet为ILSVRC-2012分类竞赛的冠军模型，达到了Top-5 15.32%的错误率。在此之前，计算机视觉方面的问题大都是使用非深度的机器学习方法，而AlexNet则把卷积神经网络带入到广大计算机视觉研究者的视野中。论文出自Hinton带领的小组，第一作者是Hinton的学生Alex，AlexNet也因此得名。</p>
<p>整个模型共分为8层，结构大致为：卷积-池化-卷积-池化-卷积-卷积-卷积-池化-全连接-全连接-全连接（其中卷积-池化看作1层）。模型中还加入了一些如今都在广泛使用的结构如ReLU激活函数和Dropout；也加入了一种类似于批标准化(Batch Normalization)的方法：局部响应归一化(LRN， Local Response Normalization)；比赛中还使用了些许数据增强的方法。</p>
<p>论文：<a href="http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf" target="_blank" rel="noopener">ImageNet Classification with Deep Convolutional Neural Networks</a></p>
<h1 id="网络详解"><a class="markdownIt-Anchor" href="#网络详解"></a> 网络详解</h1>
<p><img src="AlexNet_Andrew_Ng_20200627.png" alt="AlexNet_Andrew_Ng" /></p>
<p><strong>说明：由于论文中使用了两个GPU训练，结构图看起来不是特别清晰，所以选择了吴恩达深度学习课程上给出的结构图，且论文中的训练方法也有些特殊，相关介绍会在最后给出。此外，卷积层输出尺寸的计算可以使用公式<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>O</mi><mi>U</mi><mi>T</mi><mi>P</mi><mi>U</mi><mi>T</mi><mi mathvariant="normal">_</mi><mi>N</mi><mo>=</mo><mo stretchy="false">⌊</mo><mfrac><mrow><mi>I</mi><mi>N</mi><mi>P</mi><mi>U</mi><mi>T</mi><mi mathvariant="normal">_</mi><mi>N</mi><mo>+</mo><mn>2</mn><mi>P</mi><mo>−</mo><mi>K</mi></mrow><mi>S</mi></mfrac><mo stretchy="false">⌋</mo><mo>+</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">OUTPUT\_N = \lfloor \frac{INPUT\_N + 2P-K}{S} \rfloor + 1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.99333em;vertical-align:-0.31em;"></span><span class="mord mathdefault" style="margin-right:0.02778em;">O</span><span class="mord mathdefault" style="margin-right:0.10903em;">U</span><span class="mord mathdefault" style="margin-right:0.13889em;">T</span><span class="mord mathdefault" style="margin-right:0.13889em;">P</span><span class="mord mathdefault" style="margin-right:0.10903em;">U</span><span class="mord mathdefault" style="margin-right:0.13889em;">T</span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord mathdefault" style="margin-right:0.10903em;">N</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.350331em;vertical-align:-0.345em;"></span><span class="mopen">⌊</span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.005331em;"><span style="top:-2.6550000000000002em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.05764em;">S</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.527em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.07847em;">I</span><span class="mord mathdefault mtight" style="margin-right:0.10903em;">N</span><span class="mord mathdefault mtight" style="margin-right:0.13889em;">P</span><span class="mord mathdefault mtight" style="margin-right:0.10903em;">U</span><span class="mord mathdefault mtight" style="margin-right:0.13889em;">T</span><span class="mord mtight" style="margin-right:0.02778em;">_</span><span class="mord mathdefault mtight" style="margin-right:0.10903em;">N</span><span class="mbin mtight">+</span><span class="mord mtight">2</span><span class="mord mathdefault mtight" style="margin-right:0.13889em;">P</span><span class="mbin mtight">−</span><span class="mord mathdefault mtight" style="margin-right:0.07153em;">K</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose">⌋</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span></span></span></span>，其中INPUT_N为输入尺寸，OUTPUT_N为输出尺寸，P为填充尺寸，K为卷积核的尺寸，S为卷积步长。池化层输出尺寸也可用上述公式计算。</strong></p>
<h2 id="各层结构"><a class="markdownIt-Anchor" href="#各层结构"></a> 各层结构</h2>
<p>各层的详细参数上图中已经给出，不重复描述。下面给出各层的详细结构（有些东西并未在图中体现出来）：</p>
<ul>
<li>
<p>卷积-LRN-最大池化-ReLU</p>
</li>
<li>
<p>卷积-LRN-最大池化-ReLU</p>
</li>
<li>
<p>卷积-ReLU</p>
</li>
<li>
<p>卷积-ReLU</p>
</li>
<li>
<p>卷积-最大池化-ReLU-Flatten</p>
</li>
<li>
<p>全连接-ReLU-Dropout</p>
</li>
<li>
<p>全连接-ReLU-Dropout</p>
</li>
<li>
<p>全连接-softmax</p>
</li>
</ul>
<h2 id="模型组件"><a class="markdownIt-Anchor" href="#模型组件"></a> 模型组件</h2>
<p>本部分给出几个比较值得一提的模型组件，没有给出的不是因为不重要，而是概念过于常见，没有必要展开叙述。</p>
<h3 id="relu"><a class="markdownIt-Anchor" href="#relu"></a> ReLU</h3>
<p>在此之前我们会使用sigmoid或tanh作为模型的激活函数，但对于梯度下降来说，非饱和非线性的函数（如ReLU）要比饱和非线性函数快上许多。下图是论文作者在CIFAR-10数据集上进行的实验，使用了四层卷积的网络结构，其中实线表示ReLU激活函数的收敛过程，虚线表示tanh激活函数的收敛过程，同样是到达0.25的Training error rate，ReLU要比tanh快上6倍左右。且作者还指出，网络结构不同，实验结果也可能不同，但ReLU总是比饱和线性函数快上几倍。</p>
<p><img src="ReLU_20200627.png" alt="ReLU" /></p>
<p><strong>注：对于函数y=f(x)，当<span class="katex"><span class="katex-mathml"><math><semantics><mrow><munder><mo><mi>lim</mi><mo>⁡</mo></mo><mrow><mi>x</mi><mo>→</mo><mo>+</mo><mi mathvariant="normal">∞</mi></mrow></munder><msup><mi>f</mi><mo mathvariant="normal">′</mo></msup><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">\lim\limits_{x \to +\infty} f&#x27;(x) = 0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.5102229999999999em;vertical-align:-0.758331em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.69444em;"><span style="top:-2.1em;margin-left:0em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">x</span><span class="mrel mtight">→</span><span class="mord mtight">+</span><span class="mord mtight">∞</span></span></span></span><span style="top:-2.7em;"><span class="pstrut" style="height:2.7em;"></span><span><span class="mop">lim</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.758331em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.751892em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">0</span></span></span></span>时，则称函数f(x)右饱和；当<span class="katex"><span class="katex-mathml"><math><semantics><mrow><munder><mo><mi>lim</mi><mo>⁡</mo></mo><mrow><mi>x</mi><mo>→</mo><mo>−</mo><mi mathvariant="normal">∞</mi></mrow></munder><msup><mi>f</mi><mo mathvariant="normal">′</mo></msup><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">\lim\limits_{x \to -\infty} f&#x27;(x) = 0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.5102229999999999em;vertical-align:-0.758331em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.69444em;"><span style="top:-2.1em;margin-left:0em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">x</span><span class="mrel mtight">→</span><span class="mord mtight">−</span><span class="mord mtight">∞</span></span></span></span><span style="top:-2.7em;"><span class="pstrut" style="height:2.7em;"></span><span><span class="mop">lim</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.758331em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.751892em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">0</span></span></span></span>时，则称函数f(x)左饱和。当f(x)同时满足左饱和和右饱和时，则称f(x)为饱和函数。</strong></p>
<h3 id="局部响应标准化lrn-local-response-normalization"><a class="markdownIt-Anchor" href="#局部响应标准化lrn-local-response-normalization"></a> 局部响应标准化(LRN, Local Response Normalization)</h3>
<p>对于饱和函数，需要进行标准化来使得输入尽量落在非饱和区域，加快收敛速度。而对于非饱和函数，并没有这种需要，但实验表明LRN仍有助于泛化。LRN的公式为：</p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msubsup><mi>b</mi><mrow><mi>x</mi><mo separator="true">,</mo><mi>y</mi></mrow><mi>i</mi></msubsup><mo>=</mo><msubsup><mi>a</mi><mrow><mi>x</mi><mo separator="true">,</mo><mi>y</mi></mrow><mi>i</mi></msubsup><mi mathvariant="normal">/</mi><mo stretchy="false">(</mo><mi>k</mi><mo>+</mo><mi>α</mi><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mi>m</mi><mi>a</mi><mi>x</mi><mo stretchy="false">(</mo><mn>0</mn><mo separator="true">,</mo><mi>i</mi><mo>−</mo><mi>n</mi><mi mathvariant="normal">/</mi><mn>2</mn><mo stretchy="false">)</mo></mrow><mrow><mi>m</mi><mi>i</mi><mi>n</mi><mo stretchy="false">(</mo><mi>N</mi><mo>−</mo><mn>1</mn><mo separator="true">,</mo><mi>i</mi><mo>+</mo><mi>n</mi><mi mathvariant="normal">/</mi><mn>2</mn><mo stretchy="false">)</mo></mrow></munderover><mo stretchy="false">(</mo><msubsup><mi>a</mi><mrow><mi>x</mi><mo separator="true">,</mo><mi>y</mi></mrow><mi>j</mi></msubsup><msup><mo stretchy="false">)</mo><mn>2</mn></msup><msup><mo stretchy="false">)</mo><mi>β</mi></msup></mrow><annotation encoding="application/x-tex">b_{x, y}^{i} = a_{x, y}^{i} / (k + \alpha \sum_{j = max(0, i - n / 2)}^{min(N - 1, i + n / 2)} (a_{x, y}^{j})^2)^{\beta}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.2577720000000001em;vertical-align:-0.383108em;"></span><span class="mord"><span class="mord mathdefault">b</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.874664em;"><span style="top:-2.4530000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">x</span><span class="mpunct mtight">,</span><span class="mord mathdefault mtight" style="margin-right:0.03588em;">y</span></span></span></span><span style="top:-3.1130000000000004em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.383108em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.2577720000000001em;vertical-align:-0.383108em;"></span><span class="mord"><span class="mord mathdefault">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.874664em;"><span style="top:-2.4530000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">x</span><span class="mpunct mtight">,</span><span class="mord mathdefault mtight" style="margin-right:0.03588em;">y</span></span></span></span><span style="top:-3.1130000000000004em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.383108em;"><span></span></span></span></span></span></span><span class="mord">/</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.03148em;">k</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:3.4770100000000004em;vertical-align:-1.5160049999999998em;"></span><span class="mord mathdefault" style="margin-right:0.0037em;">α</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.9610050000000006em;"><span style="top:-1.8089950000000001em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span><span class="mrel mtight">=</span><span class="mord mathdefault mtight">m</span><span class="mord mathdefault mtight">a</span><span class="mord mathdefault mtight">x</span><span class="mopen mtight">(</span><span class="mord mtight">0</span><span class="mpunct mtight">,</span><span class="mord mathdefault mtight">i</span><span class="mbin mtight">−</span><span class="mord mathdefault mtight">n</span><span class="mord mtight">/</span><span class="mord mtight">2</span><span class="mclose mtight">)</span></span></span></span><span style="top:-3.050005em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.386005em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">m</span><span class="mord mathdefault mtight">i</span><span class="mord mathdefault mtight">n</span><span class="mopen mtight">(</span><span class="mord mathdefault mtight" style="margin-right:0.10903em;">N</span><span class="mbin mtight">−</span><span class="mord mtight">1</span><span class="mpunct mtight">,</span><span class="mord mathdefault mtight">i</span><span class="mbin mtight">+</span><span class="mord mathdefault mtight">n</span><span class="mord mtight">/</span><span class="mord mtight">2</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.5160049999999998em;"><span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.874664em;"><span style="top:-2.4530000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">x</span><span class="mpunct mtight">,</span><span class="mord mathdefault mtight" style="margin-right:0.03588em;">y</span></span></span></span><span style="top:-3.1130000000000004em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.383108em;"><span></span></span></span></span></span></span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8641079999999999em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8991079999999999em;"><span style="top:-3.1130000000000004em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.05278em;">β</span></span></span></span></span></span></span></span></span></span></span></span></span></p>
<p>其中<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msubsup><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mi>m</mi><mi>a</mi><mi>x</mi><mo stretchy="false">(</mo><mn>0</mn><mo separator="true">,</mo><mi>i</mi><mo>−</mo><mi>n</mi><mi mathvariant="normal">/</mi><mn>2</mn><mo stretchy="false">)</mo></mrow><mrow><mi>m</mi><mi>i</mi><mi>n</mi><mo stretchy="false">(</mo><mi>N</mi><mo>−</mo><mn>1</mn><mo separator="true">,</mo><mi>i</mi><mo>+</mo><mi>n</mi><mi mathvariant="normal">/</mi><mn>2</mn><mo stretchy="false">)</mo></mrow></msubsup><mo stretchy="false">(</mo><msubsup><mi>a</mi><mrow><mi>x</mi><mo separator="true">,</mo><mi>y</mi></mrow><mi>j</mi></msubsup><msup><mo stretchy="false">)</mo><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">\sum_{j = max(0, i - n / 2)}^{min(N - 1, i + n / 2)} (a_{x, y}^{j})^2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.5599999999999998em;vertical-align:-0.5151999999999999em;"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:-0.0000050000000000050004em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.0448em;"><span style="top:-2.3598em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span><span class="mrel mtight">=</span><span class="mord mathdefault mtight">m</span><span class="mord mathdefault mtight">a</span><span class="mord mathdefault mtight">x</span><span class="mopen mtight">(</span><span class="mord mtight">0</span><span class="mpunct mtight">,</span><span class="mord mathdefault mtight">i</span><span class="mbin mtight">−</span><span class="mord mathdefault mtight">n</span><span class="mord mtight">/</span><span class="mord mtight">2</span><span class="mclose mtight">)</span></span></span></span><span style="top:-3.2198em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">m</span><span class="mord mathdefault mtight">i</span><span class="mord mathdefault mtight">n</span><span class="mopen mtight">(</span><span class="mord mathdefault mtight" style="margin-right:0.10903em;">N</span><span class="mbin mtight">−</span><span class="mord mtight">1</span><span class="mpunct mtight">,</span><span class="mord mathdefault mtight">i</span><span class="mbin mtight">+</span><span class="mord mathdefault mtight">n</span><span class="mord mtight">/</span><span class="mord mtight">2</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.5151999999999999em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.824664em;"><span style="top:-2.4530000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">x</span><span class="mpunct mtight">,</span><span class="mord mathdefault mtight" style="margin-right:0.03588em;">y</span></span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.383108em;"><span></span></span></span></span></span></span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span>是对于同一位置，不同卷积核得到的卷积值（以当前核为中心，取前后各<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>n</mi><mi mathvariant="normal">/</mi><mn>2</mn></mrow><annotation encoding="application/x-tex">n / 2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault">n</span><span class="mord">/</span><span class="mord">2</span></span></span></span>个卷积值）的平方进行求和。几个超参数的设置为<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>k</mi><mo>=</mo><mn>2</mn><mo separator="true">,</mo><mi>n</mi><mo>−</mo><mn>5</mn><mo separator="true">,</mo><mi>α</mi><mo>=</mo><mn>1</mn><msup><mn>0</mn><mrow><mo>−</mo><mn>4</mn></mrow></msup><mo separator="true">,</mo><mi>b</mi><mi>e</mi><mi>t</mi><mi>a</mi><mo>=</mo><mn>0.75</mn></mrow><annotation encoding="application/x-tex">k=2, n-5, \alpha=10^{-4}, beta=0.75</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.03148em;">k</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.8388800000000001em;vertical-align:-0.19444em;"></span><span class="mord">2</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault">n</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.8388800000000001em;vertical-align:-0.19444em;"></span><span class="mord">5</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.0037em;">α</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.008548em;vertical-align:-0.19444em;"></span><span class="mord">1</span><span class="mord"><span class="mord">0</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mord mtight">4</span></span></span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault">b</span><span class="mord mathdefault">e</span><span class="mord mathdefault">t</span><span class="mord mathdefault">a</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">0</span><span class="mord">.</span><span class="mord">7</span><span class="mord">5</span></span></span></span>，这些值是在验证集上得出的。LRN相当于一种局部神经元之间的竞争机制，响应比较大的值会变得相对更大，同时横向抑制响应较小的值，以此提高泛化能力。在ImageNet数据集上，这个方法能减少top-1 1.4%，top-5 1.2%的错误率，在CIFAR-10数据集上能减少2%左右的错误率。</p>
<h3 id="重叠池化"><a class="markdownIt-Anchor" href="#重叠池化"></a> 重叠池化</h3>
<p>不同于传统的池化，AlexNet中使用的池化层步长小于池化窗口，这就使得池化窗口会出现重叠的情况，这种方法降低了top-1 0.4%和top-5 0.3%的错误率，但是重叠池化可能存在难以拟合的情况。</p>
<h3 id="dropout"><a class="markdownIt-Anchor" href="#dropout"></a> Dropout</h3>
<p>为了防止过拟合，使用了Dropout(0.5)，这种技术降低了神经元之间复杂的“相互协作”，但同时也会减缓拟合速度。</p>
<h1 id="附录论文中的网络结构"><a class="markdownIt-Anchor" href="#附录论文中的网络结构"></a> 附录：论文中的网络结构</h1>
<p><img src="AlexNet_20200627.png" alt="AlexNet" /></p>
<ul>
<li>论文中的网络结构和前面的网络结构大体相似，但有些细节不同，而且由于使用了双GPU进行运算，网络结构中有些地方也是为了进行并行运算，所以图片看起来有些复杂。上面缺少的部分不是截图少截了，而是论文中的原图就是如此。</li>
<li>论文中模型图有个错误，输入尺寸标为224×224×3，但实际上应该是227×227×3，这是如今主流的解释。个人理解为，如果不进行pad，那么输入必须是227×227×3才能与卷积后的尺寸对应；如果令pad=3，那么输入为224×224×3就可以和卷积后尺寸对应。</li>
<li>图中的第二层卷积，其输入并不是第一层输出的全部96层特征层，而是每块GPU以自身的48个特征图作为输入，分别运算。图中的第四、五层卷积与第二层卷积相同，都是以自身所在GPU的特征层作为输入，而不是以上一层的全部特征层作为输入。</li>
</ul>
</div><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">Jeff_M</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://mao-jy.github.io/2020/06/27/AlexNet/">http://mao-jy.github.io/2020/06/27/AlexNet/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://mao-jy.github.io" target="_blank">Jeff_M</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/Deep-Learning/">Deep Learning</a><a class="post-meta__tags" href="/tags/CNN/">CNN</a><a class="post-meta__tags" href="/tags/CNN%E4%BA%94%E5%A4%A7%E7%BB%8F%E5%85%B8%E6%A8%A1%E5%9E%8B/">CNN五大经典模型</a></div><div class="post_share"><div class="social-share" data-image="/yolo.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css"/><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js"></script></div></div><div class="post-reward"><a class="reward-button button--primary button--animated"> <i class="fa fa-qrcode"></i> 打赏<div class="reward-main"><ul class="reward-all"><li class="reward-item"><img class="post-qr-code__img" src="/img/wechat.png" alt="微信"/><div class="post-qr-code__desc">微信</div></li><li class="reward-item"><img class="post-qr-code__img" src="/img/alipay.png" alt="支付宝"/><div class="post-qr-code__desc">支付宝</div></li></ul></div></a></div><nav class="pagination_post" id="pagination"><div class="prev-post pull_left"><a href="/2020/06/28/GoogLeNet/"><img class="prev_cover" src="https://cdn.jsdelivr.net/gh/mao-jy/mao-jy.github.io/2020/06/28/GoogLeNet/deeper_20200628.jpg" onerror="onerror=null;src='/img/404.jpg'"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">GoogLeNet</div></div></a></div><div class="next-post pull_right"><a href="/2020/06/26/LeNet-5/"><img class="next_cover" src="https://cdn.jsdelivr.net/gh/mao-jy/mao-jy.github.io/2020/06/26/LeNet-5/LeNet_cover_20200626.png" onerror="onerror=null;src='/img/404.jpg'"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">LeNet-5</div></div></a></div></nav><div class="relatedPosts"><div class="relatedPosts_headline"><i class="fa fa-fw fa-thumbs-up" aria-hidden="true"></i><span> 相关推荐</span></div><div class="relatedPosts_list"><div class="relatedPosts_item"><a href="/2020/06/26/LeNet-5/" title="LeNet-5"><img class="relatedPosts_cover" src="https://cdn.jsdelivr.net/gh/mao-jy/mao-jy.github.io/2020/06/26/LeNet-5/LeNet_cover_20200626.png"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 2020-06-26</div><div class="relatedPosts_title">LeNet-5</div></div></a></div><div class="relatedPosts_item"><a href="/2020/07/03/ResNet/" title="ResNet"><img class="relatedPosts_cover" src="https://cdn.jsdelivr.net/gh/mao-jy/mao-jy.github.io/2020/07/03/ResNet/Shortcut_Connection.png"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 2020-07-03</div><div class="relatedPosts_title">ResNet</div></div></a></div><div class="relatedPosts_item"><a href="/2020/07/02/VGG/" title="VGG"><img class="relatedPosts_cover" src="https://cdn.jsdelivr.net/gh/mao-jy/mao-jy.github.io/2020/07/02/VGG/VGG-16_20200702.png"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 2020-07-02</div><div class="relatedPosts_title">VGG</div></div></a></div><div class="relatedPosts_item"><a href="/2020/06/28/GoogLeNet/" title="GoogLeNet"><img class="relatedPosts_cover" src="https://cdn.jsdelivr.net/gh/mao-jy/mao-jy.github.io/2020/06/28/GoogLeNet/deeper_20200628.jpg"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 2020-06-28</div><div class="relatedPosts_title">GoogLeNet</div></div></a></div><div class="relatedPosts_item"><a href="/2020/06/24/python-dl-reading-log-1/" title="《python深度学习》阅读记录（代码向） Part 1"><img class="relatedPosts_cover" src="https://cdn.jsdelivr.net/gh/mao-jy/mao-jy.github.io/2020/06/24/python-dl-reading-log-1/keras_20200624.png"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 2020-06-24</div><div class="relatedPosts_title">《python深度学习》阅读记录（代码向） Part 1</div></div></a></div><div class="relatedPosts_item"><a href="/2020/07/05/python-dl-reading-log-2/" title="《python深度学习》阅读记录（代码向） Part 2"><img class="relatedPosts_cover" src="https://cdn.jsdelivr.net/gh/mao-jy/mao-jy.github.io/2020/07/05/python-dl-reading-log-2/keras.png"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 2020-07-05</div><div class="relatedPosts_title">《python深度学习》阅读记录（代码向） Part 2</div></div></a></div></div><div class="clear_both"></div></div><hr><div id="post-comment"><div class="comment_headling"><i class="fa fa-comments fa-fw" aria-hidden="true"></i><span> 评论</span></div><div class="vcomment" id="vcomment"></div><script src="https://cdn.jsdelivr.net/npm/valine/dist/Valine.min.js"></script><script>var requestSetting = function (from,set) {
  var from = from
  var setting = set.split(',').filter(function(item){
  return from.indexOf(item) > -1
  });
  setting = setting.length == 0 ? from :setting;
  return setting
}

var guestInfo = requestSetting(['nick','mail','link'],'nick,mail,link')
var requiredFields = requestSetting(['nick','mail','link'],'nick,mail')

window.valine = new Valine({
  el:'#vcomment',
  appId: 'DMLfYgnTzSS4iKM5wKyheHE8-gzGzoHsz',
  appKey: 'B4g4Lha5hoOpOu75s8KrifQO',
  notify: false,
  verify: false,
  placeholder: '欢迎评论~',
  avatar: 'monsterid',
  meta: guestInfo,
  pageSize: '10',
  lang: 'zh-CN',
  recordIP: false,
  serverURLs: '',
  emojiCDN: '',
  emojiMaps: "",
  enableQQ: false,
  requiredFields: requiredFields
});</script></div></article></main><footer id="footer" data-type="color"><div id="footer-wrap"><div class="copyright">&copy;2020 By Jeff_M</div><div class="framework-info"><span>驱动 </span><a href="https://hexo.io" target="_blank" rel="noopener"><span>Hexo</span></a><span class="footer-separator">|</span><span>主题 </span><a href="https://github.com/jerryc127/hexo-theme-butterfly" target="_blank" rel="noopener"><span>Butterfly</span></a></div></div></footer></div><section class="rightside" id="rightside"><div id="rightside-config-hide"><i class="fa fa-book" id="readmode" title="阅读模式"></i><i class="fa fa-plus" id="font_plus" title="放大字体"></i><i class="fa fa-minus" id="font_minus" title="缩小字体"></i><a class="translate_chn_to_cht" id="translateLink" href="javascript:translatePage();" title="简繁转换" target="_self">繁</a><i class="darkmode fa fa-moon-o" id="darkmode" title="夜间模式"></i></div><div id="rightside-config-show"><div id="rightside_config" title="设置"><i class="fa fa-cog" aria-hidden="true"></i></div><a id="to_comment" href="#post-comment" title="直达评论"><i class="scroll_to_comment fa fa-comments">  </i></a><i class="fa fa-list-ul close" id="mobile-toc-button" title="目录" aria-hidden="true"></i><i class="fa fa-arrow-up" id="go-up" title="回到顶部" aria-hidden="true"></i></div></section><div class="search-dialog" id="local-search"><div class="search-dialog__title" id="local-search-title">本地搜索</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div></div><hr/><div id="local-search-results"><div id="local-hits"></div><div id="local-stats"><div class="local-search-stats__hr" id="hr"><span>由</span> <a href="https://github.com/wzpan/hexo-generator-search" target="_blank" rel="noopener" style="color:#49B1F5;">hexo-generator-search</a>
 <span>提供支持</span></div></div></div><span class="search-close-button"><i class="fa fa-times"></i></span></div><div class="search-mask"></div><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/gh/wilq32/jqueryrotate/jQueryRotate.js"></script><script src="/js/tw_cn.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.css"><script src="https://cdn.jsdelivr.net/npm/katex-copytex@latest/dist/katex-copytex.min.js"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex-copytex@latest/dist/katex-copytex.min.css"><script>$(function () {
  $('span.katex-display').wrap('<div class="katex-wrap"></div>')
})</script><script src="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.js"></script><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page@3/instantpage.min.js" type="module"></script><script src="/js/search/local-search.js"></script><script>var endLoading = function () {
  document.body.style.overflow = 'auto';
  document.getElementById('loading-box').classList.add("loaded")
}
window.addEventListener('load',endLoading)</script><script src="/js/jsdelivr.js"></script><script>if(){if(document.cookie.indexOf("user=new")==-1){Snackbar.show({duration: , text: "", width: 'auto', pos: 'top-center'});var t=new Date(new Date().getTime()+1000*60*60*);document.cookie="user=new; expires="+t.toGMTString();}}</script></body></html>